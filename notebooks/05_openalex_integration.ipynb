{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T12:45:56.455189Z",
     "start_time": "2026-02-22T12:45:55.421119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import difflib"
   ],
   "id": "30422da74ab3a70f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T12:45:57.174734Z",
     "start_time": "2026-02-22T12:45:57.166734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Config\n",
    "# OPENALEX_EMAIL = \"kar.sushmit@gmail.com\"  # <-- change this\n",
    "BASE_URL = \"https://api.openalex.org/works\"\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.80\n",
    "SLEEP_TIME = 2.5      # to avoid rate limits"
   ],
   "id": "1376f23161b4e9a8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T12:46:02.173773Z",
     "start_time": "2026-02-22T12:46:02.143734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Load titles\n",
    "titles_df = pd.read_csv('../outputs/unique_papers.csv')\n",
    "# titles_df = titles_df[titles_df['domain'] == 'DIA']\n",
    "\n",
    "# titles = titles_df['title'].dropna().unique().tolist()\n",
    "titles_df = titles_df.dropna(subset=[\"title\"])\n",
    "print(\"Total papers to query:\", len(titles_df))\n",
    "# print(\"Total DIA titles:\", len(titles))"
   ],
   "id": "2946f30d27b2f5e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers to query: 2628\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T07:29:44.159188Z",
     "start_time": "2026-02-22T07:29:44.152222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ## Title Validation\n",
    "# def is_valid_title(title):\n",
    "#     if not isinstance(title, str):\n",
    "#         return False\n",
    "#\n",
    "#     title = title.strip()\n",
    "#\n",
    "#     if len(title) < 15:\n",
    "#         return False\n",
    "#\n",
    "#     bad_keywords = [\"pdf\", \"txt\", \"md\", \"@\", \"·\"]\n",
    "#     if any(k in title.lower() for k in bad_keywords):\n",
    "#         return False\n",
    "#\n",
    "#     if not any(c.isalpha() for c in title):\n",
    "#         return False\n",
    "#\n",
    "#     return True\n",
    "#\n",
    "#\n",
    "# filtered_titles = [t for t in titles if is_valid_title(t)]\n",
    "#\n",
    "# print(\"Valid titles:\", len(filtered_titles))"
   ],
   "id": "7f5d96a0fe6e30b8",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T06:05:51.711558Z",
     "start_time": "2026-02-22T06:05:51.704538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(\"Before:\", len(titles))\n",
    "# print(\"After:\", len(filtered_titles))"
   ],
   "id": "43ef6493c8eb0ed6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T12:46:04.950218Z",
     "start_time": "2026-02-22T12:46:04.932609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ABSTRACT RECONSTRUCTION\n",
    "def reconstruct_abstract(inv_index):\n",
    "    if not inv_index:\n",
    "        return None\n",
    "\n",
    "    max_pos = max(pos for positions in inv_index.values() for pos in positions)\n",
    "    abstract_words = [\"\"] * (max_pos + 1)\n",
    "\n",
    "    for word, positions in inv_index.items():\n",
    "        for pos in positions:\n",
    "            abstract_words[pos] = word\n",
    "\n",
    "    return \" \".join(abstract_words)"
   ],
   "id": "658a3c0ae1744df3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T12:56:55.588345Z",
     "start_time": "2026-02-22T12:47:50.687275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Query OpenAlex\n",
    "import os\n",
    "\n",
    "checkpoint_path = \"../outputs/openalex_metadata_partial.csv\"\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    existing_df = pd.read_csv(checkpoint_path)\n",
    "    processed_ids = set(existing_df[\"global_paper_id\"])\n",
    "    metadata_store = existing_df.to_dict(\"records\")\n",
    "    print(\"Resuming from checkpoint:\", len(processed_ids), \"already done\")\n",
    "else:\n",
    "    processed_ids = set()\n",
    "    metadata_store = []\n",
    "\n",
    "missed_titles = []\n",
    "low_similarity_titles = []\n",
    "\n",
    "for i, row in titles_df.iterrows():\n",
    "\n",
    "    global_id = row[\"global_paper_id\"]\n",
    "    title = row[\"title\"]\n",
    "\n",
    "    # Skip already processed\n",
    "    if global_id in processed_ids:\n",
    "        continue\n",
    "\n",
    "    print(f\"[{i}/{len(titles_df)}] Processing {global_id}\")\n",
    "\n",
    "    params = {\n",
    "        \"search\": title,\n",
    "        \"per_page\": 1,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(BASE_URL, params=params, timeout=15)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Request failed:\", e)\n",
    "        missed_titles.append(global_id)\n",
    "        continue\n",
    "\n",
    "    if response.status_code == 429:\n",
    "        print(\"Rate limited. Sleeping 60 seconds...\")\n",
    "        time.sleep(60)\n",
    "        continue\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Bad status:\", response.status_code)\n",
    "        missed_titles.append(global_id)\n",
    "        time.sleep(SLEEP_TIME)\n",
    "        continue\n",
    "\n",
    "    # results = response.json().get(\"results\", [])\n",
    "    try:\n",
    "        data = response.json()\n",
    "    except Exception as e:\n",
    "        print(\"JSON parse failed:\", e)\n",
    "        missed_titles.append(global_id)\n",
    "        time.sleep(SLEEP_TIME)\n",
    "        continue\n",
    "\n",
    "    results = data.get(\"results\", [])\n",
    "\n",
    "    if not results:\n",
    "        missed_titles.append(global_id)\n",
    "        time.sleep(SLEEP_TIME)\n",
    "        continue\n",
    "\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    for r in results:\n",
    "        oa_title = r.get(\"title\", \"\")\n",
    "        score = difflib.SequenceMatcher(\n",
    "            None,\n",
    "            title.lower(),\n",
    "            oa_title.lower()\n",
    "        ).ratio()\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = r\n",
    "\n",
    "    if best_score >= SIMILARITY_THRESHOLD and best_match:\n",
    "\n",
    "        openalex_id = best_match[\"id\"]\n",
    "        year = best_match.get(\"publication_year\")\n",
    "        cited_by = best_match.get(\"cited_by_count\")\n",
    "        references = best_match.get(\"referenced_works\", [])\n",
    "        abstract = reconstruct_abstract(\n",
    "            best_match.get(\"abstract_inverted_index\")\n",
    "        )\n",
    "\n",
    "        metadata_store.append({\n",
    "            \"global_paper_id\": global_id,\n",
    "            \"openalex_id\": openalex_id,\n",
    "            \"year\": year,\n",
    "            \"cited_by_count\": cited_by,\n",
    "            \"referenced_works\": references,\n",
    "            \"abstract\": abstract,\n",
    "            \"match_score\": best_score\n",
    "        })\n",
    "\n",
    "        print(\"✔ Matched\")\n",
    "\n",
    "    else:\n",
    "        print(\"⚠ Low similarity:\", best_score)\n",
    "        low_similarity_titles.append((global_id, best_score))\n",
    "\n",
    "    # Optional: autosave every 50\n",
    "    if len(metadata_store) % 50 == 0:\n",
    "        pd.DataFrame(metadata_store).to_csv(\n",
    "            checkpoint_path, index=False\n",
    "        )\n",
    "        print(\"Checkpoint saved.\")\n",
    "\n",
    "    time.sleep(SLEEP_TIME)"
   ],
   "id": "7e4e2672af945598",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from checkpoint: 1312 already done\n",
      "[221/2628] Processing SKG_DIA_249\n",
      "Rate limited. Sleeping 60 seconds...\n",
      "[276/2628] Processing NOVEL_MT_3\n",
      "Rate limited. Sleeping 60 seconds...\n",
      "[282/2628] Processing NOVEL_MT_12\n",
      "Rate limited. Sleeping 60 seconds...\n",
      "[288/2628] Processing NOVEL_MT_22\n",
      "Rate limited. Sleeping 60 seconds...\n",
      "[294/2628] Processing NOVEL_MT_30\n",
      "Rate limited. Sleeping 60 seconds...\n",
      "[296/2628] Processing NOVEL_MT_33\n",
      "Rate limited. Sleeping 60 seconds...\n",
      "[297/2628] Processing NOVEL_MT_34\n",
      "Rate limited. Sleeping 60 seconds...\n",
      "[299/2628] Processing NOVEL_MT_36\n",
      "Rate limited. Sleeping 60 seconds...\n",
      "[307/2628] Processing NOVEL_MT_51\n",
      "Rate limited. Sleeping 60 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 44\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m429\u001B[39m:\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRate limited. Sleeping 60 seconds...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 44\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T08:55:09.305565Z",
     "start_time": "2026-02-22T08:55:09.242628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metadata_df = pd.DataFrame(metadata_store)\n",
    "metadata_df.to_csv(\"../outputs/openalex_metadata_partial.csv\", index=False)\n",
    "print(\"Partial save complete.\")"
   ],
   "id": "d4e2786d3d0887a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial save complete.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T06:52:43.684567600Z",
     "start_time": "2026-02-21T06:43:42.828622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## SAVE JSON METADATA\n",
    "\n",
    "with open(\"../outputs/openalex_metadata_full.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata_store, f, indent=2)\n",
    "\n",
    "print(\"Saved openalex_metadata_full.json\")"
   ],
   "id": "31cf83c3cbae6bce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved openalex_metadata.json\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T06:52:43.686585800Z",
     "start_time": "2026-02-21T07:00:17.370869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Saving csv summary\n",
    "metadata_df = pd.DataFrame(metadata_store)\n",
    "metadata_df.to_csv(\"../outputs/openalex_metadata_full.csv\", index=False)\n",
    "\n",
    "print(\"Saved openalex_metadata_full.csv\")"
   ],
   "id": "c9f154d8178b6b1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved openalex_metadata.csv\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T06:52:43.686585800Z",
     "start_time": "2026-02-21T07:00:19.589336Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # SAVE MATCH REPORT\n",
    "print(\"\\n==== MATCH REPORT ====\")\n",
    "print(\"Total valid titles:\", len(titles_df))\n",
    "print(\"Successful matches:\", len(metadata_df))\n",
    "print(\"Missed titles:\", len(missed_titles))\n",
    "print(\"Low similarity titles:\", len(low_similarity_titles))\n",
    "print(\"Match rate:\",\n",
    "      round(len(metadata_store) / len(titles_df), 3))\n",
    "\n",
    "\n",
    "pd.DataFrame(missed_titles, columns=[\"title\"]).to_csv(\n",
    "    \"../outputs/openalex_missed_titles.csv\", index=False\n",
    ")\n",
    "\n",
    "pd.DataFrame(low_similarity_titles,\n",
    "             columns=[\"title\", \"similarity_score\"]).to_csv(\n",
    "    \"../outputs/openalex_low_similarity.csv\", index=False\n",
    ")\n",
    "\n",
    "print(\"Saved diagnostic files.\")"
   ],
   "id": "89a3a687e5fb95be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== MATCH REPORT ====\n",
      "Total valid titles: 274\n",
      "Successful matches: 273\n",
      "Missed titles: 1\n",
      "Low similarity titles: 0\n",
      "Match rate: 0.996\n",
      "Saved diagnostic files.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T06:52:43.703460600Z",
     "start_time": "2026-02-21T07:00:22.626625Z"
    }
   },
   "cell_type": "code",
   "source": "pd.read_csv('../outputs/openalex_metadata_full.csv').head()",
   "id": "40d44a748b9f4dba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 title  \\\n",
       "0    MRF-Chat Improving Dialogue with Markov Random...   \n",
       "1    Towards Making the Most of Dialogue Characteri...   \n",
       "2    Domain-Adaptive Pretraining Methods for Dialog...   \n",
       "3    Adaptive Bridge between Training and Inference...   \n",
       "4    Controlling Dialogue Generation with Semantic ...   \n",
       "..                                                 ...   \n",
       "268  Improving Limited Labeled Dialogue State Track...   \n",
       "269  ScoutBot A Dialogue System for Collaborative N...   \n",
       "270  Bridging the Gap between Prior and Posterior K...   \n",
       "271  Evaluating Coherence in Dialogue Systems using...   \n",
       "272  Training Millions of Personalized Dialogue Agents   \n",
       "\n",
       "                          openalex_id  publication_year  cited_by_count  \\\n",
       "0    https://openalex.org/W3214342458              2021               0   \n",
       "1    https://openalex.org/W3196896228              2021              12   \n",
       "2    https://openalex.org/W3173606101              2021              19   \n",
       "3    https://openalex.org/W3214623240              2021               5   \n",
       "4    https://openalex.org/W3074476581              2021               6   \n",
       "..                                ...               ...             ...   \n",
       "268  https://openalex.org/W3105480731              2020              11   \n",
       "269  https://openalex.org/W2803503442              2018              22   \n",
       "270  https://openalex.org/W3104123491              2020              78   \n",
       "271  https://openalex.org/W2929767294              2019              17   \n",
       "272  https://openalex.org/W2890394457              2018             211   \n",
       "\n",
       "                                      referenced_works  \\\n",
       "0    ['https://openalex.org/W242376439', 'https://o...   \n",
       "1    ['https://openalex.org/W222053410', 'https://o...   \n",
       "2    ['https://openalex.org/W1522301498', 'https://...   \n",
       "3    ['https://openalex.org/W648786980', 'https://o...   \n",
       "4    ['https://openalex.org/W2037789405', 'https://...   \n",
       "..                                                 ...   \n",
       "268  ['https://openalex.org/W1522301498', 'https://...   \n",
       "269  ['https://openalex.org/W175385064', 'https://o...   \n",
       "270  ['https://openalex.org/W1522301498', 'https://...   \n",
       "271  ['https://openalex.org/W119047706', 'https://o...   \n",
       "272  ['https://openalex.org/W1793121960', 'https://...   \n",
       "\n",
       "                                              abstract  match_score  \n",
       "0    Recent state-of-the-art approaches in open-dom...     0.990654  \n",
       "1    Neural Chat Translation (NCT) aims to translat...     1.000000  \n",
       "2    Han Wu, Kun Xu, Linfeng Song, Lifeng Jin, Hais...     1.000000  \n",
       "3    Although exposure bias has been widely studied...     1.000000  \n",
       "4    Dialogue systems pretrained with large languag...     1.000000  \n",
       "..                                                 ...          ...  \n",
       "268  Existing dialogue state tracking (DST) models ...     1.000000  \n",
       "269  Stephanie M. Lukin, Felix Gervits, Cory J. Hay...     0.990991  \n",
       "270  Knowledge selection plays an important role in...     1.000000  \n",
       "271  Evaluating open-domain dialogue systems is dif...     1.000000  \n",
       "272  Current dialogue systems fail at being engagin...     1.000000  \n",
       "\n",
       "[273 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>openalex_id</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>cited_by_count</th>\n",
       "      <th>referenced_works</th>\n",
       "      <th>abstract</th>\n",
       "      <th>match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MRF-Chat Improving Dialogue with Markov Random...</td>\n",
       "      <td>https://openalex.org/W3214342458</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>['https://openalex.org/W242376439', 'https://o...</td>\n",
       "      <td>Recent state-of-the-art approaches in open-dom...</td>\n",
       "      <td>0.990654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Towards Making the Most of Dialogue Characteri...</td>\n",
       "      <td>https://openalex.org/W3196896228</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>['https://openalex.org/W222053410', 'https://o...</td>\n",
       "      <td>Neural Chat Translation (NCT) aims to translat...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Domain-Adaptive Pretraining Methods for Dialog...</td>\n",
       "      <td>https://openalex.org/W3173606101</td>\n",
       "      <td>2021</td>\n",
       "      <td>19</td>\n",
       "      <td>['https://openalex.org/W1522301498', 'https://...</td>\n",
       "      <td>Han Wu, Kun Xu, Linfeng Song, Lifeng Jin, Hais...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaptive Bridge between Training and Inference...</td>\n",
       "      <td>https://openalex.org/W3214623240</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>['https://openalex.org/W648786980', 'https://o...</td>\n",
       "      <td>Although exposure bias has been widely studied...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Controlling Dialogue Generation with Semantic ...</td>\n",
       "      <td>https://openalex.org/W3074476581</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>['https://openalex.org/W2037789405', 'https://...</td>\n",
       "      <td>Dialogue systems pretrained with large languag...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Improving Limited Labeled Dialogue State Track...</td>\n",
       "      <td>https://openalex.org/W3105480731</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>['https://openalex.org/W1522301498', 'https://...</td>\n",
       "      <td>Existing dialogue state tracking (DST) models ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>ScoutBot A Dialogue System for Collaborative N...</td>\n",
       "      <td>https://openalex.org/W2803503442</td>\n",
       "      <td>2018</td>\n",
       "      <td>22</td>\n",
       "      <td>['https://openalex.org/W175385064', 'https://o...</td>\n",
       "      <td>Stephanie M. Lukin, Felix Gervits, Cory J. Hay...</td>\n",
       "      <td>0.990991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Bridging the Gap between Prior and Posterior K...</td>\n",
       "      <td>https://openalex.org/W3104123491</td>\n",
       "      <td>2020</td>\n",
       "      <td>78</td>\n",
       "      <td>['https://openalex.org/W1522301498', 'https://...</td>\n",
       "      <td>Knowledge selection plays an important role in...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Evaluating Coherence in Dialogue Systems using...</td>\n",
       "      <td>https://openalex.org/W2929767294</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>['https://openalex.org/W119047706', 'https://o...</td>\n",
       "      <td>Evaluating open-domain dialogue systems is dif...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Training Millions of Personalized Dialogue Agents</td>\n",
       "      <td>https://openalex.org/W2890394457</td>\n",
       "      <td>2018</td>\n",
       "      <td>211</td>\n",
       "      <td>['https://openalex.org/W1793121960', 'https://...</td>\n",
       "      <td>Current dialogue systems fail at being engagin...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Duplicate global IDs:\",\n",
    "      metadata_df[\"global_paper_id\"].duplicated().sum())\n",
    "\n",
    "assert metadata_df[\"global_paper_id\"].is_unique"
   ],
   "id": "38346f87b2319ecd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
