{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-19T20:33:10.420919Z",
     "start_time": "2026-02-19T20:33:09.789745Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "import os\n",
    "from glob import glob\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:33:10.454674Z",
     "start_time": "2026-02-19T20:33:10.420919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Change this to your actual triplet folder path\n",
    "TRIPLETS_FOLDER = \"../../Scientific_Novelty_Detection/Triplets/\"\n",
    "\n",
    "# Recursively find all *_triplets.csv files\n",
    "triplet_files = glob(os.path.join(TRIPLETS_FOLDER, \"**\", \"*_triplets.csv\"), recursive=True)\n",
    "\n",
    "print(\"Found\", len(triplet_files), \"triplet files\")\n",
    "for f in triplet_files:\n",
    "    print(f)"
   ],
   "id": "b4cc12995df9d620",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 triplet files\n",
      "../../Scientific_Novelty_Detection/Triplets\\Blogs\\Dia_Blogs_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\Blogs\\MT_Blogs_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\Blogs\\QA_Blogs_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\Blogs\\SA_Blogs_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\Blogs\\Sum_Blogs_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\Novel_Papers\\Dia2021_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\Novel_Papers\\MT2021_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\Novel_Papers\\QA2021_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\Novel_Papers\\SA2021_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\Novel_Papers\\Sum2021_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\SKG\\Dia_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\SKG\\MT_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\SKG\\NLI_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\SKG\\Par_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\SKG\\QA_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\SKG\\SA_triplets.csv\n",
      "../../Scientific_Novelty_Detection/Triplets\\SKG\\Sum_triplets.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:33:11.148533Z",
     "start_time": "2026-02-19T20:33:10.466290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Merge all triplets\n",
    "all_dfs = []\n",
    "\n",
    "for file in triplet_files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    if \"sub\" not in df.columns or \"obj\" not in df.columns:\n",
    "        raise ValueError(f\"Missing 'sub' or 'obj' in {file}\")\n",
    "\n",
    "    all_dfs.append(df[[\"sub\", \"obj\"]])\n",
    "\n",
    "triplets_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(\"Total triplet rows:\", len(triplets_df))"
   ],
   "id": "6ec5ac61f47853ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triplet rows: 238088\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:33:11.196723Z",
     "start_time": "2026-02-19T20:33:11.172371Z"
    }
   },
   "cell_type": "code",
   "source": "triplets_df",
   "id": "c925c7c859725b4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                   sub                             obj\n",
       "0                     hyper-parameters           more powerful decoder\n",
       "1                more powerful decoder   higher conversational quality\n",
       "2                    ablation analysis                hyper-parameters\n",
       "3                       tuned decoding                       ssa score\n",
       "4                            ssa score                            79 %\n",
       "...                                ...                             ...\n",
       "238083                         results                  proposed model\n",
       "238084                       our model                longer sequences\n",
       "238085                longer sequences  introduction and the sentences\n",
       "238086  introduction and the sentences                       extractor\n",
       "238087                         results                       our model\n",
       "\n",
       "[238088 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub</th>\n",
       "      <th>obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyper-parameters</td>\n",
       "      <td>more powerful decoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>more powerful decoder</td>\n",
       "      <td>higher conversational quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ablation analysis</td>\n",
       "      <td>hyper-parameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tuned decoding</td>\n",
       "      <td>ssa score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssa score</td>\n",
       "      <td>79 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238083</th>\n",
       "      <td>results</td>\n",
       "      <td>proposed model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238084</th>\n",
       "      <td>our model</td>\n",
       "      <td>longer sequences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238085</th>\n",
       "      <td>longer sequences</td>\n",
       "      <td>introduction and the sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238086</th>\n",
       "      <td>introduction and the sentences</td>\n",
       "      <td>extractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238087</th>\n",
       "      <td>results</td>\n",
       "      <td>our model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238088 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:33:11.983990Z",
     "start_time": "2026-02-19T20:33:11.269143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Normalise Entity Strings\n",
    "def normalize_entity(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "\n",
    "    text = str(text).strip().lower()\n",
    "\n",
    "    # Remove excessive quotes\n",
    "    text = text.replace('\"\"\"', '\"')\n",
    "    text = text.replace(\"''\", \"'\")\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    return text\n",
    "\n",
    "triplets_df[\"sub\"] = triplets_df[\"sub\"].apply(normalize_entity)\n",
    "triplets_df[\"obj\"] = triplets_df[\"obj\"].apply(normalize_entity)"
   ],
   "id": "bea2840ec70b4fcd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:33:12.227834Z",
     "start_time": "2026-02-19T20:33:12.068905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_entities = set(triplets_df[\"sub\"].dropna()) | set(triplets_df[\"obj\"].dropna())\n",
    "print(\"Raw unique entities:\", len(raw_entities))"
   ],
   "id": "e339b87d64b59c28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw unique entities: 119379\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:33:12.528913Z",
     "start_time": "2026-02-19T20:33:12.512957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_valid_entity(text):\n",
    "    if not text:\n",
    "        return False\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    # Minimum length\n",
    "    if len(text) < 3:\n",
    "        return False\n",
    "\n",
    "    # Remove parenthesis-dominated patterns\n",
    "    if text.startswith(\"(\"):\n",
    "        return False\n",
    "\n",
    "    if re.fullmatch(r\"\\(.*\\)\", text):\n",
    "        return False\n",
    "\n",
    "    # Remove set notation / math blocks\n",
    "    if text.startswith(\"{\") or text.startswith(\"|\"):\n",
    "        return False\n",
    "\n",
    "    if re.search(r\"\\{.*\\}\", text):\n",
    "        return False\n",
    "\n",
    "    # Remove scientific notation\n",
    "    if re.search(r\"\\d+e[-\\s]?\\d+\", text):\n",
    "        return False\n",
    "\n",
    "    # Remove heavy numeric ratio\n",
    "    digit_ratio = sum(c.isdigit() for c in text) / len(text)\n",
    "    if digit_ratio > 0.4:\n",
    "        return False\n",
    "\n",
    "    # Remove hardware/config patterns\n",
    "    if \"gpu\" in text:\n",
    "        return False\n",
    "\n",
    "    if \"units\" in text:\n",
    "        return False\n",
    "\n",
    "    if \"encoder\" in text and \"decoder\" in text:\n",
    "        return False\n",
    "\n",
    "    # Remove statistical fragments\n",
    "    if text.startswith(\"~\"):\n",
    "        return False\n",
    "\n",
    "    if \"%\" in text:\n",
    "        return False\n",
    "\n",
    "    stat_patterns = [\n",
    "        \" more \",\n",
    "        \" lower\",\n",
    "        \" lines\",\n",
    "        \" questions\",\n",
    "        \" entities\",\n",
    "        \" pp\",\n",
    "        \" ratio\"\n",
    "    ]\n",
    "\n",
    "    for p in stat_patterns:\n",
    "        if p in text:\n",
    "            return False\n",
    "\n",
    "    if re.search(r\"\\d+\\s?[km]\", text):\n",
    "        return False\n",
    "\n",
    "    if re.search(r\"\\d+\\.?\\d*x\", text):\n",
    "        return False\n",
    "\n",
    "    # Must contain alphabet\n",
    "    if not re.search(r\"[a-zA-Z]\", text):\n",
    "        return False\n",
    "\n",
    "    # Remove pure punctuation\n",
    "    if re.fullmatch(r\"[\\W_]+\", text):\n",
    "        return False\n",
    "\n",
    "    return True"
   ],
   "id": "961f4115a0e44c1e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:33:14.014194Z",
     "start_time": "2026-02-19T20:33:12.749382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Extract unique Entities\n",
    "clean_entities = {e for e in raw_entities if is_valid_entity(e)}\n",
    "print(\"Clean unique entities:\", len(clean_entities))"
   ],
   "id": "b68c2a8019703139",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean unique entities: 108816\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:33:17.701959Z",
     "start_time": "2026-02-19T20:33:17.344289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Assign entity IDs\n",
    "def generate_entity_id(entity_string):\n",
    "    return \"E_\" + hashlib.md5(entity_string.encode(\"utf-8\")).hexdigest()[:10]\n",
    "\n",
    "entity_data = []\n",
    "\n",
    "for entity in sorted(clean_entities):\n",
    "    entity_id = generate_entity_id(entity)\n",
    "    entity_data.append({\n",
    "        \"node_id\": entity_id,\n",
    "        \"node_type\": \"Entity\",\n",
    "        \"name\": entity\n",
    "    })\n",
    "\n",
    "entity_nodes_df = pd.DataFrame(entity_data)"
   ],
   "id": "451096f28543ad9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:33:17.961496Z",
     "start_time": "2026-02-19T20:33:17.701959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "entity_nodes_df.to_csv(\"../outputs/entity_nodes.csv\", index=False)\n",
    "\n",
    "print(\"entity_nodes.csv created successfully.\")"
   ],
   "id": "f46ec2f008a15901",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity_nodes.csv created successfully.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:33:48.413624Z",
     "start_time": "2026-02-19T20:33:48.382360Z"
    }
   },
   "cell_type": "code",
   "source": "entity_nodes_df.sample(50)",
   "id": "124366ff9ecc2db5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             node_id node_type  \\\n",
       "19457   E_daf9566046    Entity   \n",
       "54869   E_70a82ed313    Entity   \n",
       "62566   E_0f04cf5ba5    Entity   \n",
       "19288   E_4b3ddb1ee9    Entity   \n",
       "84794   E_6276ef647a    Entity   \n",
       "5408    E_0062ef963f    Entity   \n",
       "100483  E_9fbc7e50ce    Entity   \n",
       "60646   E_dec8ae0a7e    Entity   \n",
       "88951   E_eeb5763e42    Entity   \n",
       "59032   E_e551d0b620    Entity   \n",
       "98351   E_9ba6fdf5d2    Entity   \n",
       "81219   E_dd2abf1189    Entity   \n",
       "19812   E_3f0a5be3e9    Entity   \n",
       "48806   E_f1b6cecb14    Entity   \n",
       "22291   E_888f9571cc    Entity   \n",
       "30048   E_48296c8b6a    Entity   \n",
       "9874    E_76a0e0c10a    Entity   \n",
       "100808  E_1dd8b5c2b3    Entity   \n",
       "14360   E_ab6ac177e9    Entity   \n",
       "99747   E_3fa0491289    Entity   \n",
       "99874   E_16c09e98b0    Entity   \n",
       "95143   E_3d579ecd9d    Entity   \n",
       "29334   E_48562433ea    Entity   \n",
       "101781  E_0e104c5ac8    Entity   \n",
       "46609   E_5f17a91bc1    Entity   \n",
       "45737   E_4dd629f5ba    Entity   \n",
       "51008   E_bcda52ada7    Entity   \n",
       "30674   E_827eaf955b    Entity   \n",
       "26974   E_91dcc4eba0    Entity   \n",
       "85554   E_6a8b5517d2    Entity   \n",
       "20111   E_3cf7bf8232    Entity   \n",
       "107590  E_b81357d82e    Entity   \n",
       "1775    E_e6b9bc2138    Entity   \n",
       "25547   E_595d88e7d6    Entity   \n",
       "55611   E_5a5dbf184e    Entity   \n",
       "28435   E_29eb22059b    Entity   \n",
       "99348   E_937a46ce8f    Entity   \n",
       "21271   E_d5d70f7d70    Entity   \n",
       "3246    E_a1c114acf0    Entity   \n",
       "9799    E_6c6a087fc3    Entity   \n",
       "42636   E_dfc256c4e5    Entity   \n",
       "104427  E_b40a0662e1    Entity   \n",
       "77804   E_0384b5a970    Entity   \n",
       "20825   E_318550dbc1    Entity   \n",
       "87283   E_e83c9a7cce    Entity   \n",
       "36198   E_cc21768a1b    Entity   \n",
       "66490   E_a4fe565115    Entity   \n",
       "69200   E_700a3b285b    Entity   \n",
       "13608   E_7e6919ffed    Entity   \n",
       "6246    E_7f8e918d91    Entity   \n",
       "\n",
       "                                                     name  \n",
       "19457                                          ce and afl  \n",
       "54869                          manual pyramid annotations  \n",
       "62566                          negators ( e.g. , cannot )  \n",
       "19288                              catalan - spanish pair  \n",
       "84794                                    sense embeddings  \n",
       "5408                                     69.58 bleu score  \n",
       "100483         translationese from non-translated english  \n",
       "60646                         multi-task learning methods  \n",
       "88951                skewed prediction loss distributions  \n",
       "59032                         moses default value weights  \n",
       "98351                                            tm match  \n",
       "81219                        restaurant and laptop domain  \n",
       "19812                            character identification  \n",
       "48806                                       js divergence  \n",
       "22291                                 computational study  \n",
       "30048                doubly - recurrent neural networks )  \n",
       "9874                              all turn-level features  \n",
       "100808                                           tripuser  \n",
       "14360                          basic and mid-gated models  \n",
       "99747                          transfer-learning approach  \n",
       "99874                          transformer - based models  \n",
       "95143                                syntactic reordering  \n",
       "29334                                                 dmv  \n",
       "101781                                    two key factors  \n",
       "46609   inexpensive , scalable , cputrainable and effi...  \n",
       "45737     improved shortest augmented path ( sap ) method  \n",
       "51008                                      last two teams  \n",
       "30674           dynamic convolutions ( wu et al. , 2019 )  \n",
       "26974                                      degree of bias  \n",
       "85554             sentiment lexicons nrc and sentiwordnet  \n",
       "20111                                           chit-chat  \n",
       "107590                                         word model  \n",
       "1775                                 1.5 to 2 bleu points  \n",
       "25547                                  customer 's intent  \n",
       "55611                     maximum expected bleu objective  \n",
       "28435                                      different ways  \n",
       "99348                                 trainable embedding  \n",
       "21271                                         collaborate  \n",
       "3246                200 - dim pre-trained word embeddings  \n",
       "9799                                  all three relations  \n",
       "42636             hashing of ( weinberger et al. , 2009 )  \n",
       "104427                                            v-trans  \n",
       "77804                                         queryparser  \n",
       "20825                                                 cnb  \n",
       "87283                                significant superior  \n",
       "36198                              factorized transformer  \n",
       "66490                    of adding features incrementally  \n",
       "69200             other two lemmatization scheme settings  \n",
       "13608                                    bad translations  \n",
       "6246                                       about 20 hours  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>node_type</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19457</th>\n",
       "      <td>E_daf9566046</td>\n",
       "      <td>Entity</td>\n",
       "      <td>ce and afl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54869</th>\n",
       "      <td>E_70a82ed313</td>\n",
       "      <td>Entity</td>\n",
       "      <td>manual pyramid annotations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62566</th>\n",
       "      <td>E_0f04cf5ba5</td>\n",
       "      <td>Entity</td>\n",
       "      <td>negators ( e.g. , cannot )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19288</th>\n",
       "      <td>E_4b3ddb1ee9</td>\n",
       "      <td>Entity</td>\n",
       "      <td>catalan - spanish pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84794</th>\n",
       "      <td>E_6276ef647a</td>\n",
       "      <td>Entity</td>\n",
       "      <td>sense embeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408</th>\n",
       "      <td>E_0062ef963f</td>\n",
       "      <td>Entity</td>\n",
       "      <td>69.58 bleu score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100483</th>\n",
       "      <td>E_9fbc7e50ce</td>\n",
       "      <td>Entity</td>\n",
       "      <td>translationese from non-translated english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60646</th>\n",
       "      <td>E_dec8ae0a7e</td>\n",
       "      <td>Entity</td>\n",
       "      <td>multi-task learning methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88951</th>\n",
       "      <td>E_eeb5763e42</td>\n",
       "      <td>Entity</td>\n",
       "      <td>skewed prediction loss distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59032</th>\n",
       "      <td>E_e551d0b620</td>\n",
       "      <td>Entity</td>\n",
       "      <td>moses default value weights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98351</th>\n",
       "      <td>E_9ba6fdf5d2</td>\n",
       "      <td>Entity</td>\n",
       "      <td>tm match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81219</th>\n",
       "      <td>E_dd2abf1189</td>\n",
       "      <td>Entity</td>\n",
       "      <td>restaurant and laptop domain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19812</th>\n",
       "      <td>E_3f0a5be3e9</td>\n",
       "      <td>Entity</td>\n",
       "      <td>character identification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48806</th>\n",
       "      <td>E_f1b6cecb14</td>\n",
       "      <td>Entity</td>\n",
       "      <td>js divergence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22291</th>\n",
       "      <td>E_888f9571cc</td>\n",
       "      <td>Entity</td>\n",
       "      <td>computational study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30048</th>\n",
       "      <td>E_48296c8b6a</td>\n",
       "      <td>Entity</td>\n",
       "      <td>doubly - recurrent neural networks )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>E_76a0e0c10a</td>\n",
       "      <td>Entity</td>\n",
       "      <td>all turn-level features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100808</th>\n",
       "      <td>E_1dd8b5c2b3</td>\n",
       "      <td>Entity</td>\n",
       "      <td>tripuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14360</th>\n",
       "      <td>E_ab6ac177e9</td>\n",
       "      <td>Entity</td>\n",
       "      <td>basic and mid-gated models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99747</th>\n",
       "      <td>E_3fa0491289</td>\n",
       "      <td>Entity</td>\n",
       "      <td>transfer-learning approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99874</th>\n",
       "      <td>E_16c09e98b0</td>\n",
       "      <td>Entity</td>\n",
       "      <td>transformer - based models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95143</th>\n",
       "      <td>E_3d579ecd9d</td>\n",
       "      <td>Entity</td>\n",
       "      <td>syntactic reordering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29334</th>\n",
       "      <td>E_48562433ea</td>\n",
       "      <td>Entity</td>\n",
       "      <td>dmv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101781</th>\n",
       "      <td>E_0e104c5ac8</td>\n",
       "      <td>Entity</td>\n",
       "      <td>two key factors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46609</th>\n",
       "      <td>E_5f17a91bc1</td>\n",
       "      <td>Entity</td>\n",
       "      <td>inexpensive , scalable , cputrainable and effi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45737</th>\n",
       "      <td>E_4dd629f5ba</td>\n",
       "      <td>Entity</td>\n",
       "      <td>improved shortest augmented path ( sap ) method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51008</th>\n",
       "      <td>E_bcda52ada7</td>\n",
       "      <td>Entity</td>\n",
       "      <td>last two teams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30674</th>\n",
       "      <td>E_827eaf955b</td>\n",
       "      <td>Entity</td>\n",
       "      <td>dynamic convolutions ( wu et al. , 2019 )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26974</th>\n",
       "      <td>E_91dcc4eba0</td>\n",
       "      <td>Entity</td>\n",
       "      <td>degree of bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85554</th>\n",
       "      <td>E_6a8b5517d2</td>\n",
       "      <td>Entity</td>\n",
       "      <td>sentiment lexicons nrc and sentiwordnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20111</th>\n",
       "      <td>E_3cf7bf8232</td>\n",
       "      <td>Entity</td>\n",
       "      <td>chit-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107590</th>\n",
       "      <td>E_b81357d82e</td>\n",
       "      <td>Entity</td>\n",
       "      <td>word model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>E_e6b9bc2138</td>\n",
       "      <td>Entity</td>\n",
       "      <td>1.5 to 2 bleu points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25547</th>\n",
       "      <td>E_595d88e7d6</td>\n",
       "      <td>Entity</td>\n",
       "      <td>customer 's intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55611</th>\n",
       "      <td>E_5a5dbf184e</td>\n",
       "      <td>Entity</td>\n",
       "      <td>maximum expected bleu objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28435</th>\n",
       "      <td>E_29eb22059b</td>\n",
       "      <td>Entity</td>\n",
       "      <td>different ways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99348</th>\n",
       "      <td>E_937a46ce8f</td>\n",
       "      <td>Entity</td>\n",
       "      <td>trainable embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21271</th>\n",
       "      <td>E_d5d70f7d70</td>\n",
       "      <td>Entity</td>\n",
       "      <td>collaborate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>E_a1c114acf0</td>\n",
       "      <td>Entity</td>\n",
       "      <td>200 - dim pre-trained word embeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>E_6c6a087fc3</td>\n",
       "      <td>Entity</td>\n",
       "      <td>all three relations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42636</th>\n",
       "      <td>E_dfc256c4e5</td>\n",
       "      <td>Entity</td>\n",
       "      <td>hashing of ( weinberger et al. , 2009 )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104427</th>\n",
       "      <td>E_b40a0662e1</td>\n",
       "      <td>Entity</td>\n",
       "      <td>v-trans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77804</th>\n",
       "      <td>E_0384b5a970</td>\n",
       "      <td>Entity</td>\n",
       "      <td>queryparser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20825</th>\n",
       "      <td>E_318550dbc1</td>\n",
       "      <td>Entity</td>\n",
       "      <td>cnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87283</th>\n",
       "      <td>E_e83c9a7cce</td>\n",
       "      <td>Entity</td>\n",
       "      <td>significant superior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36198</th>\n",
       "      <td>E_cc21768a1b</td>\n",
       "      <td>Entity</td>\n",
       "      <td>factorized transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66490</th>\n",
       "      <td>E_a4fe565115</td>\n",
       "      <td>Entity</td>\n",
       "      <td>of adding features incrementally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69200</th>\n",
       "      <td>E_700a3b285b</td>\n",
       "      <td>Entity</td>\n",
       "      <td>other two lemmatization scheme settings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>E_7e6919ffed</td>\n",
       "      <td>Entity</td>\n",
       "      <td>bad translations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>E_7f8e918d91</td>\n",
       "      <td>Entity</td>\n",
       "      <td>about 20 hours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
