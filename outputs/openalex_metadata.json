{
  "MRF-Chat Improving Dialogue with Markov Random Fields": {
    "openalex_id": "https://openalex.org/W3214342458",
    "publication_year": 2021,
    "cited_by_count": 0,
    "referenced_works": [
      "https://openalex.org/W242376439",
      "https://openalex.org/W1996117323",
      "https://openalex.org/W1997161938",
      "https://openalex.org/W2098441518",
      "https://openalex.org/W2101137458",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2784400615",
      "https://openalex.org/W2822830299",
      "https://openalex.org/W2890140518",
      "https://openalex.org/W2893684749",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2916772188",
      "https://openalex.org/W2950457956",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963448850",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2965191666",
      "https://openalex.org/W2969574947",
      "https://openalex.org/W2971883198",
      "https://openalex.org/W2973226110",
      "https://openalex.org/W2995969307",
      "https://openalex.org/W3034600233"
    ],
    "abstract": "Recent state-of-the-art approaches in open-domain dialogue include training end-to-end deep-learning models to learn various conversational features like emotional content of response, symbolic transitions of dialogue contexts in a knowledge graph and persona of the agent and the user, among others. While neural models have shown reasonable results, modelling the cognitive processes that humans use when conversing with each other may improve the agent\u2019s quality of responses. A key element of natural conversation is to tailor one\u2019s response such that it accounts for concepts that the speaker and listener may or may not know and the contextual relevance of all prior concepts used in conversation. We show that a rich representation and explicit modeling of these psychological processes can improve predictions made by existing neural network models. In this work, we propose a novel probabilistic approach using Markov Random Fields (MRF) to augment existing deep-learning methods for improved next utterance prediction. Using human and automatic evaluations, we show that our augmentation approach significantly improves the performance of existing state-of-the-art retrieval models for open-domain conversational agents.",
    "match_score": 0.9906542056074766
  },
  "Towards Making the Most of Dialogue Characteristics for Neural Chat Translation": {
    "openalex_id": "https://openalex.org/W3196896228",
    "publication_year": 2021,
    "cited_by_count": 12,
    "referenced_works": [
      "https://openalex.org/W222053410",
      "https://openalex.org/W1503071992",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1614298861",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133012565",
      "https://openalex.org/W2136353104",
      "https://openalex.org/W2149327368",
      "https://openalex.org/W2250969425",
      "https://openalex.org/W2397490041",
      "https://openalex.org/W2608029998",
      "https://openalex.org/W2669742347",
      "https://openalex.org/W2767019613",
      "https://openalex.org/W2771249222",
      "https://openalex.org/W2794365787",
      "https://openalex.org/W2799051177",
      "https://openalex.org/W2808508619",
      "https://openalex.org/W2888159079",
      "https://openalex.org/W2891534142",
      "https://openalex.org/W2904829696",
      "https://openalex.org/W2922158773",
      "https://openalex.org/W2951039930",
      "https://openalex.org/W2952446148",
      "https://openalex.org/W2952889708",
      "https://openalex.org/W2962712961",
      "https://openalex.org/W2962784628",
      "https://openalex.org/W2962802109",
      "https://openalex.org/W2962882341",
      "https://openalex.org/W2962943802",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963532001",
      "https://openalex.org/W2963686995",
      "https://openalex.org/W2963842551",
      "https://openalex.org/W2964093087",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964202354",
      "https://openalex.org/W2964289193",
      "https://openalex.org/W2964291396",
      "https://openalex.org/W2964345285",
      "https://openalex.org/W2964669873",
      "https://openalex.org/W2970240344",
      "https://openalex.org/W2970489252",
      "https://openalex.org/W2971287409",
      "https://openalex.org/W2971347700",
      "https://openalex.org/W2971737394",
      "https://openalex.org/W2985067290",
      "https://openalex.org/W3012405907",
      "https://openalex.org/W3033962033",
      "https://openalex.org/W3034351728",
      "https://openalex.org/W3034999754",
      "https://openalex.org/W3035520602",
      "https://openalex.org/W3035629723",
      "https://openalex.org/W3099925113",
      "https://openalex.org/W3101668578",
      "https://openalex.org/W3101683892",
      "https://openalex.org/W3103733040",
      "https://openalex.org/W3105218667",
      "https://openalex.org/W3111706314",
      "https://openalex.org/W3113225429",
      "https://openalex.org/W3120168417",
      "https://openalex.org/W3120749277",
      "https://openalex.org/W3120964679",
      "https://openalex.org/W3147710239",
      "https://openalex.org/W3168420886",
      "https://openalex.org/W3173680274",
      "https://openalex.org/W3175424132",
      "https://openalex.org/W3175870450",
      "https://openalex.org/W4385245566",
      "https://openalex.org/W4404781009"
    ],
    "abstract": "Neural Chat Translation (NCT) aims to translate conversational text between speakers of different languages. Despite the promising performance of sentence-level and context-aware neural machine translation models, there still remain limitations in current NCT models because the inherent dialogue characteristics of chat, such as dialogue coherence and speaker personality, are neglected. In this paper, we propose to promote the chat translation by introducing the modeling of dialogue characteristics into the NCT model. To this end, we design four auxiliary tasks including monolingual response generation, cross-lingual response generation, next utterance discrimination, and speaker identification. Together with the main chat translation task, we optimize the enhanced NCT model through the training objectives of all these tasks. By this means, the NCT model can be enhanced by capturing the inherent dialogue characteristics, thus generating more coherent and speaker-relevant translations. Comprehensive experiments on four language directions (English<->German and English<->Chinese) verify the effectiveness and superiority of the proposed approach.",
    "match_score": 1.0
  },
  "Domain-Adaptive Pretraining Methods for Dialogue Understanding": {
    "openalex_id": "https://openalex.org/W3173606101",
    "publication_year": 2021,
    "cited_by_count": 19,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2061397531",
      "https://openalex.org/W2911489562",
      "https://openalex.org/W2944815030",
      "https://openalex.org/W2949769095",
      "https://openalex.org/W2952468927",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964223283",
      "https://openalex.org/W2970119519",
      "https://openalex.org/W2970597249",
      "https://openalex.org/W2998189980",
      "https://openalex.org/W3011411500",
      "https://openalex.org/W3034238904",
      "https://openalex.org/W3034503989",
      "https://openalex.org/W3036362489",
      "https://openalex.org/W3098694757",
      "https://openalex.org/W3113519452",
      "https://openalex.org/W3134155563",
      "https://openalex.org/W3153491684",
      "https://openalex.org/W4298870559"
    ],
    "abstract": "Han Wu, Kun Xu, Linfeng Song, Lifeng Jin, Haisong Zhang, Linqi Song. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 2021.",
    "match_score": 1.0
  },
  "Adaptive Bridge between Training and Inference for Dialogue Generation": {
    "openalex_id": "https://openalex.org/W3214623240",
    "publication_year": 2021,
    "cited_by_count": 5,
    "referenced_works": [
      "https://openalex.org/W648786980",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1861492603",
      "https://openalex.org/W1895577753",
      "https://openalex.org/W1947481528",
      "https://openalex.org/W2099471712",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2176263492",
      "https://openalex.org/W2268617045",
      "https://openalex.org/W2525778437",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2607987856",
      "https://openalex.org/W2890220768",
      "https://openalex.org/W2908747729",
      "https://openalex.org/W2938704169",
      "https://openalex.org/W2962784628",
      "https://openalex.org/W2963163972",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963248296",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963463964",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964345285",
      "https://openalex.org/W2968297680",
      "https://openalex.org/W2979826702",
      "https://openalex.org/W2995028880",
      "https://openalex.org/W2995404354",
      "https://openalex.org/W2996287690",
      "https://openalex.org/W3003223181",
      "https://openalex.org/W3033166111",
      "https://openalex.org/W3098824823",
      "https://openalex.org/W3100439847",
      "https://openalex.org/W3106118243",
      "https://openalex.org/W3176393173",
      "https://openalex.org/W4287817357",
      "https://openalex.org/W4320013936",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Although exposure bias has been widely studied in some NLP tasks, it faces its unique challenges in dialogue response generation, the representative one-to-various generation scenario.In real human dialogue, there are many appropriate responses for the same context, not only with different expressions, but also with different topics. Therefore, due to the much bigger gap between various ground-truth responses and the generated synthetic response, exposure bias is more challenging in dialogue generation task.What\u2019s more, as MLE encourages the model to only learn the common words among different ground-truth responses, but ignores the interesting and specific parts, exposure bias may further lead to the common response generation problem, such as \u201cI don\u2019t know\u201d and \u201cHaHa?\u201d In this paper, we propose a novel adaptive switching mechanism, which learns to automatically transit between ground-truth learning and generated learning regarding the word-level matching score, such as the cosine similarity. Experimental results on both Chinese STC dataset and English Reddit dataset, show that our adaptive method achieves a significant improvement in terms of metric-based evaluation and human evaluation, as compared with the state-of-the-art exposure bias approaches. Further analysis on NMT task also shows that our model can achieve a significant improvement.",
    "match_score": 1.0
  },
  "Controlling Dialogue Generation with Semantic Exemplars": {
    "openalex_id": "https://openalex.org/W3074476581",
    "publication_year": 2021,
    "cited_by_count": 6,
    "referenced_works": [
      "https://openalex.org/W2037789405",
      "https://openalex.org/W2106087324",
      "https://openalex.org/W2115792525",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2728192282",
      "https://openalex.org/W2740167620",
      "https://openalex.org/W2788330850",
      "https://openalex.org/W2796032388",
      "https://openalex.org/W2798463315",
      "https://openalex.org/W2885421725",
      "https://openalex.org/W2889009749",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2914397182",
      "https://openalex.org/W2914855263",
      "https://openalex.org/W2940154139",
      "https://openalex.org/W2946803219",
      "https://openalex.org/W2949940827",
      "https://openalex.org/W2955539078",
      "https://openalex.org/W2962753250",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2962805889",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963332597",
      "https://openalex.org/W2963371754",
      "https://openalex.org/W2963521540",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963695965",
      "https://openalex.org/W2963964898",
      "https://openalex.org/W2964110616",
      "https://openalex.org/W2964202145",
      "https://openalex.org/W2965718149",
      "https://openalex.org/W2970785611",
      "https://openalex.org/W2973049837",
      "https://openalex.org/W2979702391",
      "https://openalex.org/W2981259322",
      "https://openalex.org/W2988647680",
      "https://openalex.org/W2989202909",
      "https://openalex.org/W2995289474",
      "https://openalex.org/W2996287690",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3005136412",
      "https://openalex.org/W3017860180",
      "https://openalex.org/W3021582395",
      "https://openalex.org/W3022065131",
      "https://openalex.org/W3022592851",
      "https://openalex.org/W3023366413",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3035068109",
      "https://openalex.org/W3035636774"
    ],
    "abstract": "Dialogue systems pretrained with large language models generate locally coherent responses, but lack the fine-grained control over responses necessary to achieve specific goals. A promising method to control response generation is exemplar-based generation, in which models edit exemplar responses that are retrieved from training data, or hand-written to strategically address discourse-level goals, to fit new dialogue contexts. But, current exemplar-based approaches often excessively copy words from the exemplar responses, leading to incoherent replies. We present an Exemplar-based Dialogue Generation model, EDGE, that uses the semantic frames present in exemplar responses to guide generation. We show that controlling dialogue generation based on the semantic frames of exemplars, rather than words in the exemplar itself, improves the coherence of generated responses, while preserving semantic meaning and conversation goals present in exemplar responses.",
    "match_score": 1.0
  },
  "Proxy Indicators for the Quality of Open-domain Dialogues": {
    "openalex_id": "https://openalex.org/W3212156931",
    "publication_year": 2021,
    "cited_by_count": 0,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W131533222",
      "https://openalex.org/W1599016936",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2123301721",
      "https://openalex.org/W2130158090",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2251939518",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2396767181",
      "https://openalex.org/W2525127255",
      "https://openalex.org/W2894060751",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962989446",
      "https://openalex.org/W2963310665",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963527228",
      "https://openalex.org/W2963748441",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963846996",
      "https://openalex.org/W2963854351",
      "https://openalex.org/W2964178377",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2971164557",
      "https://openalex.org/W2972664115",
      "https://openalex.org/W2978670439",
      "https://openalex.org/W3032834023",
      "https://openalex.org/W3034808773",
      "https://openalex.org/W3104033643",
      "https://openalex.org/W3105604018",
      "https://openalex.org/W3117162907",
      "https://openalex.org/W3117574848",
      "https://openalex.org/W3121541553"
    ],
    "abstract": "The automatic evaluation of open-domain dialogues remains a largely unsolved challenge. Despite the abundance of work done in the field, human judges have to evaluate dialogues quality. As a consequence, performing such evaluations at scale is usually expensive. This work investigates using a deep-learning model trained on the General Language Understanding Evaluation (GLUE) benchmark to serve as a quality indication of open-domain dialogues. The aim is to use the various GLUE tasks as different perspectives on judging the quality of conversation, thus reducing the need for additional training data or responses that serve as quality references. Due to this nature, the method can infer various quality metrics and can derive a component-based overall score. We achieve statistically signif icant correlation coefficients of up to 0.7.",
    "match_score": 1.0
  },
  "Cross-lingual Intermediate Fine-tuning improves Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W3202597539",
    "publication_year": 2021,
    "cited_by_count": 11,
    "referenced_works": [
      "https://openalex.org/W2270070752",
      "https://openalex.org/W2419539795",
      "https://openalex.org/W2620558438",
      "https://openalex.org/W2898700502",
      "https://openalex.org/W2898856000",
      "https://openalex.org/W2914120296",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2951216772",
      "https://openalex.org/W2962738716",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2963026768",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2971277088",
      "https://openalex.org/W2973088264",
      "https://openalex.org/W2979826702",
      "https://openalex.org/W2997214274",
      "https://openalex.org/W3011574394",
      "https://openalex.org/W3034238904",
      "https://openalex.org/W3034255912",
      "https://openalex.org/W3034716087",
      "https://openalex.org/W3034724424",
      "https://openalex.org/W3035016936",
      "https://openalex.org/W3035579820",
      "https://openalex.org/W3036362489",
      "https://openalex.org/W3037879762",
      "https://openalex.org/W3098824823",
      "https://openalex.org/W3098826124",
      "https://openalex.org/W3116343068",
      "https://openalex.org/W3121523248",
      "https://openalex.org/W3124687886",
      "https://openalex.org/W3155682407",
      "https://openalex.org/W4235805184",
      "https://openalex.org/W4287599851",
      "https://openalex.org/W4288288848",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4322614701",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Recent progress in task-oriented neural dialogue systems is largely focused on a handful of languages, as annotation of training data is tedious and expensive. Machine translation has been used to make systems multilingual, but this can introduce a pipeline of errors. Another promising solution is using cross-lingual transfer learning through pretrained multilingual models. Existing methods train multilingual models with additional code-mixed task data or refine the cross-lingual representations through parallel ontologies. In this work, we enhance the transfer learning process by intermediate fine-tuning of pretrained multilingual models, where the multilingual models are fine-tuned with different but related data and/or tasks. Specifically, we use parallel and conversational movie subtitles datasets to design cross-lingual intermediate tasks suitable for downstream dialogue tasks. We use only 200K lines of parallel data for intermediate fine-tuning which is already available for 1782 language pairs. We test our approach on the cross-lingual dialogue state tracking task for the parallel MultiWoZ (English -> Chinese, Chinese -> English) and Multilingual WoZ (English -> German, English -> Italian) datasets. We achieve impressive improvements (> 20% on joint goal accuracy) on the parallel MultiWoZ dataset and the Multilingual WoZ dataset over the vanilla baseline with only 10% of the target language task data and zero-shot setup respectively.",
    "match_score": 1.0
  },
  "Continual Learning for Task-oriented Dialogue System with Iterative Network Pruning, Expanding and Masking": {
    "openalex_id": "https://openalex.org/W3175994953",
    "publication_year": 2021,
    "cited_by_count": 18,
    "referenced_works": [
      "https://openalex.org/W1682403713",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2126204609",
      "https://openalex.org/W2788388592",
      "https://openalex.org/W2791091755",
      "https://openalex.org/W2792760996",
      "https://openalex.org/W2891707612",
      "https://openalex.org/W2947843732",
      "https://openalex.org/W2952555501",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2963072899",
      "https://openalex.org/W2963412005",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964588180",
      "https://openalex.org/W2970748152",
      "https://openalex.org/W2971234316",
      "https://openalex.org/W2980994576",
      "https://openalex.org/W3034896171",
      "https://openalex.org/W3035301094",
      "https://openalex.org/W3090415328",
      "https://openalex.org/W3102445752",
      "https://openalex.org/W3106274079",
      "https://openalex.org/W3117865619",
      "https://openalex.org/W3176453826",
      "https://openalex.org/W3179436402"
    ],
    "abstract": "Binzong Geng, Fajie Yuan, Qiancheng Xu, Ying Shen, Ruifeng Xu, Min Yang. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 2021.",
    "match_score": 1.0
  },
  "Transferable Persona-Grounded Dialogues via Grounded Minimal Edits": {
    "openalex_id": "https://openalex.org/W3200036871",
    "publication_year": 2021,
    "cited_by_count": 14,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2143017621",
      "https://openalex.org/W2547875792",
      "https://openalex.org/W2578354947",
      "https://openalex.org/W2615146352",
      "https://openalex.org/W2617566453",
      "https://openalex.org/W2752047430",
      "https://openalex.org/W2798463315",
      "https://openalex.org/W2798931235",
      "https://openalex.org/W2801890059",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2885305518",
      "https://openalex.org/W2885421725",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2914442349",
      "https://openalex.org/W2945978556",
      "https://openalex.org/W2946393904",
      "https://openalex.org/W2952335829",
      "https://openalex.org/W2953039584",
      "https://openalex.org/W2953320089",
      "https://openalex.org/W2962793481",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2962851944",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2962989446",
      "https://openalex.org/W2963206679",
      "https://openalex.org/W2963366196",
      "https://openalex.org/W2963371754",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963506530",
      "https://openalex.org/W2963667126",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964321064",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2964529779",
      "https://openalex.org/W2965033324",
      "https://openalex.org/W2965718149",
      "https://openalex.org/W2970453125",
      "https://openalex.org/W2970562804",
      "https://openalex.org/W2970680405",
      "https://openalex.org/W2971277071",
      "https://openalex.org/W2979826702",
      "https://openalex.org/W2995197202",
      "https://openalex.org/W3004621150",
      "https://openalex.org/W3004665584",
      "https://openalex.org/W3015322406",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3034600233",
      "https://openalex.org/W3034720580",
      "https://openalex.org/W3035448310",
      "https://openalex.org/W3035695271",
      "https://openalex.org/W3093059841",
      "https://openalex.org/W3098824823",
      "https://openalex.org/W3099066892",
      "https://openalex.org/W3099852471",
      "https://openalex.org/W3100719877",
      "https://openalex.org/W3106007100",
      "https://openalex.org/W3111711122",
      "https://openalex.org/W3114595500",
      "https://openalex.org/W3116103312",
      "https://openalex.org/W3154272574",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W3173813266",
      "https://openalex.org/W3175039711",
      "https://openalex.org/W4287642224",
      "https://openalex.org/W4287781290",
      "https://openalex.org/W4288624561"
    ],
    "abstract": "Grounded dialogue models generate responses that are grounded on certain concepts. Limited by the distribution of grounded dialogue data, models trained on such data face the transferability challenges in terms of the data distribution and the type of grounded concepts. To address the challenges, we propose the grounded minimal editing framework, which minimally edits existing responses to be grounded on the given concept. Focusing on personas, we propose Grounded Minimal Editor (GME), which learns to edit by disentangling and recombining persona-related and persona-agnostic parts of the response. To evaluate persona-grounded minimal editing, we present the PersonaMi-nEdit dataset, and experimental results show that GME outperforms competitive baselines by a large margin. To evaluate the transferability, we experiment on the test set of BlendedSkillTalk and show that GME can edit dialogue models' responses to largely improve their persona consistency while preserving the use of knowledge and empathy.",
    "match_score": 1.0
  },
  "Bot-Adversarial Dialogue for Safe Conversational Agents": {
    "openalex_id": "https://openalex.org/W3171850892",
    "publication_year": 2021,
    "cited_by_count": 57,
    "referenced_works": [
      "https://openalex.org/W188088074",
      "https://openalex.org/W2001829221",
      "https://openalex.org/W2012378416",
      "https://openalex.org/W2083365005",
      "https://openalex.org/W2101900802",
      "https://openalex.org/W2160685721",
      "https://openalex.org/W2540646130",
      "https://openalex.org/W2595653137",
      "https://openalex.org/W2612675303",
      "https://openalex.org/W2740168486",
      "https://openalex.org/W2744575762",
      "https://openalex.org/W2791170418",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2942915765",
      "https://openalex.org/W2949678053",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2962977603",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2968297680",
      "https://openalex.org/W2971173235",
      "https://openalex.org/W2971883198",
      "https://openalex.org/W2979592845",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2995404354",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3002330681",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3030172318",
      "https://openalex.org/W3034850762",
      "https://openalex.org/W3037528277",
      "https://openalex.org/W3082884418",
      "https://openalex.org/W3100355250",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W3157298328",
      "https://openalex.org/W4243989635",
      "https://openalex.org/W4287900772",
      "https://openalex.org/W4288113479",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Jing Xu, Da Ju, Margaret Li, Y-Lan Boureau, Jason Weston, Emily Dinan. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.",
    "match_score": 1.0
  },
  "Different Strokes for Different Folks Investigating Appropriate Further Pre-training Approaches for Diverse Dialogue Tasks": {
    "openalex_id": "https://openalex.org/W3200506654",
    "publication_year": 2021,
    "cited_by_count": 1,
    "referenced_works": [
      "https://openalex.org/W2481265265",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2806600904",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2970597249",
      "https://openalex.org/W2971737394",
      "https://openalex.org/W3100110884"
    ],
    "abstract": "Loading models pre-trained on the large-scale corpus in the general domain and fine-tuning them on specific downstream tasks is gradually becoming a paradigm in Natural Language Processing. Previous investigations prove that introducing a further pre-training phase between pre-training and fine-tuning phases to adapt the model on the domain-specific unlabeled data can bring positive effects. However, most of these further pre-training works just keep running the conventional pre-training task, e.g., masked language model, which can be regarded as the domain adaptation to bridge the data distribution gap. After observing diverse downstream tasks, we suggest that different tasks may also need a further pre-training phase with appropriate training tasks to bridge the task formulation gap. To investigate this, we carry out a study for improving multiple task-oriented dialogue downstream tasks through designing various tasks at the further pre-training phase. The experiment shows that different downstream tasks prefer different further pre-training tasks, which have intrinsic correlation and most further pre-training tasks significantly improve certain target tasks rather than all. Our investigation indicates that it is of great importance and effectiveness to design appropriate further pre-training tasks modeling specific information that benefit downstream tasks. Besides, we present multiple constructive empirical conclusions for enhancing task-oriented dialogues.",
    "match_score": 0.9959183673469387
  },
  "Reference-Centric Models for Grounded Collaborative Dialogue": {
    "openalex_id": "https://openalex.org/W3201144093",
    "publication_year": 2021,
    "cited_by_count": 12,
    "referenced_works": [
      "https://openalex.org/W185375561",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1552206080",
      "https://openalex.org/W1576632330",
      "https://openalex.org/W1940872118",
      "https://openalex.org/W1974105891",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1983707534",
      "https://openalex.org/W1993979041",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2097204000",
      "https://openalex.org/W2097219834",
      "https://openalex.org/W2109878893",
      "https://openalex.org/W2110930288",
      "https://openalex.org/W2116245940",
      "https://openalex.org/W2125447031",
      "https://openalex.org/W2132271306",
      "https://openalex.org/W2133298256",
      "https://openalex.org/W2147880316",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2166490941",
      "https://openalex.org/W2166700048",
      "https://openalex.org/W2252033417",
      "https://openalex.org/W2264742718",
      "https://openalex.org/W2525032226",
      "https://openalex.org/W2571175805",
      "https://openalex.org/W2574790321",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2595784962",
      "https://openalex.org/W2604397416",
      "https://openalex.org/W2768661419",
      "https://openalex.org/W2769917417",
      "https://openalex.org/W2774005037",
      "https://openalex.org/W2806117557",
      "https://openalex.org/W2835434549",
      "https://openalex.org/W2950697717",
      "https://openalex.org/W2950801649",
      "https://openalex.org/W2951281980",
      "https://openalex.org/W2952316487",
      "https://openalex.org/W2952589943",
      "https://openalex.org/W2953064936",
      "https://openalex.org/W2959918500",
      "https://openalex.org/W2960994197",
      "https://openalex.org/W2962727507",
      "https://openalex.org/W2963109634",
      "https://openalex.org/W2963170138",
      "https://openalex.org/W2963217826",
      "https://openalex.org/W2963318456",
      "https://openalex.org/W2963907629",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964183327",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964260310",
      "https://openalex.org/W2970340522",
      "https://openalex.org/W2971077754",
      "https://openalex.org/W2998108220",
      "https://openalex.org/W3029418112",
      "https://openalex.org/W3098158595",
      "https://openalex.org/W3104952102",
      "https://openalex.org/W3106007100",
      "https://openalex.org/W3135812974",
      "https://openalex.org/W4249013746",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4297795721"
    ],
    "abstract": "We present a grounded neural dialogue model that successfully collaborates with people in a partially-observable reference game. We focus on a setting where two agents each observe an overlapping part of a world context and need to identify and agree on some object they share. Therefore, the agents should pool their information and communicate pragmatically to solve the task. Our dialogue agent accurately grounds referents from the partner\u2019s utterances using a structured reference resolver, conditions on these referents using a recurrent memory, and uses a pragmatic generation procedure to ensure the partner can resolve the references the agent produces. We evaluate on the OneCommon spatial grounding dialogue task (Udagawa and Aizawa 2019), involving a number of dots arranged on a board with continuously varying positions, sizes, and shades. Our agent substantially outperforms the previous state of the art for the task, obtaining a 20% relative improvement in successful task completion in self-play evaluations and a 50% relative improvement in success in human evaluations.",
    "match_score": 1.0
  },
  "RAST Domain-Robust Dialogue Rewriting as Sequence Tagging": {
    "openalex_id": "https://openalex.org/W3212307878",
    "publication_year": 2021,
    "cited_by_count": 1,
    "referenced_works": [
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2888302696",
      "https://openalex.org/W2912904516",
      "https://openalex.org/W2949769095",
      "https://openalex.org/W2952855649",
      "https://openalex.org/W2962944953",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963620441",
      "https://openalex.org/W2963748441",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964223283",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2970391482",
      "https://openalex.org/W2970744242",
      "https://openalex.org/W2970960706",
      "https://openalex.org/W2970996870",
      "https://openalex.org/W3035148359",
      "https://openalex.org/W3035566559",
      "https://openalex.org/W3089006046",
      "https://openalex.org/W3094437659",
      "https://openalex.org/W3098694757",
      "https://openalex.org/W3100063812",
      "https://openalex.org/W3105388824",
      "https://openalex.org/W3153491684",
      "https://openalex.org/W3163840908",
      "https://openalex.org/W3176413694"
    ],
    "abstract": "The task of dialogue rewriting aims to reconstruct the latest dialogue utterance by copying the missing content from the dialogue context. Until now, the existing models for this task suffer from the robustness issue, i.e., performances drop dramatically when testing on a different dataset. We address this robustness issue by proposing a novel sequence-tagging-based model so that the search space is significantly reduced, yet the core of this task is still well covered. As a common issue of most tagging models for text generation, the model\u2019s outputs may lack fluency. To alleviate this issue, we inject the loss signal from BLEU or GPT-2 under a REINFORCE framework. Experiments show huge improvements of our model over the current state-of-the-art systems when transferring to another dataset.",
    "match_score": 0.991304347826087
  },
  "\u201cNice Try, Kiddo\u201d Investigating Ad Hominems in Dialogue Responses": {
    "openalex_id": "https://openalex.org/W3166704354",
    "publication_year": 2021,
    "cited_by_count": 37,
    "referenced_works": [
      "https://openalex.org/W78136081",
      "https://openalex.org/W80056832",
      "https://openalex.org/W249736312",
      "https://openalex.org/W1071251684",
      "https://openalex.org/W1506224928",
      "https://openalex.org/W1814822231",
      "https://openalex.org/W1969501657",
      "https://openalex.org/W1997326096",
      "https://openalex.org/W2073315954",
      "https://openalex.org/W2119769989",
      "https://openalex.org/W2145162117",
      "https://openalex.org/W2151245229",
      "https://openalex.org/W2160685721",
      "https://openalex.org/W2340954483",
      "https://openalex.org/W2540646130",
      "https://openalex.org/W2806344213",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2938704169",
      "https://openalex.org/W2949089361",
      "https://openalex.org/W2949413855",
      "https://openalex.org/W2949777421",
      "https://openalex.org/W2962768347",
      "https://openalex.org/W2963096510",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963352809",
      "https://openalex.org/W2963667126",
      "https://openalex.org/W2964029788",
      "https://openalex.org/W2966746916",
      "https://openalex.org/W2970395295",
      "https://openalex.org/W2971173235",
      "https://openalex.org/W2971307358",
      "https://openalex.org/W2982756474",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2996287690",
      "https://openalex.org/W2997195635",
      "https://openalex.org/W3013226821",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3034937117",
      "https://openalex.org/W3035540807",
      "https://openalex.org/W3085190015",
      "https://openalex.org/W3099246072",
      "https://openalex.org/W3099635335",
      "https://openalex.org/W3099872554",
      "https://openalex.org/W3100355250",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W4289236291"
    ],
    "abstract": "Emily Sheng, Kai-Wei Chang, Prem Natarajan, Nanyun Peng. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.",
    "match_score": 0.9923664122137404
  },
  "A Three-Stage Learning Framework for Low-Resource Knowledge-Grounded Dialogue Generation": {
    "openalex_id": "https://openalex.org/W3198455100",
    "publication_year": 2021,
    "cited_by_count": 24,
    "referenced_works": [
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2107598941",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2143017621",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2768282280",
      "https://openalex.org/W2795571593",
      "https://openalex.org/W2891826200",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2945260553",
      "https://openalex.org/W2949769095",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2951508633",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963248455",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964458951",
      "https://openalex.org/W2971236040",
      "https://openalex.org/W2971274815",
      "https://openalex.org/W2972916088",
      "https://openalex.org/W2979478117",
      "https://openalex.org/W2979826702",
      "https://openalex.org/W2982399380",
      "https://openalex.org/W2995183464",
      "https://openalex.org/W2996227762",
      "https://openalex.org/W3007008027",
      "https://openalex.org/W3034238904",
      "https://openalex.org/W3034758256",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3039017601",
      "https://openalex.org/W3043859333",
      "https://openalex.org/W3098824823",
      "https://openalex.org/W3103100151",
      "https://openalex.org/W3104123491",
      "https://openalex.org/W3104777900",
      "https://openalex.org/W3130164045",
      "https://openalex.org/W3156789018",
      "https://openalex.org/W3172448816",
      "https://openalex.org/W4251372957",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Neural conversation models have shown great potentials towards generating fluent and informative responses by introducing external background knowledge. Nevertheless, it is laborious to construct such knowledge-grounded dialogues, and existing models usually perform poorly when transfer to new domains with limited training samples. Therefore, building a knowledge-grounded dialogue system under the low-resource setting is a still crucial issue. In this paper, we propose a novel three-stage learning framework based on weakly supervised learning which benefits from large scale ungrounded dialogues and unstructured knowledge base. To better cooperate with this framework, we devise a variant of Transformer with decoupled decoder which facilitates the disentangled learning of response generation and knowledge incorporation. Evaluation results on two benchmarks indicate that our approach can outperform other state-of-the-art methods with less training data, and even in zero-resource scenario, our approach still performs well.",
    "match_score": 1.0
  },
  "CoLV A Collaborative Latent Variable Model for Knowledge-Grounded Dialogue Generation": {
    "openalex_id": "https://openalex.org/W3213758350",
    "publication_year": 2021,
    "cited_by_count": 15,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1965555277",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2547875792",
      "https://openalex.org/W2548228487",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2794557536",
      "https://openalex.org/W2799176105",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2891103209",
      "https://openalex.org/W2891826200",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2949769095",
      "https://openalex.org/W2949782788",
      "https://openalex.org/W2951114218",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963241825",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963713328",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963945575",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964458951",
      "https://openalex.org/W2970971581",
      "https://openalex.org/W2995183464",
      "https://openalex.org/W2997094605",
      "https://openalex.org/W2997260297",
      "https://openalex.org/W2997896082",
      "https://openalex.org/W3007008027",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3032717904",
      "https://openalex.org/W3034739704",
      "https://openalex.org/W3034758256",
      "https://openalex.org/W3034999754",
      "https://openalex.org/W3035072597",
      "https://openalex.org/W3035148359",
      "https://openalex.org/W3035500185",
      "https://openalex.org/W3035755323",
      "https://openalex.org/W3103100151",
      "https://openalex.org/W3103691705",
      "https://openalex.org/W3104123491",
      "https://openalex.org/W3172448816",
      "https://openalex.org/W3176584016",
      "https://openalex.org/W3176956817",
      "https://openalex.org/W4295312788",
      "https://openalex.org/W4385245566",
      "https://openalex.org/W4391602018"
    ],
    "abstract": "Knowledge-grounded dialogue generation has achieved promising performance with the engagement of external knowledge sources. Typical approaches towards this task usually perform relatively independent two sub-tasks, i.e., knowledge selection and knowledge-aware response generation. In this paper, in order to improve the diversity of both knowledge selection and knowledge-aware response generation, we propose a collaborative latent variable (CoLV) model to integrate these two aspects simultaneously in separate yet collaborative latent spaces, so as to capture the inherent correlation between knowledge selection and response generation. During generation, our proposed model firstly draws knowledge candidate from the latent space conditioned on the dialogue context, and then samples a response from another collaborative latent space conditioned on both the context and the selected knowledge. Experimental results on two widely-used knowledge-grounded dialogue datasets show that our model outperforms previous methods on both knowledge selection and response generation.",
    "match_score": 0.9941520467836257
  },
  "A Comparative Study on Schema-Guided Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W3158235155",
    "publication_year": 2021,
    "cited_by_count": 10,
    "referenced_works": [
      "https://openalex.org/W1801721664",
      "https://openalex.org/W1969152782",
      "https://openalex.org/W1978347212",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2468710617",
      "https://openalex.org/W2594229957",
      "https://openalex.org/W2784070054",
      "https://openalex.org/W2798392716",
      "https://openalex.org/W2806482527",
      "https://openalex.org/W2806600904",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2898700502",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2971737394",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2985067290",
      "https://openalex.org/W2995289474",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W3015637204",
      "https://openalex.org/W3021016503",
      "https://openalex.org/W3023027202",
      "https://openalex.org/W3024509506",
      "https://openalex.org/W3030754432",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3044597194",
      "https://openalex.org/W3045689439",
      "https://openalex.org/W3045703328",
      "https://openalex.org/W3082793928",
      "https://openalex.org/W3090305424",
      "https://openalex.org/W3097392354",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W3160818482",
      "https://openalex.org/W4287795696",
      "https://openalex.org/W4288094254",
      "https://openalex.org/W4288288848",
      "https://openalex.org/W4322614701"
    ],
    "abstract": "Frame-based state representation is widely used in modern task-oriented dialog systems to model user intentions and slot values. However, a fixed design of domain ontology makes it difficult to extend to new services and APIs. Recent work proposed to use natural language descriptions to define the domain ontology instead of tag names for each intent or slot, thus offering a dynamic set of schema. In this paper, we conduct in-depth comparative studies to understand the use of natural language description for schema in dialog state tracking. Our discussion mainly covers three aspects: encoder architectures, impact of supplementary training, and effective schema description styles. We introduce a set of newly designed bench-marking descriptions and reveal the model robustness on both homogeneous and heterogeneous description styles in training and evaluation.",
    "match_score": 1.0
  },
  "Simple Conversational Data Augmentation for Semi-supervised Abstractive Dialogue Summarization": {
    "openalex_id": "https://openalex.org/W3212362289",
    "publication_year": 2021,
    "cited_by_count": 31,
    "referenced_works": [
      "https://openalex.org/W26963497",
      "https://openalex.org/W1983707534",
      "https://openalex.org/W1990334093",
      "https://openalex.org/W2044120473",
      "https://openalex.org/W2088622183",
      "https://openalex.org/W2101210369",
      "https://openalex.org/W2111316763",
      "https://openalex.org/W2161068821",
      "https://openalex.org/W2327037637",
      "https://openalex.org/W2530816535",
      "https://openalex.org/W2888482885",
      "https://openalex.org/W2889326796",
      "https://openalex.org/W2889984458",
      "https://openalex.org/W2890719433",
      "https://openalex.org/W2891602716",
      "https://openalex.org/W2898695436",
      "https://openalex.org/W2912762447",
      "https://openalex.org/W2936695845",
      "https://openalex.org/W2940009958",
      "https://openalex.org/W2949530332",
      "https://openalex.org/W2951970475",
      "https://openalex.org/W2952229419",
      "https://openalex.org/W2952890017",
      "https://openalex.org/W2962369866",
      "https://openalex.org/W2963126845",
      "https://openalex.org/W2963216553",
      "https://openalex.org/W2963545917",
      "https://openalex.org/W2963600562",
      "https://openalex.org/W2963795756",
      "https://openalex.org/W2963969878",
      "https://openalex.org/W2963983466",
      "https://openalex.org/W2963997607",
      "https://openalex.org/W2964089584",
      "https://openalex.org/W2964159205",
      "https://openalex.org/W2970418174",
      "https://openalex.org/W2971296908",
      "https://openalex.org/W2976223659",
      "https://openalex.org/W2989743967",
      "https://openalex.org/W2995746049",
      "https://openalex.org/W2996403597",
      "https://openalex.org/W3006647218",
      "https://openalex.org/W3007685714",
      "https://openalex.org/W3008323921",
      "https://openalex.org/W3010293452",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3035160371",
      "https://openalex.org/W3035542229",
      "https://openalex.org/W3085629518",
      "https://openalex.org/W3089659770",
      "https://openalex.org/W3092993357",
      "https://openalex.org/W3094217371",
      "https://openalex.org/W3100560913",
      "https://openalex.org/W3100742171",
      "https://openalex.org/W3102136264",
      "https://openalex.org/W3102903864",
      "https://openalex.org/W3104257895",
      "https://openalex.org/W3111436535",
      "https://openalex.org/W3154981967",
      "https://openalex.org/W3162734203",
      "https://openalex.org/W3167002470",
      "https://openalex.org/W3169565655",
      "https://openalex.org/W3171388604",
      "https://openalex.org/W3174150157",
      "https://openalex.org/W4241891521",
      "https://openalex.org/W4287636206",
      "https://openalex.org/W4287829148",
      "https://openalex.org/W4327656064",
      "https://openalex.org/W4392143959"
    ],
    "abstract": "ive conversation summarization has received growing attention while most current state-of-the-art summarization models heavily rely on human-annotated summaries. To reduce the dependence on labeled summaries, in this work, we present a simple yet effective set of Conversational Data Augmentation (CODA) methods for semi-supervised abstractive conversation summarization, such as random swapping/deletion to perturb the discourse relations inside conversations, dialogue-acts-guided insertion to interrupt the development of conversations, and conditional-generation-based substitution to substitute utterances with their paraphrases generated based on the conversation context. To further utilize unlabeled conversations, we combine CODA with two-stage noisy self-training where we first pre-train the summarization model on unlabeled conversations with pseudo summaries and then fine-tune it on labeled conversations. Experiments conducted on the recent conversation summarization datasets demonstrate the effectiveness of our methods over several state-of-the-art data augmentation baselines.",
    "match_score": 1.0
  },
  "Thinking Clearly, Talking Fast Concept-Guided Non-Autoregressive Generation for Open-Domain Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3197754599",
    "publication_year": 2021,
    "cited_by_count": 27,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2159637323",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2554952599",
      "https://openalex.org/W2767206889",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2890560993",
      "https://openalex.org/W2891826200",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2900629321",
      "https://openalex.org/W2920538220",
      "https://openalex.org/W2925513271",
      "https://openalex.org/W2949644922",
      "https://openalex.org/W2949769095",
      "https://openalex.org/W2950299257",
      "https://openalex.org/W2950457956",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962896208",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963434219",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2963986868",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964587107",
      "https://openalex.org/W2968297680",
      "https://openalex.org/W2970832665",
      "https://openalex.org/W2985694911",
      "https://openalex.org/W2995404354",
      "https://openalex.org/W2997219446",
      "https://openalex.org/W2997260297",
      "https://openalex.org/W2997300509",
      "https://openalex.org/W3005768470",
      "https://openalex.org/W3034548376",
      "https://openalex.org/W3034569646",
      "https://openalex.org/W3034696087",
      "https://openalex.org/W3034720580",
      "https://openalex.org/W3039805635",
      "https://openalex.org/W3098295156",
      "https://openalex.org/W3114869109",
      "https://openalex.org/W3167303745",
      "https://openalex.org/W4294170691",
      "https://openalex.org/W4322614756",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Human dialogue contains evolving concepts, and speakers naturally associate multiple concepts to compose a response. However, current dialogue models with the seq2seq framework lack the ability to effectively manage concept transitions and can hardly introduce multiple concepts to responses in a sequential decoding manner. To facilitate a controllable and coherent dialogue, in this work, we devise a concept-guided non-autoregressive model (CG-nAR) for open-domain dialogue generation. The proposed model comprises a multi-concept planning module that learns to identify multiple associated concepts from a concept graph and a customized Insertion Transformer that performs concept-guided non-autoregressive generation to complete a response. The experimental results on two public datasets show that CG-nAR can produce diverse and coherent responses, outperforming state-of-the-art baselines in both automatic and human evaluations with substantially faster inference speed.",
    "match_score": 0.9953917050691244
  },
  "Effective Sequence-to-Sequence Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W3197133421",
    "publication_year": 2021,
    "cited_by_count": 0,
    "referenced_works": [
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2606722458",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2804010326",
      "https://openalex.org/W2808093377",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2928941594",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2951216772",
      "https://openalex.org/W2951392882",
      "https://openalex.org/W2962911098",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2988647680",
      "https://openalex.org/W3004304303",
      "https://openalex.org/W3021016503",
      "https://openalex.org/W3021096583",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3034715004",
      "https://openalex.org/W3044597194",
      "https://openalex.org/W3082274269",
      "https://openalex.org/W3088415854",
      "https://openalex.org/W3099140977",
      "https://openalex.org/W3103469330",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W3135087612",
      "https://openalex.org/W3151066410",
      "https://openalex.org/W3155308379",
      "https://openalex.org/W3156697766",
      "https://openalex.org/W3159914836",
      "https://openalex.org/W3188964051"
    ],
    "abstract": "Sequence-to-sequence models have been applied to a wide variety of NLP tasks, but how to properly use them for dialogue state tracking has not been systematically investigated. In this paper, we study this problem from the perspectives of pre-training objectives as well as the formats of context representations. We demonstrate that the choice of pre-training objective makes a significant difference to the state tracking quality. In particular, we find that masked span prediction is more effective than auto-regressive language modeling. We also explore using Pegasus, a span prediction-based pre-training objective for text summarization, for the state tracking model. We found that pre-training for the seemingly distant summarization task works surprisingly well for dialogue state tracking. In addition, we found that while recurrent state context representation works also reasonably well, the model may have a hard time recovering from earlier mistakes. We conducted experiments on the MultiWOZ 2.1-2.4, WOZ 2.0, and DSTC2 datasets with consistent observations.",
    "match_score": 1.0
  },
  "Looking for Confirmations An Effective and Human-Like Visual Dialogue Strategy": {
    "openalex_id": "https://openalex.org/W3200001502",
    "publication_year": 2021,
    "cited_by_count": 6,
    "referenced_works": [
      "https://openalex.org/W860478996",
      "https://openalex.org/W1629317078",
      "https://openalex.org/W1861492603",
      "https://openalex.org/W1986776260",
      "https://openalex.org/W2017515822",
      "https://openalex.org/W2041945486",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2142653990",
      "https://openalex.org/W2194775991",
      "https://openalex.org/W2429300145",
      "https://openalex.org/W2558809543",
      "https://openalex.org/W2903036216",
      "https://openalex.org/W2938704169",
      "https://openalex.org/W2945087694",
      "https://openalex.org/W2953251345",
      "https://openalex.org/W2962735233",
      "https://openalex.org/W2963014658",
      "https://openalex.org/W2988617410",
      "https://openalex.org/W2996287690",
      "https://openalex.org/W2997117909",
      "https://openalex.org/W3045998699",
      "https://openalex.org/W3107855336",
      "https://openalex.org/W3154811600",
      "https://openalex.org/W3156736277",
      "https://openalex.org/W3184537908",
      "https://openalex.org/W4239338037",
      "https://openalex.org/W4247986398"
    ],
    "abstract": "Generating goal-oriented questions in Visual Dialogue tasks is a challenging and longstanding problem. State-Of-The-Art systems are shown to generate questions that, although grammatically correct, often lack an effective strategy and sound unnatural to humans. Inspired by the cognitive literature on information search and cross-situational word learning, we design Confirm-it, a model based on a beam search re-ranking algorithm that guides an effective goal-oriented strategy by asking questions that confirm the model{'}s conjecture about the referent. We take the GuessWhat?! game as a case-study. We show that dialogues generated by Confirm-it are more natural and effective than beam search decoding without re-ranking",
    "match_score": 0.9936305732484076
  },
  "Clipping Loops for Sample-Efficient Dialogue Policy Optimisation": {
    "openalex_id": "https://openalex.org/W3170644973",
    "publication_year": 2021,
    "cited_by_count": 2,
    "referenced_works": [
      "https://openalex.org/W1191599655",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2117989772",
      "https://openalex.org/W2120045257",
      "https://openalex.org/W2396229782",
      "https://openalex.org/W2408200822",
      "https://openalex.org/W2559038528",
      "https://openalex.org/W2736601468",
      "https://openalex.org/W2739936944",
      "https://openalex.org/W2772217324",
      "https://openalex.org/W2783543950",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2889186204",
      "https://openalex.org/W2947212824",
      "https://openalex.org/W2949476504",
      "https://openalex.org/W2950314731",
      "https://openalex.org/W2963064439",
      "https://openalex.org/W2963433587",
      "https://openalex.org/W2963567240",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W3016142228",
      "https://openalex.org/W3103837004",
      "https://openalex.org/W4297806413",
      "https://openalex.org/W4306716473"
    ],
    "abstract": "Training dialogue agents requires a large number of interactions with users: agents have no idea about which responses are bad among a lengthy dialogue. In this paper, we propose loop-clipping policy optimisation (LCPO) to eliminate useless responses. LCPO consists of two stages: loop clipping and advantage clipping. In loop clipping, we clip off useless responses (called loops) from dialogue history (called trajectories). The clipped trajectories are more succinct than the original ones, and the estimation of state-value is more accurate. Second, in advantage clipping, we estimate and clip the advantages of useless responses and normal ones separately. The clipped advantage distinguish useless actions from others and reduce the probabilities of useless actions efficiently. In experiments on Cambridge Restaurant Dialogue System, LCPO uses only 260 training dialogues to achieve 80% success rate, while PPO baseline requires 2160 dialogues. Besides, LCPO receives 3.7/5 scores in human evaluation where the agent interactively collects 100 real-user dialogues in training phase.",
    "match_score": 1.0
  },
  "Low-Resource Dialogue Summarization with Domain-Agnostic Multi-Source Pretraining": {
    "openalex_id": "https://openalex.org/W3196326437",
    "publication_year": 2021,
    "cited_by_count": 18,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1531174292",
      "https://openalex.org/W1544827683",
      "https://openalex.org/W1566289585",
      "https://openalex.org/W1861492603",
      "https://openalex.org/W1882958252",
      "https://openalex.org/W1976975519",
      "https://openalex.org/W2014571624",
      "https://openalex.org/W2015895495",
      "https://openalex.org/W2025768430",
      "https://openalex.org/W2033839684",
      "https://openalex.org/W2125420881",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2161068821",
      "https://openalex.org/W2187089797",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2888482885",
      "https://openalex.org/W2908336025",
      "https://openalex.org/W2913407944",
      "https://openalex.org/W2921522814",
      "https://openalex.org/W2940579548",
      "https://openalex.org/W2949615363",
      "https://openalex.org/W2952809536",
      "https://openalex.org/W2952890017",
      "https://openalex.org/W2955471745",
      "https://openalex.org/W2962704246",
      "https://openalex.org/W2962785754",
      "https://openalex.org/W2962849707",
      "https://openalex.org/W2962965405",
      "https://openalex.org/W2962985882",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963521413",
      "https://openalex.org/W2963826681",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964288227",
      "https://openalex.org/W2970060597",
      "https://openalex.org/W2970419734",
      "https://openalex.org/W2972916088",
      "https://openalex.org/W2982399380",
      "https://openalex.org/W2989743967",
      "https://openalex.org/W2996264288",
      "https://openalex.org/W3034715004",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3085629518",
      "https://openalex.org/W3094217371",
      "https://openalex.org/W3098562101",
      "https://openalex.org/W3100560913",
      "https://openalex.org/W3102136264",
      "https://openalex.org/W3105245805",
      "https://openalex.org/W3110659220",
      "https://openalex.org/W3111693342",
      "https://openalex.org/W3116498179",
      "https://openalex.org/W3142970963",
      "https://openalex.org/W3169565655",
      "https://openalex.org/W3171639395",
      "https://openalex.org/W4287636206",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "With the rapid increase in the volume of dialogue data from daily life, there is a growing demand for dialogue summarization. Unfortunately, training a large summarization model is generally infeasible due to the inadequacy of dialogue data with annotated summaries. Most existing works for low-resource dialogue summarization directly pretrain models in other domains, e.g., the news domain, but they generally neglect the huge difference between dialogues and conventional articles. To bridge the gap between out-of-domain pretraining and in-domain fine-tuning, in this work, we propose a multi-source pretraining paradigm to better leverage the external summary data. Specifically, we exploit large-scale in-domain non-summary data to separately pretrain the dialogue encoder and the summary decoder. The combined encoder-decoder model is then pretrained on the out-of-domain summary data using adversarial critics, aiming to facilitate domain-agnostic summarization. The experimental results on two public datasets show that with only limited training data, our approach achieves competitive performance and generalizes well in different dialogue scenarios.",
    "match_score": 1.0
  },
  "Zero-Shot Dialogue State Tracking via Cross-Task Transfer": {
    "openalex_id": "https://openalex.org/W3200546165",
    "publication_year": 2021,
    "cited_by_count": 2,
    "referenced_works": [
      "https://openalex.org/W1598178035",
      "https://openalex.org/W1969152782",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2557764419",
      "https://openalex.org/W2606964149",
      "https://openalex.org/W2609826708",
      "https://openalex.org/W2784070054",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2889787757",
      "https://openalex.org/W2908510526",
      "https://openalex.org/W2912904516",
      "https://openalex.org/W2912924812",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2950577311",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2963323070",
      "https://openalex.org/W2963339397",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963748441",
      "https://openalex.org/W2963925437",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2982756474",
      "https://openalex.org/W2987442863",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W2988421999",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W3008186200",
      "https://openalex.org/W3015637204",
      "https://openalex.org/W3016625483",
      "https://openalex.org/W3021016503",
      "https://openalex.org/W3021096583",
      "https://openalex.org/W3030754432",
      "https://openalex.org/W3033461281",
      "https://openalex.org/W3045703328",
      "https://openalex.org/W3082274269",
      "https://openalex.org/W3091355780",
      "https://openalex.org/W3094479119",
      "https://openalex.org/W3099655892",
      "https://openalex.org/W3100110884",
      "https://openalex.org/W3100128199",
      "https://openalex.org/W3115336344",
      "https://openalex.org/W3119438769",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W3119822474",
      "https://openalex.org/W3168491067",
      "https://openalex.org/W3170632963",
      "https://openalex.org/W3189817881"
    ],
    "abstract": "Zero-shot transfer learning for dialogue state tracking (DST) enables us to handle a variety of task-oriented dialogue domains without the expense of collecting in-domain data. In this work, we propose to transfer the \\textit{cross-task} knowledge from general question answering (QA) corpora for the zero-shot DST task. Specifically, we propose TransferQA, a transferable generative QA model that seamlessly combines extractive QA and multi-choice QA via a text-to-text transformer framework, and tracks both categorical slots and non-categorical slots in DST. In addition, we introduce two effective ways to construct unanswerable questions, namely, negative question sampling and context truncation, which enable our model to handle \"none\" value slots in the zero-shot DST setting. The extensive experiments show that our approaches substantially improve the existing zero-shot and few-shot results on MultiWoz. Moreover, compared to the fully trained baseline on the Schema-Guided Dialogue dataset, our approach shows better generalization ability in unseen domains.",
    "match_score": 1.0
  },
  "Just Say No Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts": {
    "openalex_id": "https://openalex.org/W3194113117",
    "publication_year": 2021,
    "cited_by_count": 49,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W136732505",
      "https://openalex.org/W205930466",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1840435438",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2281420995",
      "https://openalex.org/W2505005027",
      "https://openalex.org/W2595653137",
      "https://openalex.org/W2607700676",
      "https://openalex.org/W2741229899",
      "https://openalex.org/W2758912220",
      "https://openalex.org/W2785615365",
      "https://openalex.org/W2791170418",
      "https://openalex.org/W2884561390",
      "https://openalex.org/W2892217998",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2910580498",
      "https://openalex.org/W2912102236",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2916719435",
      "https://openalex.org/W2916772188",
      "https://openalex.org/W2938704169",
      "https://openalex.org/W2949678053",
      "https://openalex.org/W2951583236",
      "https://openalex.org/W2951737564",
      "https://openalex.org/W2962753250",
      "https://openalex.org/W2962875044",
      "https://openalex.org/W2962977603",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963351448",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963549959",
      "https://openalex.org/W2963691377",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963955897",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2970269073",
      "https://openalex.org/W2970395295",
      "https://openalex.org/W2971150411",
      "https://openalex.org/W2971173235",
      "https://openalex.org/W2974587494",
      "https://openalex.org/W2979826702",
      "https://openalex.org/W2982756474",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2996287690",
      "https://openalex.org/W2997510038",
      "https://openalex.org/W3002330681",
      "https://openalex.org/W3022992164",
      "https://openalex.org/W3034238904",
      "https://openalex.org/W3034600233",
      "https://openalex.org/W3034937117",
      "https://openalex.org/W3034951181",
      "https://openalex.org/W3037528277",
      "https://openalex.org/W3093233911",
      "https://openalex.org/W3098824823",
      "https://openalex.org/W3099635335",
      "https://openalex.org/W3100355250",
      "https://openalex.org/W3100355408",
      "https://openalex.org/W3103639864",
      "https://openalex.org/W3104152666",
      "https://openalex.org/W3106460864",
      "https://openalex.org/W3126763054",
      "https://openalex.org/W3133423348",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W3155742828",
      "https://openalex.org/W3175432533",
      "https://openalex.org/W3177468621",
      "https://openalex.org/W3186288536",
      "https://openalex.org/W4292779060"
    ],
    "abstract": "Dialogue models trained on human conversations inadvertently learn to generate toxic responses. In addition to producing explicitly offensive utterances, these models can also implicitly insult a group or individual by aligning themselves with an offensive statement. To better understand the dynamics of contextually offensive language, we investigate the stance of dialogue model responses in offensive Reddit conversations. Specifically, we create ToxiChat, a crowd-annotated dataset of 2,000 Reddit threads and model responses labeled with offensive language and stance. Our analysis reveals that 42% of human responses agree with toxic comments, whereas only 13% agree with safe comments. This undesirable behavior is learned by neural dialogue models, such as DialoGPT, which we show are two times more likely to agree with offensive comments. To enable automatic detection of offensive language, we fine-tuned transformer-based classifiers on ToxiChat that achieve 0.71 F1 for offensive labels and 0.53 Macro-F1 for stance labels. Finally, we quantify the effectiveness of controllable text generation (CTG) methods to mitigate the tendency of neural dialogue models to agree with offensive comments. Compared to the baseline, our best CTG model achieves a 19% reduction in agreement with offensive comments and produces 29% fewer offensive replies. Our work highlights the need for further efforts to characterize and analyze inappropriate behavior in dialogue models, in order to help make them safer.",
    "match_score": 0.9940828402366864
  },
  "CSDS A Fine-Grained Chinese Dataset for Customer Service Dialogue Summarization": {
    "openalex_id": "https://openalex.org/W3198548340",
    "publication_year": 2021,
    "cited_by_count": 20,
    "referenced_works": [
      "https://openalex.org/W42510783",
      "https://openalex.org/W1487886355",
      "https://openalex.org/W1569447338",
      "https://openalex.org/W1591607137",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2158751803",
      "https://openalex.org/W2160204597",
      "https://openalex.org/W2182572585",
      "https://openalex.org/W2574535369",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2781963152",
      "https://openalex.org/W2842624112",
      "https://openalex.org/W2888482885",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2936695845",
      "https://openalex.org/W2952138241",
      "https://openalex.org/W2962985882",
      "https://openalex.org/W2963045354",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963929190",
      "https://openalex.org/W2964211782",
      "https://openalex.org/W2970419734",
      "https://openalex.org/W2970785793",
      "https://openalex.org/W2971139875",
      "https://openalex.org/W2985237994",
      "https://openalex.org/W2989743967",
      "https://openalex.org/W2996403597",
      "https://openalex.org/W3031414376",
      "https://openalex.org/W3035259249",
      "https://openalex.org/W3098562101",
      "https://openalex.org/W3109862485",
      "https://openalex.org/W3110131742",
      "https://openalex.org/W3110659220",
      "https://openalex.org/W3111693342",
      "https://openalex.org/W3116079511",
      "https://openalex.org/W3142970963",
      "https://openalex.org/W3159259047",
      "https://openalex.org/W3164029002",
      "https://openalex.org/W3169942382",
      "https://openalex.org/W3171639395"
    ],
    "abstract": "Dialogue summarization has drawn much attention recently. Especially in the customer service domain, agents could use dialogue summaries to help boost their works by quickly knowing customer's issues and service progress. These applications require summaries to contain the perspective of a single speaker and have a clear topic flow structure, while neither are available in existing datasets. Therefore, in this paper, we introduce a novel Chinese dataset for Customer Service Dialogue Summarization (CSDS). CSDS improves the abstractive summaries in two aspects: (1) In addition to the overall summary for the whole dialogue, role-oriented summaries are also provided to acquire different speakers' viewpoints. (2) All the summaries sum up each topic separately, thus containing the topic-level structure of the dialogue. We define tasks in CSDS as generating the overall summary and different role-oriented summaries for a given dialogue. Next, we compare various summarization methods on CSDS, and experiment results show that existing methods are prone to generate redundant and incoherent summaries. Besides, the performance becomes much worse when analyzing the performance on role-oriented summaries and topic structures. We hope that this study could benchmark Chinese dialogue summarization and benefit further studies.",
    "match_score": 0.9937106918238994
  },
  "DIALKI Knowledge Identification in Conversational Systems through Dialogue-Document Contextualization": {
    "openalex_id": "https://openalex.org/W3199691415",
    "publication_year": 2021,
    "cited_by_count": 22,
    "referenced_works": [
      "https://openalex.org/W2563734883",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2888302696",
      "https://openalex.org/W2891103209",
      "https://openalex.org/W2891304738",
      "https://openalex.org/W2891826200",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2951508633",
      "https://openalex.org/W2951976932",
      "https://openalex.org/W2962985038",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963532001",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2964223283",
      "https://openalex.org/W2964458951",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2971008823",
      "https://openalex.org/W2979478117",
      "https://openalex.org/W2979826702",
      "https://openalex.org/W2989312920",
      "https://openalex.org/W2995183464",
      "https://openalex.org/W3015468748",
      "https://openalex.org/W3021582395",
      "https://openalex.org/W3023790734",
      "https://openalex.org/W3034758256",
      "https://openalex.org/W3034951181",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3035187010",
      "https://openalex.org/W3098824823",
      "https://openalex.org/W3099590177",
      "https://openalex.org/W3099700870",
      "https://openalex.org/W3103691705",
      "https://openalex.org/W3104777900",
      "https://openalex.org/W3171847983",
      "https://openalex.org/W4287824654",
      "https://openalex.org/W4299567010",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Identifying relevant knowledge to be used in conversational systems that are grounded in long documents is critical to effective response generation. We introduce a knowledge identification model that leverages the document structure to provide dialogue-contextualized passage encodings and better locate knowledge relevant to the conversation. An auxiliary loss captures the history of dialogue-document connections. We demonstrate the effectiveness of our model on two document-grounded conversational datasets and provide analyses showing generalization to unseen documents and long dialogue contexts.",
    "match_score": 0.9950738916256158
  },
  "Uncertainty Measures in Neural Belief Tracking and the Effects on Dialogue Policy Performance": {
    "openalex_id": "https://openalex.org/W3196636639",
    "publication_year": 2021,
    "cited_by_count": 8,
    "referenced_works": [
      "https://openalex.org/W10050918",
      "https://openalex.org/W1632484548",
      "https://openalex.org/W1821462560",
      "https://openalex.org/W2015936967",
      "https://openalex.org/W2047335008",
      "https://openalex.org/W2055537935",
      "https://openalex.org/W2108806737",
      "https://openalex.org/W2117555338",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2129405869",
      "https://openalex.org/W2147933644",
      "https://openalex.org/W2154740693",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2492505811",
      "https://openalex.org/W2736601468",
      "https://openalex.org/W2788907134",
      "https://openalex.org/W2889424988",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2943171176",
      "https://openalex.org/W2948194985",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963178340",
      "https://openalex.org/W2963215553",
      "https://openalex.org/W2963341924",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964059111",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964180249",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2970828515",
      "https://openalex.org/W2970859221",
      "https://openalex.org/W2972777589",
      "https://openalex.org/W2995464762",
      "https://openalex.org/W2996184071",
      "https://openalex.org/W3003199999",
      "https://openalex.org/W3006511999",
      "https://openalex.org/W3021096583",
      "https://openalex.org/W3030754432",
      "https://openalex.org/W3034198728",
      "https://openalex.org/W3035470414",
      "https://openalex.org/W3037879762",
      "https://openalex.org/W3088238433",
      "https://openalex.org/W3094479119",
      "https://openalex.org/W3099140719",
      "https://openalex.org/W3103996868",
      "https://openalex.org/W3105184920",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W3156909481",
      "https://openalex.org/W3161663089",
      "https://openalex.org/W3162462834",
      "https://openalex.org/W4288094254",
      "https://openalex.org/W4288288848",
      "https://openalex.org/W4385245566",
      "https://openalex.org/W4386564360"
    ],
    "abstract": "Carel van Niekerk, Andrey Malinin, Christian Geishauser, Michael Heck, Hsien-chin Lin, Nurul Lubis, Shutong Feng, Milica Gasic. Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021.",
    "match_score": 1.0
  },
  "Learning Neural Templates for Recommender Dialogue System": {
    "openalex_id": "https://openalex.org/W3204697369",
    "publication_year": 2021,
    "cited_by_count": 39,
    "referenced_works": [
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2009415795",
      "https://openalex.org/W2054141820",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133012565",
      "https://openalex.org/W2153225416",
      "https://openalex.org/W2157881433",
      "https://openalex.org/W2158515176",
      "https://openalex.org/W2295739661",
      "https://openalex.org/W2561529111",
      "https://openalex.org/W2605350416",
      "https://openalex.org/W2783215745",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2808871448",
      "https://openalex.org/W2809617427",
      "https://openalex.org/W2888515090",
      "https://openalex.org/W2891389695",
      "https://openalex.org/W2898076813",
      "https://openalex.org/W2952215380",
      "https://openalex.org/W2955416746",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962944953",
      "https://openalex.org/W2963201498",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964112275",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964207259",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964309167",
      "https://openalex.org/W2970236742",
      "https://openalex.org/W2970799419",
      "https://openalex.org/W2982904530",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2997662139",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3034328025",
      "https://openalex.org/W3035098003",
      "https://openalex.org/W3035301094",
      "https://openalex.org/W3035355914",
      "https://openalex.org/W3080122044",
      "https://openalex.org/W3094070895",
      "https://openalex.org/W3099865390",
      "https://openalex.org/W3100790518",
      "https://openalex.org/W3101718968",
      "https://openalex.org/W3106454043",
      "https://openalex.org/W3113741750",
      "https://openalex.org/W3115944734",
      "https://openalex.org/W3116062118",
      "https://openalex.org/W3116455257",
      "https://openalex.org/W3121970007",
      "https://openalex.org/W3152509363",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W3162337509",
      "https://openalex.org/W3163631185",
      "https://openalex.org/W3170262904",
      "https://openalex.org/W3174681481",
      "https://openalex.org/W3175618100",
      "https://openalex.org/W3195061894",
      "https://openalex.org/W4287180823",
      "https://openalex.org/W4287776017",
      "https://openalex.org/W4287900772",
      "https://openalex.org/W4289751766",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "The task of Conversational Recommendation System (CRS), i.e., recommender dialog system, aims to recommend precise items to users through natural language interactions. Though recent end-to-end neural models have shown promising progress on this task, two key challenges still remain. First, the recommended items cannot be always incorporated into the generated response precisely and appropriately. Second, only the items mentioned in the training corpus have a chance to be recommended in the conversation. To tackle these challenges, we introduce a novel framework called NTRD for recommender dialogue system that can decouple the dialogue generation from the item recommendation. NTRD has two key components, i.e., response template generator and item selector. The former adopts an encoder-decoder model to generate a response template with slot locations tied to target items, while the latter fills in slot locations with the proper items using a sufficient attention mechanism. Our approach combines the strengths of both classical slot filling approaches (that are generally controllable) and modern neural NLG approaches (that are generally more natural and accurate). Extensive experiments on the benchmark ReDial show our approach significantly outperforms the previous state-of-the-art methods. Besides, our approach has the unique advantage to produce novel items that do not appear in the training set of dialogue corpus. The code is available at https://github.com/jokieleung/NTRD.",
    "match_score": 1.0
  },
  "Fine-grained Post-training for Improving Retrieval-based Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3171266972",
    "publication_year": 2021,
    "cited_by_count": 51,
    "referenced_works": [
      "https://openalex.org/W1902237438",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2197546379",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2804547589",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2908602207",
      "https://openalex.org/W2925618549",
      "https://openalex.org/W2949446780",
      "https://openalex.org/W2951807227",
      "https://openalex.org/W2952813980",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963715136",
      "https://openalex.org/W2964303773",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2970648534",
      "https://openalex.org/W2995289474",
      "https://openalex.org/W2996428491",
      "https://openalex.org/W3021016503",
      "https://openalex.org/W3034533785",
      "https://openalex.org/W3034975599",
      "https://openalex.org/W3083814290",
      "https://openalex.org/W3094612274",
      "https://openalex.org/W3097517997",
      "https://openalex.org/W3176002924",
      "https://openalex.org/W3176506090",
      "https://openalex.org/W4287795696",
      "https://openalex.org/W4300687842",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Janghoon Han, Taesuk Hong, Byoungjae Kim, Youngjoong Ko, Jungyun Seo. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.",
    "match_score": 1.0
  },
  "Graph Based Network with Contextualized Representations of Turns in Dialogue": {
    "openalex_id": "https://openalex.org/W3196292458",
    "publication_year": 2021,
    "cited_by_count": 42,
    "referenced_works": [
      "https://openalex.org/W110692952",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1832693441",
      "https://openalex.org/W2093585241",
      "https://openalex.org/W2131774270",
      "https://openalex.org/W2168248941",
      "https://openalex.org/W2181629536",
      "https://openalex.org/W2250521169",
      "https://openalex.org/W2400672603",
      "https://openalex.org/W2513378248",
      "https://openalex.org/W2524459589",
      "https://openalex.org/W2740550900",
      "https://openalex.org/W2749002090",
      "https://openalex.org/W2759211898",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2914120296",
      "https://openalex.org/W2952179106",
      "https://openalex.org/W2962830617",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963686995",
      "https://openalex.org/W2964015378",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964166731",
      "https://openalex.org/W2964300796",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2971221499",
      "https://openalex.org/W2975998869",
      "https://openalex.org/W2982479487",
      "https://openalex.org/W2985882473",
      "https://openalex.org/W2996428491",
      "https://openalex.org/W3021224558",
      "https://openalex.org/W3035020961",
      "https://openalex.org/W3035053871",
      "https://openalex.org/W3035566559",
      "https://openalex.org/W3094612274",
      "https://openalex.org/W3098556456",
      "https://openalex.org/W3099056802",
      "https://openalex.org/W3102663935",
      "https://openalex.org/W3103836967",
      "https://openalex.org/W3112076981",
      "https://openalex.org/W3174817334",
      "https://openalex.org/W3205498744",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Dialogue-based relation extraction (RE) aims to extract relation(s) between two arguments that appear in a dialogue. Because dialogues have the characteristics of high personal pronoun occurrences and low information density, and since most relational facts in dialogues are not supported by any single sentence, dialogue-based relation extraction requires a comprehensive understanding of dialogue. In this paper, we propose the TUrn COntext awaRE Graph Convolutional Network (TUCORE-GCN) modeled by paying attention to the way people understand dialogues. In addition, we propose a novel approach which treats the task of emotion recognition in conversations (ERC) as a dialogue-based RE. Experiments on a dialogue-based RE dataset and three ERC datasets demonstrate that our model is very effective in various dialogue-based natural language understanding tasks. In these experiments, TUCORE-GCN outperforms the state-of-the-art models on most of the benchmark datasets. Our code is available at https://github.com/BlackNoodle/TUCORE-GCN.",
    "match_score": 1.0
  },
  "Exophoric Pronoun Resolution in Dialogues with Topic Regularization": {
    "openalex_id": "https://openalex.org/W3201091014",
    "publication_year": 2021,
    "cited_by_count": 4,
    "referenced_works": [
      "https://openalex.org/W138910040",
      "https://openalex.org/W2015933299",
      "https://openalex.org/W2042689318",
      "https://openalex.org/W2057820243",
      "https://openalex.org/W2081580037",
      "https://openalex.org/W2113242047",
      "https://openalex.org/W2114917204",
      "https://openalex.org/W2118320923",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2140646431",
      "https://openalex.org/W2143017621",
      "https://openalex.org/W2151373442",
      "https://openalex.org/W2155069789",
      "https://openalex.org/W2217772701",
      "https://openalex.org/W2250701745",
      "https://openalex.org/W2331260012",
      "https://openalex.org/W2768661419",
      "https://openalex.org/W2806042735",
      "https://openalex.org/W2892245540",
      "https://openalex.org/W2946581011",
      "https://openalex.org/W2953320089",
      "https://openalex.org/W2963087868",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2970550868",
      "https://openalex.org/W2970745243",
      "https://openalex.org/W2981902456",
      "https://openalex.org/W2986536733",
      "https://openalex.org/W3011411500",
      "https://openalex.org/W3034786666",
      "https://openalex.org/W3034797437",
      "https://openalex.org/W3152694552",
      "https://openalex.org/W4231510805",
      "https://openalex.org/W4234682833",
      "https://openalex.org/W4249013746",
      "https://openalex.org/W4287367772"
    ],
    "abstract": "Resolving pronouns to their referents has long been studied as a fundamental natural language understanding problem. Previous works on pronoun coreference resolution (PCR) mostly focus on resolving pronouns to mentions in text while ignoring the exophoric scenario. Exophoric pronouns are common in daily communications, where speakers may directly use pronouns to refer to some objects present in the environment without introducing the objects first. Although such objects are not mentioned in the dialogue text, they can often be disambiguated by the general topics of the dialogue. Motivated by this, we propose to jointly leverage the local context and global topics of dialogues to solve the out-of-text PCR problem. Extensive experiments demonstrate the effectiveness of adding topic regularization for resolving exophoric pronouns.",
    "match_score": 1.0
  },
  "Zero-Shot Dialogue Disentanglement by Self-Supervised Entangled Response Selection": {
    "openalex_id": "https://openalex.org/W3209879382",
    "publication_year": 2021,
    "cited_by_count": 1,
    "referenced_works": [
      "https://openalex.org/W2113063049",
      "https://openalex.org/W2115615127",
      "https://openalex.org/W2121912514",
      "https://openalex.org/W2155707639",
      "https://openalex.org/W2803119681",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2949600515",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2970597249",
      "https://openalex.org/W2998672049",
      "https://openalex.org/W3015071427",
      "https://openalex.org/W3015297483",
      "https://openalex.org/W3015468748",
      "https://openalex.org/W3102606416",
      "https://openalex.org/W3104997146",
      "https://openalex.org/W4287635673",
      "https://openalex.org/W4287704453"
    ],
    "abstract": "Dialogue disentanglement aims to group utterances in a long and multi-participant dialogue into threads. This is useful for discourse analysis and downstream applications such as dialogue response selection, where it can be the first step to construct a clean context/response set. Unfortunately, labeling all reply-to links takes quadratic effort w.r.t the number of utterances: an annotator must check all preceding utterances to identify the one to which the current utterance is a reply. In this paper, we are the first to propose a zero-shot dialogue disentanglement solution. Firstly, we train a model on a multi-participant response selection dataset harvested from the web which is not annotated; we then apply the trained model to perform zero-shot dialogue disentanglement. Without any labeled data, our model can achieve a cluster F1 score of 25. We also fine-tune the model using various amounts of labeled data. Experiments show that with only 10% of the data, we achieve nearly the same performance of using the full dataset.",
    "match_score": 1.0
  },
  "Preview, Attend and Review Schema-Aware Curriculum Learning for Multi-Domain Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W3173691672",
    "publication_year": 2021,
    "cited_by_count": 35,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1527783480",
      "https://openalex.org/W2296073425",
      "https://openalex.org/W2468710617",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2899628936",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2950695840",
      "https://openalex.org/W2962721878",
      "https://openalex.org/W2962739339",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2963096017",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2997657234",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W2998572029",
      "https://openalex.org/W3015974317",
      "https://openalex.org/W3021096583",
      "https://openalex.org/W3034201598",
      "https://openalex.org/W3034284249",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3034623328",
      "https://openalex.org/W3034938700",
      "https://openalex.org/W3035470414",
      "https://openalex.org/W3035633461",
      "https://openalex.org/W3040352674",
      "https://openalex.org/W3091355780",
      "https://openalex.org/W3094024803",
      "https://openalex.org/W3094479119",
      "https://openalex.org/W3099231098",
      "https://openalex.org/W3101131512",
      "https://openalex.org/W3103753314",
      "https://openalex.org/W3106495716",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W3126918322",
      "https://openalex.org/W3142849873",
      "https://openalex.org/W3175095351",
      "https://openalex.org/W3175678722",
      "https://openalex.org/W4285719527",
      "https://openalex.org/W4287659415",
      "https://openalex.org/W4287749601",
      "https://openalex.org/W4287795696",
      "https://openalex.org/W4288094254",
      "https://openalex.org/W4288288848"
    ],
    "abstract": "Yinpei Dai, Hangyu Li, Yongbin Li, Jian Sun, Fei Huang, Luo Si, Xiaodan Zhu. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 2021.",
    "match_score": 0.9950248756218906
  },
  "A Simple and Efficient Multi-Task Learning Approach for Conditioned Dialogue Generation": {
    "openalex_id": "https://openalex.org/W3170012708",
    "publication_year": 2021,
    "cited_by_count": 13,
    "referenced_works": [
      "https://openalex.org/W1956340063",
      "https://openalex.org/W2053154970",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2741323980",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2765617518",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2898700502",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2945260553",
      "https://openalex.org/W2951583236",
      "https://openalex.org/W2962753250",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963188990",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963330684",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963939249",
      "https://openalex.org/W2963995063",
      "https://openalex.org/W2964042872",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2964587107",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2965617855",
      "https://openalex.org/W2970252402",
      "https://openalex.org/W2971274815",
      "https://openalex.org/W2972916088",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2997892440",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3034337319",
      "https://openalex.org/W3035451444",
      "https://openalex.org/W3038115231",
      "https://openalex.org/W3040352674",
      "https://openalex.org/W3082549344",
      "https://openalex.org/W3094611204",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W4287749601",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4322614701"
    ],
    "abstract": "Conditioned dialogue generation suffers from the scarcity of labeled responses. In this work, we exploit labeled non-dialogue text data related to the condition, which are much easier to collect. We propose a multi-task learning approach to leverage both labeled dialogue and text data. The 3 tasks jointly optimize the same pre-trained Transformer \u2013 conditioned dialogue generation task on the labeled dialogue data, conditioned language encoding task and conditioned language generation task on the labeled text data. Experimental results show that our approach outperforms the state-of-the-art models by leveraging the labeled texts, and it also obtains larger improvement in performance comparing to the previous methods to leverage text data.",
    "match_score": 1.0
  },
  "Controllable Neural Dialogue Summarization with Personal Named Entity Planning": {
    "openalex_id": "https://openalex.org/W3204515301",
    "publication_year": 2021,
    "cited_by_count": 43,
    "referenced_works": [
      "https://openalex.org/W1513168555",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2101390659",
      "https://openalex.org/W2125336414",
      "https://openalex.org/W2144933361",
      "https://openalex.org/W2153190547",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2574535369",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2612675303",
      "https://openalex.org/W2617566453",
      "https://openalex.org/W2626778328",
      "https://openalex.org/W2735642330",
      "https://openalex.org/W2793978524",
      "https://openalex.org/W2798139452",
      "https://openalex.org/W2889518897",
      "https://openalex.org/W2889984458",
      "https://openalex.org/W2908510526",
      "https://openalex.org/W2949530332",
      "https://openalex.org/W2949615363",
      "https://openalex.org/W2952138241",
      "https://openalex.org/W2962805889",
      "https://openalex.org/W2962965405",
      "https://openalex.org/W2963126845",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963366196",
      "https://openalex.org/W2963607157",
      "https://openalex.org/W2963691697",
      "https://openalex.org/W2964015378",
      "https://openalex.org/W2964222296",
      "https://openalex.org/W2968154628",
      "https://openalex.org/W2970419734",
      "https://openalex.org/W2970745243",
      "https://openalex.org/W2970971581",
      "https://openalex.org/W2971034336",
      "https://openalex.org/W2982399380",
      "https://openalex.org/W3008323921",
      "https://openalex.org/W3021199973",
      "https://openalex.org/W3034863243",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3037109418",
      "https://openalex.org/W3074476581",
      "https://openalex.org/W3098295156",
      "https://openalex.org/W3099474967",
      "https://openalex.org/W3100439863",
      "https://openalex.org/W3100560913",
      "https://openalex.org/W3101913037",
      "https://openalex.org/W3103031657",
      "https://openalex.org/W3104257895",
      "https://openalex.org/W3106234277",
      "https://openalex.org/W3111372071",
      "https://openalex.org/W3158986179",
      "https://openalex.org/W3164979202",
      "https://openalex.org/W3169117666",
      "https://openalex.org/W3170033958",
      "https://openalex.org/W3170083118",
      "https://openalex.org/W3176770275",
      "https://openalex.org/W3193260960",
      "https://openalex.org/W4241891521",
      "https://openalex.org/W4295312788",
      "https://openalex.org/W4385245566",
      "https://openalex.org/W4385970303"
    ],
    "abstract": "In this paper, we propose a controllable neural generation framework that can flexibly guide dialogue summarization with personal named entity planning. The conditional sequences are modulated to decide what types of information or what perspective to focus on when forming summaries to tackle the under-constrained problem in summarization tasks. This framework supports two types of use cases: (1) Comprehensive Perspective, which is a general-purpose case with no user-preference specified, considering summary points from all conversational interlocutors and all mentioned persons; (2) Focus Perspective, positioning the summary based on a user-specified personal named entity, which could be one of the interlocutors or one of the persons mentioned in the conversation. During training, we exploit occurrence planning of personal named entities and coreference information to improve temporal coherence and to minimize hallucination in neural generation. Experimental results show that our proposed framework generates fluent and factually consistent summaries under various planning controls using both objective metrics and human evaluations.",
    "match_score": 1.0
  },
  "Dialogue State Tracking with a Language Model using Schema-Driven Prompting": {
    "openalex_id": "https://openalex.org/W3200895474",
    "publication_year": 2021,
    "cited_by_count": 85,
    "referenced_works": [
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2784070054",
      "https://openalex.org/W2804010326",
      "https://openalex.org/W2888849322",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2908510526",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2951216772",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2955810669",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963925437",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2972777589",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3004786215",
      "https://openalex.org/W3021016503",
      "https://openalex.org/W3021096583",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3024509506",
      "https://openalex.org/W3034533785",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3044438666",
      "https://openalex.org/W3045703328",
      "https://openalex.org/W3082274269",
      "https://openalex.org/W3099827451",
      "https://openalex.org/W3100110884",
      "https://openalex.org/W3100128199",
      "https://openalex.org/W3102854726",
      "https://openalex.org/W3104078590",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W3119822474",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W3156909481",
      "https://openalex.org/W4287795696",
      "https://openalex.org/W4287815000",
      "https://openalex.org/W4287900772",
      "https://openalex.org/W4288027128",
      "https://openalex.org/W4288089799",
      "https://openalex.org/W4288094254",
      "https://openalex.org/W4292779060"
    ],
    "abstract": "Task-oriented conversational systems often use dialogue state tracking to represent the user's intentions, which involves filling in values of pre-defined slots. Many approaches have been proposed, often using task-specific architectures with special-purpose classifiers. Recently, good results have been obtained using more general architectures based on pretrained language models. Here, we introduce a new variation of the language modeling approach that uses schema-driven prompting to provide task-aware history encoding that is used for both categorical and non-categorical slots. We further improve performance by augmenting the prompting with schema descriptions, a naturally occurring source of in-domain knowledge. Our purely generative system achieves state-of-the-art performance on MultiWOZ 2.2 and achieves competitive performance on two other benchmarks: MultiWOZ 2.1 and M2M. The data and code will be available at https://github.com/chiahsuan156/DST-as-Prompting.",
    "match_score": 1.0
  },
  "Neural Path Hunter Reducing Hallucination in Dialogue Systems via Path Grounding": {
    "openalex_id": "https://openalex.org/W3153046263",
    "publication_year": 2021,
    "cited_by_count": 72,
    "referenced_works": [
      "https://openalex.org/W145832685",
      "https://openalex.org/W182831726",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1984205520",
      "https://openalex.org/W2094728533",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2132453167",
      "https://openalex.org/W2148721079",
      "https://openalex.org/W2152790380",
      "https://openalex.org/W2250930514",
      "https://openalex.org/W2252136820",
      "https://openalex.org/W2270070752",
      "https://openalex.org/W2283196293",
      "https://openalex.org/W2295754318",
      "https://openalex.org/W2519887557",
      "https://openalex.org/W2739046565",
      "https://openalex.org/W2739716023",
      "https://openalex.org/W2754194354",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2909737760",
      "https://openalex.org/W2914397182",
      "https://openalex.org/W2938704169",
      "https://openalex.org/W2949413855",
      "https://openalex.org/W2950457956",
      "https://openalex.org/W2952523122",
      "https://openalex.org/W2962729880",
      "https://openalex.org/W2962735233",
      "https://openalex.org/W2962816513",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963506925",
      "https://openalex.org/W2963520511",
      "https://openalex.org/W2964015378",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964303773",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2970476646",
      "https://openalex.org/W2970988759",
      "https://openalex.org/W2971236040",
      "https://openalex.org/W2972916088",
      "https://openalex.org/W2973049837",
      "https://openalex.org/W2975059944",
      "https://openalex.org/W2979826702",
      "https://openalex.org/W2981259322",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2995448904",
      "https://openalex.org/W2996287690",
      "https://openalex.org/W3011411500",
      "https://openalex.org/W3015322406",
      "https://openalex.org/W3022463379",
      "https://openalex.org/W3022814719",
      "https://openalex.org/W3034188538",
      "https://openalex.org/W3034383590",
      "https://openalex.org/W3082549344",
      "https://openalex.org/W3098196327",
      "https://openalex.org/W3098495697",
      "https://openalex.org/W3098824823",
      "https://openalex.org/W3099453223",
      "https://openalex.org/W3099766584",
      "https://openalex.org/W3102659883",
      "https://openalex.org/W3106234277",
      "https://openalex.org/W3115944734",
      "https://openalex.org/W3158244987",
      "https://openalex.org/W3176098057",
      "https://openalex.org/W4287684041",
      "https://openalex.org/W4288091035"
    ],
    "abstract": "Dialogue systems powered by large pre-trained language models exhibit an innate ability to deliver fluent and natural-sounding responses. Despite their impressive performance, these models are fitful and can often generate factually incorrect statements impeding their widespread adoption. In this paper, we focus on the task of improving faithfulness and reducing hallucination of neural dialogue systems to known facts supplied by a Knowledge Graph (KG). We propose NEURAL PATH HUNTER which follows a generate-then-refine strategy whereby a generated response is amended using the KG. NEURAL PATH HUNTER leverages a separate token-level fact critic to identify plausible sources of hallucination followed by a refinement stage that retrieves correct entities by crafting a query signal that is propagated over a k-hop subgraph. We empirically validate our proposed approach on the OpenDialKG dataset (Moon et al., 2019) against a suite of metrics and report a relative improvement of faithfulness over dialogue responses by 20.35% based on FeQA (Durmus et al., 2020). The code is available at https://github.com/nouhadziri/Neural-Path-Hunter.",
    "match_score": 0.9937888198757764
  },
  "Spoken Language Understanding for Task-oriented Dialogue Systems with Augmented Memory Networks": {
    "openalex_id": "https://openalex.org/W3171708917",
    "publication_year": 2021,
    "cited_by_count": 12,
    "referenced_works": [
      "https://openalex.org/W648947103",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1550863320",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2077302143",
      "https://openalex.org/W2124895976",
      "https://openalex.org/W2129554061",
      "https://openalex.org/W2137871902",
      "https://openalex.org/W2153962611",
      "https://openalex.org/W2166293310",
      "https://openalex.org/W2267186426",
      "https://openalex.org/W2400801499",
      "https://openalex.org/W2473329891",
      "https://openalex.org/W2534274346",
      "https://openalex.org/W2575101493",
      "https://openalex.org/W2797625445",
      "https://openalex.org/W2803392141",
      "https://openalex.org/W2803609229",
      "https://openalex.org/W2804945011",
      "https://openalex.org/W2891533927",
      "https://openalex.org/W2950527759",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2962954913",
      "https://openalex.org/W2963033987",
      "https://openalex.org/W2963066655",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963448850",
      "https://openalex.org/W2963974889",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2971167298",
      "https://openalex.org/W4297683418",
      "https://openalex.org/W4303633609",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Spoken language understanding, usually including intent detection and slot filling, is a core component to build a spoken dialog system. Recent research shows promising results by jointly learning of those two tasks based on the fact that slot filling and intent detection are sharing semantic knowledge. Furthermore, attention mechanism boosts joint learning to achieve state-of-the-art results. However, current joint learning models ignore the following important facts: 1. Long-term slot context is not traced effectively, which is crucial for future slot filling. 2. Slot tagging and intent detection could be mutually rewarding, but bi-directional interaction between slot filling and intent detection remains seldom explored. In this paper, we propose a novel approach to model long-term slot context and to fully utilize the semantic correlation between slots and intents. We adopt a key-value memory network to model slot context dynamically and to track more important slot tags decoded before, which are then fed into our decoder for slot tagging. Furthermore, gated memory information is utilized to perform intent detection, mutually improving both tasks through global optimization. Experiments on benchmark ATIS and Snips datasets show that our model achieves state-of-the-art performance and outperforms other methods, especially for the slot filling task.",
    "match_score": 1.0
  },
  "Efficient Dialogue Complementary Policy Learning via Deep Q-network Policy and Episodic Memory Policy": {
    "openalex_id": "https://openalex.org/W3212099586",
    "publication_year": 2021,
    "cited_by_count": 11,
    "referenced_works": [
      "https://openalex.org/W117128830",
      "https://openalex.org/W1534395135",
      "https://openalex.org/W1904365287",
      "https://openalex.org/W2021151961",
      "https://openalex.org/W2027685064",
      "https://openalex.org/W2047057213",
      "https://openalex.org/W2056566670",
      "https://openalex.org/W2094484179",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2099647287",
      "https://openalex.org/W2100377190",
      "https://openalex.org/W2112707476",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2159345153",
      "https://openalex.org/W2167362547",
      "https://openalex.org/W2201581102",
      "https://openalex.org/W2294065713",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2436711315",
      "https://openalex.org/W2507592741",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2594466397",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2739936944",
      "https://openalex.org/W2740191615",
      "https://openalex.org/W2759104452",
      "https://openalex.org/W2787841449",
      "https://openalex.org/W2798494119",
      "https://openalex.org/W2884814595",
      "https://openalex.org/W2889186204",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2947212824",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2949476504",
      "https://openalex.org/W2951805158",
      "https://openalex.org/W2962996309",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963289713",
      "https://openalex.org/W2963433587",
      "https://openalex.org/W2963477884",
      "https://openalex.org/W2963567240",
      "https://openalex.org/W2963692154",
      "https://openalex.org/W2963993502",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964044380",
      "https://openalex.org/W2964082094",
      "https://openalex.org/W2970828515",
      "https://openalex.org/W2998458199",
      "https://openalex.org/W3008413595",
      "https://openalex.org/W3034330559",
      "https://openalex.org/W3104546989",
      "https://openalex.org/W3105957118",
      "https://openalex.org/W3175095351",
      "https://openalex.org/W4234134528",
      "https://openalex.org/W4239187508",
      "https://openalex.org/W4297732320",
      "https://openalex.org/W4312609624"
    ],
    "abstract": "Deep reinforcement learning has shown great potential in training dialogue policies. However, its favorable performance comes at the cost of many rounds of interaction. Most of the existing dialogue policy methods rely on a single learning system, while the human brain has two specialized learning and memory systems, supporting to find good solutions without requiring copious examples. Inspired by the human brain, this paper proposes a novel complementary policy learning (CPL) framework, which exploits the complementary advantages of the episodic memory (EM) policy and the deep Q-network (DQN) policy to achieve fast and effective dialogue policy learning. In order to coordinate between the two policies, we proposed a confidence controller to control the complementary time according to their relative efficacy at different stages. Furthermore, memory connectivity and time pruning are proposed to guarantee the flexible and adaptive generalization of the EM policy in dialog tasks. Experimental results on three dialogue datasets show that our method significantly outperforms existing methods relying on a single learning system.",
    "match_score": 1.0
  },
  "Contextualize Knowledge Bases with Transformer for End-to-end Task-Oriented Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3094083263",
    "publication_year": 2021,
    "cited_by_count": 9,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2171837816",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2808093377",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2949141958",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963858333",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2970260827",
      "https://openalex.org/W2971261034",
      "https://openalex.org/W2994673210",
      "https://openalex.org/W3013192639",
      "https://openalex.org/W3017074538",
      "https://openalex.org/W3035301094",
      "https://openalex.org/W3082549344",
      "https://openalex.org/W3099453223",
      "https://openalex.org/W3102521862",
      "https://openalex.org/W3106274079",
      "https://openalex.org/W3162000275",
      "https://openalex.org/W4295838474",
      "https://openalex.org/W4297733535",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Incorporating knowledge bases (KB) into end-to-end task-oriented dialogue systems is challenging, since it requires to properly represent the entity of KB, which is associated with its KB context and dialogue context. The existing works represent the entity with only perceiving a part of its KB context, which can lead to the less effective representation due to the information loss, and adversely favor KB reasoning and response generation. To tackle this issue, we explore to fully contextualize the entity representation by dynamically perceiving all the relevant entities and dialogue history. To achieve this, we propose a COntext-aware Memory Enhanced Transformer framework (COMET), which treats the KB as a sequence and leverages a novel Memory Mask to enforce the entity to only focus on its relevant entities and dialogue history, while avoiding the distraction from the irrelevant entities. Through extensive experiments, we show that our COMET framework can achieve superior performance over the state of the arts.",
    "match_score": 1.0
  },
  "Adding Chit-Chat to Enhance Task-Oriented Dialogues": {
    "openalex_id": "https://openalex.org/W3166143260",
    "publication_year": 2021,
    "cited_by_count": 35,
    "referenced_works": [
      "https://openalex.org/W1598178035",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1993567041",
      "https://openalex.org/W2099813784",
      "https://openalex.org/W2108806737",
      "https://openalex.org/W2250456405",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251235149",
      "https://openalex.org/W2464790259",
      "https://openalex.org/W2565274151",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2611138659",
      "https://openalex.org/W2759621817",
      "https://openalex.org/W2784070054",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2950457956",
      "https://openalex.org/W2951583236",
      "https://openalex.org/W2952607215",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2963134326",
      "https://openalex.org/W2963201498",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963969444",
      "https://openalex.org/W2963974889",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2971883198",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W2999134550",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3002330681",
      "https://openalex.org/W3021016503",
      "https://openalex.org/W3021096583",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3024509506",
      "https://openalex.org/W3034337319",
      "https://openalex.org/W3034600233",
      "https://openalex.org/W3034908682",
      "https://openalex.org/W3037528277",
      "https://openalex.org/W3082549344",
      "https://openalex.org/W3102854726",
      "https://openalex.org/W3117238912",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W4254836149",
      "https://openalex.org/W4287795696",
      "https://openalex.org/W4287900772",
      "https://openalex.org/W4288113479",
      "https://openalex.org/W4288288848",
      "https://openalex.org/W4289147179",
      "https://openalex.org/W4295249402"
    ],
    "abstract": "Kai Sun, Seungwhan Moon, Paul Crook, Stephen Roller, Becka Silvert, Bing Liu, Zhiguang Wang, Honglei Liu, Eunjoon Cho, Claire Cardie. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.",
    "match_score": 1.0
  },
  "GOLD Improving Out-of-Scope Detection in Dialogues using Data Augmentation": {
    "openalex_id": "https://openalex.org/W3196675050",
    "publication_year": 2021,
    "cited_by_count": 18,
    "referenced_works": [
      "https://openalex.org/W1480981077",
      "https://openalex.org/W1574901103",
      "https://openalex.org/W1976526581",
      "https://openalex.org/W2045812729",
      "https://openalex.org/W2144182447",
      "https://openalex.org/W2152272511",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251658415",
      "https://openalex.org/W2475167333",
      "https://openalex.org/W2531327146",
      "https://openalex.org/W2575298912",
      "https://openalex.org/W2577267675",
      "https://openalex.org/W2740149041",
      "https://openalex.org/W2758425594",
      "https://openalex.org/W2767414122",
      "https://openalex.org/W2806753317",
      "https://openalex.org/W2889625178",
      "https://openalex.org/W2891642103",
      "https://openalex.org/W2898856000",
      "https://openalex.org/W2904981516",
      "https://openalex.org/W2905266130",
      "https://openalex.org/W2913352150",
      "https://openalex.org/W2923780723",
      "https://openalex.org/W2932893307",
      "https://openalex.org/W2948367246",
      "https://openalex.org/W2951883849",
      "https://openalex.org/W2951911250",
      "https://openalex.org/W2952409498",
      "https://openalex.org/W2959053776",
      "https://openalex.org/W2962721878",
      "https://openalex.org/W2963238274",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963384319",
      "https://openalex.org/W2963545917",
      "https://openalex.org/W2963655793",
      "https://openalex.org/W2963693742",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963924212",
      "https://openalex.org/W2964059111",
      "https://openalex.org/W2964201905",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2968297680",
      "https://openalex.org/W2970418174",
      "https://openalex.org/W2970641574",
      "https://openalex.org/W2970855255",
      "https://openalex.org/W2970946347",
      "https://openalex.org/W2971002550",
      "https://openalex.org/W2971089712",
      "https://openalex.org/W2971296908",
      "https://openalex.org/W2985067290",
      "https://openalex.org/W2986193249",
      "https://openalex.org/W2995188922",
      "https://openalex.org/W2995404354",
      "https://openalex.org/W2997140799",
      "https://openalex.org/W2997212544",
      "https://openalex.org/W3014773921",
      "https://openalex.org/W3034630076",
      "https://openalex.org/W3035441651",
      "https://openalex.org/W3094447228",
      "https://openalex.org/W3097663391",
      "https://openalex.org/W3098341425",
      "https://openalex.org/W3099617520",
      "https://openalex.org/W3100247553",
      "https://openalex.org/W3105190746",
      "https://openalex.org/W3105388824",
      "https://openalex.org/W3121064530",
      "https://openalex.org/W3133589252",
      "https://openalex.org/W3165919849",
      "https://openalex.org/W4254182148"
    ],
    "abstract": "Practical dialogue systems require robust methods of detecting out-of-scope (OOS) utterances to avoid conversational breakdowns and related failure modes. Directly training a model with labeled OOS examples yields reasonable performance, but obtaining such data is a resource-intensive process. To tackle this limited-data problem, previous methods focus on better modeling the distribution of in-scope (INS) examples. We introduce GOLD as an orthogonal technique that augments existing data to train better OOS detectors operating in low-data regimes. GOLD generates pseudo-labeled candidates using samples from an auxiliary dataset and keeps only the most beneficial candidates for training through a novel filtering mechanism. In experiments across three target benchmarks, the top GOLD model outperforms all existing methods on all key metrics, achieving relative gains of 52.4%, 48.9% and 50.3% against median baseline performance. We also analyze the unique properties of OOS data to identify key factors for optimally applying our proposed method.",
    "match_score": 0.9932885906040269
  },
  "More is Better Enhancing Open-Domain Dialogue Generation via Multi-Source Heterogeneous Knowledge": {
    "openalex_id": "https://openalex.org/W3212092284",
    "publication_year": 2021,
    "cited_by_count": 15,
    "referenced_works": [
      "https://openalex.org/W1902237438",
      "https://openalex.org/W2098985784",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2127795553",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2304113845",
      "https://openalex.org/W2561529111",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2798385473",
      "https://openalex.org/W2799037524",
      "https://openalex.org/W2804552794",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2890969459",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2951883832",
      "https://openalex.org/W2952420867",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963285578",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963541420",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964207259",
      "https://openalex.org/W2970260827",
      "https://openalex.org/W2970579055",
      "https://openalex.org/W2970988759",
      "https://openalex.org/W2971199636",
      "https://openalex.org/W2995183464",
      "https://openalex.org/W2996227762",
      "https://openalex.org/W2997094605",
      "https://openalex.org/W2997300509",
      "https://openalex.org/W2998083599",
      "https://openalex.org/W3011801489",
      "https://openalex.org/W3034569646",
      "https://openalex.org/W3034606970",
      "https://openalex.org/W3034696087",
      "https://openalex.org/W3034758256",
      "https://openalex.org/W3035072597",
      "https://openalex.org/W3035356453",
      "https://openalex.org/W3045507162",
      "https://openalex.org/W3092288641",
      "https://openalex.org/W3093956460",
      "https://openalex.org/W3100523370",
      "https://openalex.org/W3113225429",
      "https://openalex.org/W3113547664",
      "https://openalex.org/W3118010541",
      "https://openalex.org/W3121541553",
      "https://openalex.org/W3187909673",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Despite achieving remarkable performance, previous knowledge-enhanced works usually only use a single-source homogeneous knowledge base of limited knowledge coverage. Thus, they often degenerate into traditional methods because not all dialogues can be linked with knowledge entries. This paper proposes a novel dialogue generation model, MSKE-Dialog, to solve this issue with three unique advantages: (1) Rather than only one, MSKE-Dialog can simultaneously leverage multiple heterogeneous knowledge sources (it includes but is not limited to commonsense knowledge facts, text knowledge, infobox knowledge) to improve the knowledge coverage; (2) To avoid the topic conflict among the context and different knowledge sources, we propose a Multi-Reference Selection to better select context/knowledge; (3) We propose a Multi-Reference Generation to generate informative responses by referring to multiple generation references at the same time. Extensive evaluations on a Chinese dataset show the superior performance of this work against various state-of-the-art approaches. To our best knowledge, this work is the first to use the multi-source heterogeneous knowledge in the open-domain knowledge-enhanced dialogue generation.",
    "match_score": 0.9948717948717949
  },
  "Knowledge-Aware Graph-Enhanced GPT-2 for Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W3153659051",
    "publication_year": 2021,
    "cited_by_count": 3,
    "referenced_works": [
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963858333",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W3015974317",
      "https://openalex.org/W3021096583",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3034956542",
      "https://openalex.org/W3035470414",
      "https://openalex.org/W3035594326",
      "https://openalex.org/W3035633461",
      "https://openalex.org/W3088238433",
      "https://openalex.org/W3101131512",
      "https://openalex.org/W3103753314",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W3121272494",
      "https://openalex.org/W3166401044",
      "https://openalex.org/W3174401467"
    ],
    "abstract": "Dialogue State Tracking is central to multi-domain task-oriented dialogue systems, responsible for extracting information from user utterances. We present a novel hybrid architecture that augments GPT-2 with representations derived from Graph Attention Networks in such a way to allow causal, sequential prediction of slot values. The model architecture captures inter-slot relationships and dependencies across domains that otherwise can be lost in sequential prediction. We report improvements in state tracking performance in MultiWOZ 2.0 against a strong GPT-2 baseline and investigate a simplified sparse training scenario in which DST models are trained only on session-level annotations but evaluated at the turn level. We further report detailed analyses to demonstrate the effectiveness of graph models in DST by showing that the proposed graph modules capture inter-slot dependencies and improve the predictions of values that are common to multiple domains.",
    "match_score": 1.0
  },
  "Contextual Rephrase Detection for Reducing Friction in Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3201234832",
    "publication_year": 2021,
    "cited_by_count": 8,
    "referenced_works": [
      "https://openalex.org/W2045865594",
      "https://openalex.org/W2533180076",
      "https://openalex.org/W2745673470",
      "https://openalex.org/W2790235966",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2964015378",
      "https://openalex.org/W2964082993",
      "https://openalex.org/W2964165804",
      "https://openalex.org/W3016107769",
      "https://openalex.org/W3093793648",
      "https://openalex.org/W3099700870",
      "https://openalex.org/W3156636935",
      "https://openalex.org/W3161825643",
      "https://openalex.org/W4320803111"
    ],
    "abstract": "For voice assistants like Alexa, Google Assistant, and Siri, correctly interpreting users\u2019 intentions is of utmost importance. However, users sometimes experience friction with these assistants, caused by errors from different system components or user errors such as slips of the tongue. Users tend to rephrase their queries until they get a satisfactory response. Rephrase detection is used to identify the rephrases and has long been treated as a task with pairwise input, which does not fully utilize the contextual information (e.g. users\u2019 implicit feedback). To this end, we propose a contextual rephrase detection model ContReph to automatically identify rephrases from multi-turn dialogues. We showcase how to leverage the dialogue context and user-agent interaction signals, including the user\u2019s implicit feedback and the time gap between different turns, which can help significantly outperform the pairwise rephrase detection models.",
    "match_score": 1.0
  },
  "MediaSum A Large-scale Media Interview Dataset for Dialogue Summarization": {
    "openalex_id": "https://openalex.org/W3169942382",
    "publication_year": 2021,
    "cited_by_count": 85,
    "referenced_works": [
      "https://openalex.org/W1880262756",
      "https://openalex.org/W1983719983",
      "https://openalex.org/W2101234009",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2945260553",
      "https://openalex.org/W2952890017",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2963607157",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2971274815",
      "https://openalex.org/W2978075745",
      "https://openalex.org/W2989743967",
      "https://openalex.org/W3015818096",
      "https://openalex.org/W3023363161",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3035259249",
      "https://openalex.org/W3085629518",
      "https://openalex.org/W3104257895",
      "https://openalex.org/W4288095748"
    ],
    "abstract": "This paper introduces MediaSum, a large-scale media interview dataset consisting of 463.6K transcripts with abstractive summaries. To create this dataset, we collect interview transcripts from NPR and CNN and employ the overview and topic descriptions as summaries. Compared with existing public corpora for dialogue summarization, our dataset is an order of magnitude larger and contains complex multi-party conversations from multiple domains. We conduct statistical analysis to demonstrate the unique positional bias exhibited in the transcripts of televised and radioed interviews. We also show that MediaSum can be used in transfer learning to improve a model\u2019s performance on other dialogue summarization tasks.",
    "match_score": 0.9931972789115646
  },
  "Leveraging Slot Descriptions for Zero-Shot Cross-Domain Dialogue StateTracking": {
    "openalex_id": "https://openalex.org/W3168491067",
    "publication_year": 2021,
    "cited_by_count": 60,
    "referenced_works": [
      "https://openalex.org/W1598178035",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2908510526",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2951088751",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963578915",
      "https://openalex.org/W2963925437",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W2997214274",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W3015637204",
      "https://openalex.org/W3016625483",
      "https://openalex.org/W3021016503",
      "https://openalex.org/W3021096583",
      "https://openalex.org/W3034284249",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3045689439",
      "https://openalex.org/W3045703328",
      "https://openalex.org/W3049346316",
      "https://openalex.org/W3082274269",
      "https://openalex.org/W3094479119",
      "https://openalex.org/W3097392354",
      "https://openalex.org/W3100110884",
      "https://openalex.org/W3100128199",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W3156909481",
      "https://openalex.org/W3160818482",
      "https://openalex.org/W4285719527",
      "https://openalex.org/W4287795696",
      "https://openalex.org/W4288027128",
      "https://openalex.org/W4288089799",
      "https://openalex.org/W4288094254"
    ],
    "abstract": "Zhaojiang Lin, Bing Liu, Seungwhan Moon, Paul Crook, Zhenpeng Zhou, Zhiguang Wang, Zhou Yu, Andrea Madotto, Eunjoon Cho, Rajen Subba. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.",
    "match_score": 1.0
  },
  "Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation": {
    "openalex_id": "https://openalex.org/W3213435953",
    "publication_year": 2021,
    "cited_by_count": 19,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W2406390611",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2809213523",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2938830017",
      "https://openalex.org/W2950220847",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2951508633",
      "https://openalex.org/W2953356739",
      "https://openalex.org/W2962786758",
      "https://openalex.org/W2963371754",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2964458951",
      "https://openalex.org/W2970986510",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2995183464",
      "https://openalex.org/W2996227762",
      "https://openalex.org/W3034600233",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3035153870",
      "https://openalex.org/W3104123491",
      "https://openalex.org/W3104415840",
      "https://openalex.org/W3104777900",
      "https://openalex.org/W3123799706",
      "https://openalex.org/W3137695714",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Although pre-training models have achieved great success in dialogue generation, their performance drops dramatically when the input contains an entity that does not appear in pre-training and fine-tuning datasets (unseen entity). To address this issue, existing methods leverage an external knowledge base to generate appropriate responses. In real-world practical, the entity may not be included by the knowledge base or suffer from the precision of knowledge retrieval. To deal with this problem, instead of introducing knowledge base as the input, we force the model to learn a better semantic representation by predicting the information in the knowledge base, only based on the input context. Specifically, with the help of a knowledge base, we introduce two auxiliary training objectives: 1) Interpret Masked Word, which conjectures the meaning of the masked entity given the context; 2) Hypernym Generation, which predicts the hypernym of the entity based on the context. Experiment results on two dialogue corpus verify the effectiveness of our methods under both knowledge available and unavailable settings.",
    "match_score": 1.0
  },
  "Domain-Lifelong Learning for Dialogue State Tracking via Knowledge Preservation Networks": {
    "openalex_id": "https://openalex.org/W3214501429",
    "publication_year": 2021,
    "cited_by_count": 8,
    "referenced_works": [
      "https://openalex.org/W1524766440",
      "https://openalex.org/W1682403713",
      "https://openalex.org/W1821462560",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2060277733",
      "https://openalex.org/W2108807072",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2166344886",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251235149",
      "https://openalex.org/W2473930607",
      "https://openalex.org/W2541884796",
      "https://openalex.org/W2554863749",
      "https://openalex.org/W2560647685",
      "https://openalex.org/W2583761661",
      "https://openalex.org/W2601450892",
      "https://openalex.org/W2737492962",
      "https://openalex.org/W2771964490",
      "https://openalex.org/W2777054756",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2948734064",
      "https://openalex.org/W2950635152",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2962724315",
      "https://openalex.org/W2963038864",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963314614",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963559848",
      "https://openalex.org/W2963588172",
      "https://openalex.org/W2963733234",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964189064",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2971146255",
      "https://openalex.org/W2972777589",
      "https://openalex.org/W2982410595",
      "https://openalex.org/W2986349107",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W3021931813",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3034898894",
      "https://openalex.org/W3035470414",
      "https://openalex.org/W3035594326",
      "https://openalex.org/W3035633461",
      "https://openalex.org/W3035691277",
      "https://openalex.org/W3099554319",
      "https://openalex.org/W3103819114",
      "https://openalex.org/W3109225397",
      "https://openalex.org/W3115336344",
      "https://openalex.org/W4205340316",
      "https://openalex.org/W4295200480",
      "https://openalex.org/W4295883599",
      "https://openalex.org/W4301163820",
      "https://openalex.org/W4318619660",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Dialogue state tracking (DST), which estimates user goals given a dialogue context, is an essential component of task-oriented dialogue systems. Conventional DST models are usually trained offline, which requires a fixed dataset prepared in advance. This paradigm is often impractical in real-world applications since online dialogue systems usually involve continually emerging new data and domains. Therefore, this paper explores Domain-Lifelong Learning for Dialogue State Tracking (DLL-DST), which aims to continually train a DST model on new data to learn incessantly emerging new domains while avoiding catastrophically forgetting old learned domains. To this end, we propose a novel domain-lifelong learning method, called Knowledge Preservation Networks (KPN), which consists of multi-prototype enhanced retrospection and multi-strategy knowledge distillation, to solve the problems of expression diversity and combinatorial explosion in the DLL-DST task. Experimental results show that KPN effectively alleviates catastrophic forgetting and outperforms previous state-of-the-art lifelong learning methods by 4.25% and 8.27% of whole joint goal accuracy on the MultiWOZ benchmark and the SGD benchmark, respectively.",
    "match_score": 1.0
  },
  "CREAD Combined Resolution of Ellipses and Anaphora in Dialogues": {
    "openalex_id": "https://openalex.org/W3163744364",
    "publication_year": 2021,
    "cited_by_count": 13,
    "referenced_works": [
      "https://openalex.org/W1495981708",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1612381393",
      "https://openalex.org/W2050273484",
      "https://openalex.org/W2075011505",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130848543",
      "https://openalex.org/W2180160918",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2250738489",
      "https://openalex.org/W2252247041",
      "https://openalex.org/W2406055728",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2579689822",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2921671634",
      "https://openalex.org/W2952855649",
      "https://openalex.org/W2962769558",
      "https://openalex.org/W2963087868",
      "https://openalex.org/W2963167649",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964222246",
      "https://openalex.org/W2970110247",
      "https://openalex.org/W2970550868",
      "https://openalex.org/W2972873275",
      "https://openalex.org/W3011411500",
      "https://openalex.org/W3031383011",
      "https://openalex.org/W3034797437",
      "https://openalex.org/W3171244865",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Bo-Hsiang Tseng, Shruti Bhargava, Jiarui Lu, Joel Ruben Antony Moniz, Dhivya Piraviperumal, Lin Li, Hong Yu. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.",
    "match_score": 0.9921259842519685
  },
  "Multi-Modal Open-Domain Dialogue": {
    "openalex_id": "https://openalex.org/W3090998540",
    "publication_year": 2021,
    "cited_by_count": 5,
    "referenced_works": [
      "https://openalex.org/W84786028",
      "https://openalex.org/W639708223",
      "https://openalex.org/W1514535095",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1889081078",
      "https://openalex.org/W1895577753",
      "https://openalex.org/W1933349210",
      "https://openalex.org/W2117539524",
      "https://openalex.org/W2185175083",
      "https://openalex.org/W2546696630",
      "https://openalex.org/W2737766105",
      "https://openalex.org/W2768661419",
      "https://openalex.org/W2890394457",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2950178297",
      "https://openalex.org/W2950761309",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963467339",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963703197",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963904606",
      "https://openalex.org/W2963955897",
      "https://openalex.org/W2968124245",
      "https://openalex.org/W2970231061",
      "https://openalex.org/W2970352191",
      "https://openalex.org/W2970608575",
      "https://openalex.org/W2971173235",
      "https://openalex.org/W2971883198",
      "https://openalex.org/W2972119347",
      "https://openalex.org/W2982260276",
      "https://openalex.org/W2982277189",
      "https://openalex.org/W2985799198",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2991289756",
      "https://openalex.org/W2997517419",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3022310886",
      "https://openalex.org/W3022579796",
      "https://openalex.org/W3023074479",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3023893410",
      "https://openalex.org/W3034238904",
      "https://openalex.org/W3034255912",
      "https://openalex.org/W3034600233",
      "https://openalex.org/W3034727271",
      "https://openalex.org/W3035448310",
      "https://openalex.org/W3037528277",
      "https://openalex.org/W3037831233",
      "https://openalex.org/W3090449556",
      "https://openalex.org/W3103639864"
    ],
    "abstract": "Recent work in open-domain conversational agents has demonstrated that significant improvements in model engagingness and humanness metrics can be achieved via massive scaling in both pre-training data and model size (Adiwardana et al., 2020; Roller et al., 2020). However, if we want to build agents with human-like abilities, we must expand beyond handling just text. A particularly important topic is the ability to see images and communicate about what is perceived. With the goal of engaging humans in multi-modal dialogue, we investigate combining components from state-of-the-art open-domain dialogue agents with those from state-of-the-art vision models. We study incorporating different image fusion schemes and domain-adaptive pre-training and fine-tuning strategies, and show that our best resulting model outperforms strong existing models in multi-modal dialogue while simultaneously performing as well as its predecessor (text-only) BlenderBot (Roller et al., 2020) in text-based conversation. We additionally investigate and incorporate safety components in our final model, and show that such efforts do not diminish model performance with respect to engagingness metrics.",
    "match_score": 1.0
  },
  "DialogueCSE Dialogue-based Contrastive Learning of Sentence Embeddings": {
    "openalex_id": "https://openalex.org/W3202125623",
    "publication_year": 2021,
    "cited_by_count": 26,
    "referenced_works": [
      "https://openalex.org/W1486649854",
      "https://openalex.org/W1566289585",
      "https://openalex.org/W1665214252",
      "https://openalex.org/W1840435438",
      "https://openalex.org/W2155482025",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2250790822",
      "https://openalex.org/W2413533759",
      "https://openalex.org/W2611029872",
      "https://openalex.org/W2786464815",
      "https://openalex.org/W2790235966",
      "https://openalex.org/W2798583685",
      "https://openalex.org/W2842511635",
      "https://openalex.org/W2884814595",
      "https://openalex.org/W2891177506",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2923014074",
      "https://openalex.org/W2949433733",
      "https://openalex.org/W2949446780",
      "https://openalex.org/W2953384591",
      "https://openalex.org/W2963149412",
      "https://openalex.org/W2963310665",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963644595",
      "https://openalex.org/W2963804993",
      "https://openalex.org/W2963846996",
      "https://openalex.org/W2963918774",
      "https://openalex.org/W2970641574",
      "https://openalex.org/W3031414376",
      "https://openalex.org/W3033406728",
      "https://openalex.org/W3034238904",
      "https://openalex.org/W3100652389",
      "https://openalex.org/W3104033643",
      "https://openalex.org/W3104078590",
      "https://openalex.org/W3105816068",
      "https://openalex.org/W3115295967",
      "https://openalex.org/W3131870090",
      "https://openalex.org/W3154229486",
      "https://openalex.org/W3156636935",
      "https://openalex.org/W3164054899",
      "https://openalex.org/W3173783447",
      "https://openalex.org/W3175362188",
      "https://openalex.org/W4252076394",
      "https://openalex.org/W4297785815",
      "https://openalex.org/W4297808394",
      "https://openalex.org/W4298443704",
      "https://openalex.org/W4313908941"
    ],
    "abstract": "Learning sentence embeddings from dialogues has drawn increasing attention due to its low annotation cost and high domain adaptability. Conventional approaches employ the siamese-network for this task, which obtains the sentence embeddings through modeling the context-response semantic relevance by applying a feed-forward network on top of the sentence encoders. However, as the semantic textual similarity is commonly measured through the element-wise distance metrics (e.g. cosine and L2 distance), such architecture yields a large gap between training and evaluating. In this paper, we propose DialogueCSE, a dialogue-based contrastive learning approach to tackle this issue. DialogueCSE first introduces a novel matching-guided embedding (MGE) mechanism, which generates a context-aware embedding for each candidate response embedding (i.e. the context-free embedding) according to the guidance of the multi-turn context-response matching matrices. Then it pairs each context-aware embedding with its corresponding context-free embedding and finally minimizes the contrastive loss across all pairs. We evaluate our model on three multi-turn dialogue datasets: the Microsoft Dialogue Corpus, the Jing Dong Dialogue Corpus, and the E-commerce Dialogue Corpus. Evaluation results show that our approach significantly outperforms the baselines across all three datasets in terms of MAP and Spearman\u2019s correlation measures, demonstrating its effectiveness. Further quantitative experiments show that our approach achieves better performance when leveraging more dialogue context and remains robust when less training data is provided.",
    "match_score": 0.9929078014184397
  },
  "Generation and Extraction Combined Dialogue State Tracking with Hierarchical Ontology Integration": {
    "openalex_id": "https://openalex.org/W3213972251",
    "publication_year": 2021,
    "cited_by_count": 7,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2889448364",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2953071719",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2962808855",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963527209",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W3021096583",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3036362489",
      "https://openalex.org/W3045689439",
      "https://openalex.org/W3100544532",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W4205671217",
      "https://openalex.org/W4288094254",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Recently, the focus of dialogue state tracking has expanded from single domain to multiple domains. The task is characterized by the shared slots between domains. As the scenario gets more complex, the out-of-vocabulary problem also becomes severer. Current models are not satisfactory for solving the challenges of ontology integration between domains and out-of-vocabulary problems. To address the problem, we explore the hierarchical semantic of ontology and enhance the interrelation between slots with masked hierarchical attention. In state value decoding stage, we solve the out-of-vocabulary problem by combining generation method and extraction method together. We evaluate the performance of our model on two representative datasets, MultiWOZ in English and CrossWOZ in Chinese. The results show that our model yields a significant performance gain over current state-of-the-art state tracking model and it is more robust to out-of-vocabulary problem compared with other methods.",
    "match_score": 1.0
  },
  "NDH-Full Learning and Evaluating Navigational Agents on Full-Length Dialogue": {
    "openalex_id": "https://openalex.org/W3211887611",
    "publication_year": 2021,
    "cited_by_count": 10,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1602500555",
      "https://openalex.org/W1933065844",
      "https://openalex.org/W2118781169",
      "https://openalex.org/W2130463046",
      "https://openalex.org/W2194775991",
      "https://openalex.org/W2236233024",
      "https://openalex.org/W2585954273",
      "https://openalex.org/W2627585944",
      "https://openalex.org/W2774005037",
      "https://openalex.org/W2795911278",
      "https://openalex.org/W2805984364",
      "https://openalex.org/W2835434549",
      "https://openalex.org/W2890902815",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2899235916",
      "https://openalex.org/W2899771611",
      "https://openalex.org/W2908510526",
      "https://openalex.org/W2926977875",
      "https://openalex.org/W2950697717",
      "https://openalex.org/W2951973805",
      "https://openalex.org/W2952033963",
      "https://openalex.org/W2958574008",
      "https://openalex.org/W2959918500",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963726321",
      "https://openalex.org/W2963800628",
      "https://openalex.org/W2963946945",
      "https://openalex.org/W2964043796",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964217371",
      "https://openalex.org/W2966715458",
      "https://openalex.org/W2967186499",
      "https://openalex.org/W2970231061",
      "https://openalex.org/W2970340522",
      "https://openalex.org/W2970608575",
      "https://openalex.org/W2979727876",
      "https://openalex.org/W2981601849",
      "https://openalex.org/W2981851019",
      "https://openalex.org/W2997886377",
      "https://openalex.org/W3023306062",
      "https://openalex.org/W3029418112",
      "https://openalex.org/W3030193665",
      "https://openalex.org/W3034253961",
      "https://openalex.org/W3034376488",
      "https://openalex.org/W3034500398",
      "https://openalex.org/W3034578524",
      "https://openalex.org/W3034758614",
      "https://openalex.org/W3034984114",
      "https://openalex.org/W3084181639",
      "https://openalex.org/W3090072755",
      "https://openalex.org/W3090449556",
      "https://openalex.org/W3091588028",
      "https://openalex.org/W3100923070",
      "https://openalex.org/W3101009265",
      "https://openalex.org/W3106571068",
      "https://openalex.org/W3108144224",
      "https://openalex.org/W3109097593",
      "https://openalex.org/W3135367836",
      "https://openalex.org/W3166396011",
      "https://openalex.org/W4285719527",
      "https://openalex.org/W4287603546",
      "https://openalex.org/W4297798492"
    ],
    "abstract": "Communication between human and mobile agents is getting increasingly important as such agents are widely deployed in our daily lives. Vision-and-Dialogue Navigation is one of the tasks that evaluate the agent's ability to interact with humans for assistance and navigate based on natural language responses. In this paper, we explore the Navigation from Dialogue History (NDH) task, which is based on the Cooperative Vision-and-Dialogue Navigation (CVDN) dataset, and present a state-of-the-art model which is built upon Vision-Language transformers. However, despite achieving competitive performance, we find that the agent in the NDH task is not evaluated appropriately by the primary metric \u2013 Goal Progress. By analyzing the performance mismatch between Goal Progress and other metrics (e.g., normalized Dynamic Time Warping) from our state-of-the-art model, we show that NDH's sub-path based task setup (i.e., navigating partial trajectory based on its correspondent subset of the full dialogue) does not provide the agent with enough supervision signal towards the goal region. Therefore, we propose a new task setup called NDH-Full which takes the full dialogue and the whole navigation path as one instance. We present a strong baseline model and show initial results on this new task. We further describe several approaches that we try, in order to improve the model performance (based on curriculum learning, pre-training, and data-augmentation), suggesting potential useful training methods on this new NDH-Full task.",
    "match_score": 0.9934640522875817
  },
  "Intention Reasoning Network for Multi-Domain End-to-end Task-Oriented Dialogue": {
    "openalex_id": "https://openalex.org/W3213852610",
    "publication_year": 2021,
    "cited_by_count": 5,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1793121960",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2184957013",
      "https://openalex.org/W2797625445",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2808093377",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2949141958",
      "https://openalex.org/W2950457956",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2962944953",
      "https://openalex.org/W2963201498",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963448850",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2970110247",
      "https://openalex.org/W2970260827",
      "https://openalex.org/W3034569646",
      "https://openalex.org/W3034879520",
      "https://openalex.org/W3035301094",
      "https://openalex.org/W3105732730",
      "https://openalex.org/W3106274079",
      "https://openalex.org/W3117865619",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Recent years has witnessed the remarkable success in end-to-end task-oriented dialog system, especially when incorporating external knowledge information. However, the quality of most existing models\u2019 generated response is still limited, mainly due to their lack of fine-grained reasoning on deterministic knowledge (w.r.t. conceptual tokens), which makes them difficult to capture the concept shifts and identify user\u2019s real intention in cross-task scenarios. To address these issues, we propose a novel intention mechanism to better model deterministic entity knowledge. Based on such a mechanism, we further propose an intention reasoning network (IR-Net), which consists of joint and multi-hop reasoning, to obtain intention-aware representations of conceptual tokens that can be used to capture the concept shifts involved in task-oriented conversations, so as to effectively identify user\u2019s intention and generate more accurate responses. Experimental results verify the effectiveness of IR-Net, showing that it achieves the state-of-the-art performance on two representative multi-domain dialog datasets.",
    "match_score": 1.0
  },
  "Are Training Samples Correlated Learning to Generate Dialogue Responses with Multiple References": {
    "openalex_id": "https://openalex.org/W2949782788",
    "publication_year": 2019,
    "cited_by_count": 46,
    "referenced_works": [
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2099471712",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2188365844",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2557436004",
      "https://openalex.org/W2565378226",
      "https://openalex.org/W2583741591",
      "https://openalex.org/W2584220694",
      "https://openalex.org/W2593696076",
      "https://openalex.org/W2604444020",
      "https://openalex.org/W2741323980",
      "https://openalex.org/W2753215597",
      "https://openalex.org/W2757121784",
      "https://openalex.org/W2788932366",
      "https://openalex.org/W2798984671",
      "https://openalex.org/W2808293489",
      "https://openalex.org/W2889502429",
      "https://openalex.org/W2890940245",
      "https://openalex.org/W2933374552",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963330684",
      "https://openalex.org/W2963567641",
      "https://openalex.org/W2963594498",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964178377",
      "https://openalex.org/W2964222296",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4294294142",
      "https://openalex.org/W4320013936"
    ],
    "abstract": "Due to its potential applications, open-domain dialogue generation has become popular and achieved remarkable progress in recent years, but sometimes suffers from generic responses. Previous models are generally trained based on 1-to-1 mapping from an input query to its response, which actually ignores the nature of 1-to-n mapping in dialogue that there may exist multiple valid responses corresponding to the same query. In this paper, we propose to utilize the multiple references by considering the correlation of different valid responses and modeling the 1-to-n mapping with a novel two-step generation architecture. The first generation phase extracts the common features of different responses which, combined with distinctive features obtained in the second phase, can generate multiple diverse and appropriate responses. Experimental results show that our proposed model can effectively improve the quality of response and outperform existing neural dialogue models on both automatic and human evaluations.",
    "match_score": 0.9948186528497409
  },
  "doc2dial A Goal-Oriented Document-Grounded Dialogue Dataset": {
    "openalex_id": "https://openalex.org/W3099590177",
    "publication_year": 2020,
    "cited_by_count": 84,
    "referenced_works": [
      "https://openalex.org/W150739662",
      "https://openalex.org/W1497300277",
      "https://openalex.org/W1602839414",
      "https://openalex.org/W2079758417",
      "https://openalex.org/W2166957049",
      "https://openalex.org/W2741802726",
      "https://openalex.org/W2757599232",
      "https://openalex.org/W2805172814",
      "https://openalex.org/W2810015029",
      "https://openalex.org/W2888302696",
      "https://openalex.org/W2888984656",
      "https://openalex.org/W2891304738",
      "https://openalex.org/W2923014074",
      "https://openalex.org/W2951846787",
      "https://openalex.org/W2962690139",
      "https://openalex.org/W2962966777",
      "https://openalex.org/W2963159690",
      "https://openalex.org/W2963310665",
      "https://openalex.org/W2963323070",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963748441",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964223283",
      "https://openalex.org/W2971737394",
      "https://openalex.org/W2980282514",
      "https://openalex.org/W2983409842",
      "https://openalex.org/W2985067290",
      "https://openalex.org/W3033540108",
      "https://openalex.org/W3034624105",
      "https://openalex.org/W3037780283",
      "https://openalex.org/W3159086726",
      "https://openalex.org/W4252076394",
      "https://openalex.org/W4287996196",
      "https://openalex.org/W4293651473"
    ],
    "abstract": "We introduce doc2dial, a new dataset of goal-oriented dialogues that are grounded in the associated documents. Inspired by how the authors compose documents for guiding end users, we first construct dialogue flows based on the content elements that corresponds to higher-level relations across text sections as well as lower-level relations between discourse units within a section. Then we present these dialogue flows to crowd contributors to create conversational utterances. The dataset includes over 4500 annotated conversations with an average of 14 turns that are grounded in over 450 documents from four domains. Compared to the prior document-grounded dialogue datasets, this dataset covers a variety of dialogue scenes in information-seeking conversations. For evaluating the versatility of the dataset, we introduce multiple dialogue modeling tasks and present baseline approaches.",
    "match_score": 0.9915966386554622
  },
  "Learning to Customize Model Structures for Few-shot Dialogue Generation Tasks": {
    "openalex_id": "https://openalex.org/W3025611493",
    "publication_year": 2020,
    "cited_by_count": 33,
    "referenced_works": [
      "https://openalex.org/W1958706068",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2172140247",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2311783643",
      "https://openalex.org/W2427497464",
      "https://openalex.org/W2432717477",
      "https://openalex.org/W2472819217",
      "https://openalex.org/W2601450892",
      "https://openalex.org/W2604763608",
      "https://openalex.org/W2605133118",
      "https://openalex.org/W2741363662",
      "https://openalex.org/W2748513770",
      "https://openalex.org/W2768195931",
      "https://openalex.org/W2768228940",
      "https://openalex.org/W2772564276",
      "https://openalex.org/W2787911506",
      "https://openalex.org/W2791666059",
      "https://openalex.org/W2804107505",
      "https://openalex.org/W2890719433",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2903334135",
      "https://openalex.org/W2911327180",
      "https://openalex.org/W2914752403",
      "https://openalex.org/W2921156067",
      "https://openalex.org/W2945367412",
      "https://openalex.org/W2945978556",
      "https://openalex.org/W2948727657",
      "https://openalex.org/W2949529330",
      "https://openalex.org/W2949568611",
      "https://openalex.org/W2951615109",
      "https://openalex.org/W2951980657",
      "https://openalex.org/W2952402849",
      "https://openalex.org/W2953111196",
      "https://openalex.org/W2962739339",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2963026768",
      "https://openalex.org/W2963137684",
      "https://openalex.org/W2963188990",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963341924",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963613359",
      "https://openalex.org/W2963643701",
      "https://openalex.org/W2963775850",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963866663",
      "https://openalex.org/W2963943197",
      "https://openalex.org/W2964105864",
      "https://openalex.org/W2964199361",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964316912",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2964588180",
      "https://openalex.org/W2970971561",
      "https://openalex.org/W3015189211",
      "https://openalex.org/W3113529090",
      "https://openalex.org/W3159575429",
      "https://openalex.org/W4285719527"
    ],
    "abstract": "Training the generative models with minimal corpus is one of the critical challenges for building open-domain dialogue systems. Existing methods tend to use the meta-learning framework which pre-trains the parameters on all non-target tasks then fine-tunes on the target task. However, fine-tuning distinguishes tasks from the parameter perspective but ignores the model-structure perspective, resulting in similar dialogue models for different tasks. In this paper, we propose an algorithm that can customize a unique dialogue model for each task in the few-shot setting. In our approach, each dialogue model consists of a shared module, a gating module, and a private module. The first two modules are shared among all the tasks, while the third one will differentiate into different network structures to better capture the characteristics of the corresponding task. The extensive experiments on two datasets show that our method outperforms all the baselines in terms of task consistency, response quality, and diversity.",
    "match_score": 1.0
  },
  "Memory Consolidation for Contextual Spoken Language Understanding with Dialogue Logistic Inference": {
    "openalex_id": "https://openalex.org/W2963594470",
    "publication_year": 2019,
    "cited_by_count": 10,
    "referenced_works": [
      "https://openalex.org/W648947103",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1550863320",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W1972595521",
      "https://openalex.org/W2004672974",
      "https://openalex.org/W2024632416",
      "https://openalex.org/W2094472029",
      "https://openalex.org/W2124895976",
      "https://openalex.org/W2132508435",
      "https://openalex.org/W2166293310",
      "https://openalex.org/W2473329891",
      "https://openalex.org/W2473965551",
      "https://openalex.org/W2575101493",
      "https://openalex.org/W2736272491",
      "https://openalex.org/W2741361549",
      "https://openalex.org/W2786464815",
      "https://openalex.org/W2803392141",
      "https://openalex.org/W2848493808",
      "https://openalex.org/W2888875316",
      "https://openalex.org/W2953052971",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963644595",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964121744"
    ],
    "abstract": "Dialogue contexts are proven helpful in the spoken language understanding (SLU) system and they are typically encoded with explicit memory representations. However, most of the previous models learn the context memory with only one objective to maximizing the SLU performance, leaving the context memory under-exploited. In this paper, we propose a new dialogue logistic inference (DLI) task to consolidate the context memory jointly with SLU in the multi-task framework. DLI is defined as sorting a shuffled dialogue session into its original logical order and shares the same memory encoder and retrieval mechanism as the SLU model. Our experimental results show that various popular contextual SLU models can benefit from our approach, and improvements are quite impressive, especially in slot filling.",
    "match_score": 1.0
  },
  "Toward Dialogue Modeling A Semantic Annotation Scheme for Questions and Answers": {
    "openalex_id": "https://openalex.org/W2966371977",
    "publication_year": 2019,
    "cited_by_count": 1,
    "referenced_works": [
      "https://openalex.org/W14996564",
      "https://openalex.org/W26963497",
      "https://openalex.org/W1559297830",
      "https://openalex.org/W1579838312",
      "https://openalex.org/W2053154970",
      "https://openalex.org/W2062946627",
      "https://openalex.org/W2070246124",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2149706766",
      "https://openalex.org/W2164777277",
      "https://openalex.org/W2957342141",
      "https://openalex.org/W4236137412"
    ],
    "abstract": "The present study proposes an annotation scheme for classifying the content\\nand discourse contribution of question-answer pairs. We propose detailed\\nguidelines for using the scheme and apply them to dialogues in English,\\nSpanish, and Dutch. Finally, we report on initial machine learning experiments\\nfor automatic annotation.\\n",
    "match_score": 0.9937106918238994
  },
  "AirConcierge Generating Task-Oriented Dialogue via Efficient Large-Scale Knowledge Retrieval": {
    "openalex_id": "https://openalex.org/W3100963818",
    "publication_year": 2020,
    "cited_by_count": 5,
    "referenced_works": [
      "https://openalex.org/W140747314",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1793121960",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2117448986",
      "https://openalex.org/W2119276199",
      "https://openalex.org/W2395389931",
      "https://openalex.org/W2560678344",
      "https://openalex.org/W2749436976",
      "https://openalex.org/W2751448157",
      "https://openalex.org/W2768409085",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2809324505",
      "https://openalex.org/W2891704263",
      "https://openalex.org/W2899771611",
      "https://openalex.org/W2912624765",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2962713807",
      "https://openalex.org/W2962776342",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964119254",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2972571786",
      "https://openalex.org/W4288601872",
      "https://openalex.org/W4293350112",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4301674784"
    ],
    "abstract": "Despite recent success in neural task-oriented dialogue systems, developing such a real-world system involves accessing large-scale knowledge bases (KBs), which cannot be simply encoded by neural approaches, such as memory network mechanisms. To alleviate the above problem, we propose , an end-to-end trainable text-to-SQL guided framework to learn a neural agent that interacts with KBs using the generated SQL queries. Specifically, the neural agent first learns to ask and confirm the customer's intent during the multi-turn interactions, then dynamically determining when to ground the user constraints into executable SQL queries so as to fetch relevant information from KBs. With the help of our method, the agent can use less but more accurate fetched results to generate useful responses efficiently, instead of incorporating the entire KBs. We evaluate the proposed method on the AirDialogue dataset, a large corpus released by Google, containing the conversations of customers booking flight tickets from the agent. The experimental results show that significantly improves over previous work in terms of accuracy and the BLEU score, which demonstrates not only the ability to achieve the given task but also the good quality of the generated dialogues.",
    "match_score": 0.9945945945945946
  },
  "Training Neural Response Selection for Task-Oriented Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2952267213",
    "publication_year": 2019,
    "cited_by_count": 84,
    "referenced_works": [
      "https://openalex.org/W295828404",
      "https://openalex.org/W836999996",
      "https://openalex.org/W1532325895",
      "https://openalex.org/W1539309091",
      "https://openalex.org/W1577202350",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1654173042",
      "https://openalex.org/W1677182931",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1958706068",
      "https://openalex.org/W2102531443",
      "https://openalex.org/W2115090890",
      "https://openalex.org/W2147152072",
      "https://openalex.org/W2149489931",
      "https://openalex.org/W2152180407",
      "https://openalex.org/W2155482025",
      "https://openalex.org/W2160458012",
      "https://openalex.org/W2183341477",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250473257",
      "https://openalex.org/W2250595267",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251861449",
      "https://openalex.org/W2252217313",
      "https://openalex.org/W2288878529",
      "https://openalex.org/W2306229986",
      "https://openalex.org/W2318810549",
      "https://openalex.org/W2339852062",
      "https://openalex.org/W2373570000",
      "https://openalex.org/W2413533759",
      "https://openalex.org/W2419539795",
      "https://openalex.org/W2468484304",
      "https://openalex.org/W2534274346",
      "https://openalex.org/W2581377246",
      "https://openalex.org/W2593751037",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2611029872",
      "https://openalex.org/W2611669587",
      "https://openalex.org/W2620558438",
      "https://openalex.org/W2622263826",
      "https://openalex.org/W2624413595",
      "https://openalex.org/W2766164908",
      "https://openalex.org/W2770102447",
      "https://openalex.org/W2786983967",
      "https://openalex.org/W2794557536",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2799042347",
      "https://openalex.org/W2806600904",
      "https://openalex.org/W2884814595",
      "https://openalex.org/W2885421725",
      "https://openalex.org/W2886198413",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2908331278",
      "https://openalex.org/W2909544278",
      "https://openalex.org/W2914120296",
      "https://openalex.org/W2923890923",
      "https://openalex.org/W2925618549",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2950444459",
      "https://openalex.org/W2951807227",
      "https://openalex.org/W2952357537",
      "https://openalex.org/W2953246132",
      "https://openalex.org/W2962739339",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962972936",
      "https://openalex.org/W2963026768",
      "https://openalex.org/W2963134326",
      "https://openalex.org/W2963149412",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963454111",
      "https://openalex.org/W2963469388",
      "https://openalex.org/W2963527209",
      "https://openalex.org/W2963662719",
      "https://openalex.org/W2963691849",
      "https://openalex.org/W2963702144",
      "https://openalex.org/W2963745931",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963854351",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2972437240",
      "https://openalex.org/W3121541553",
      "https://openalex.org/W4213009331",
      "https://openalex.org/W4252076394",
      "https://openalex.org/W4289377895",
      "https://openalex.org/W4290742115",
      "https://openalex.org/W4294641903",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4297736277",
      "https://openalex.org/W4297785815",
      "https://openalex.org/W4297798436",
      "https://openalex.org/W4300125564",
      "https://openalex.org/W4300427681",
      "https://openalex.org/W4320930577",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Matthew Henderson, Ivan Vuli\u0107, Daniela Gerz, I\u00f1igo Casanueva, Pawe\u0142 Budzianowski, Sam Coope, Georgios Spithourakis, Tsung-Hsien Wen, Nikola Mrk\u0161i\u0107, Pei-Hao Su. Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2019.",
    "match_score": 1.0
  },
  "Auto-Dialabel Labeling Dialogue Data with Unsupervised Learning": {
    "openalex_id": "https://openalex.org/W2889636191",
    "publication_year": 2018,
    "cited_by_count": 40,
    "referenced_works": [
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1521626219",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1714665356",
      "https://openalex.org/W1773652845",
      "https://openalex.org/W1969152782",
      "https://openalex.org/W2077302143",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2131876387",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251235149",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963963856"
    ],
    "abstract": "The lack of labeled data is one of the main challenges when building a task-oriented dialogue system. Existing dialogue datasets usually rely on human labeling, which is expensive, limited in size, and in low coverage. In this paper, we instead propose our framework auto-dialabel to automatically cluster the dialogue intents and slots. In this framework, we collect a set of context features, leverage an autoencoder for feature assembly, and adapt a dynamic hierarchical clustering method for intent and slot labeling. Experimental results show that our framework can promote human labeling cost to a great extent, achieve good intent clustering accuracy (84.1%), and provide reasonable and instructive slot labeling results.",
    "match_score": 0.9921259842519685
  },
  "Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization": {
    "openalex_id": "https://openalex.org/W3104257895",
    "publication_year": 2020,
    "cited_by_count": 121,
    "referenced_works": [
      "https://openalex.org/W34986029",
      "https://openalex.org/W1469909552",
      "https://openalex.org/W1626945812",
      "https://openalex.org/W1654173042",
      "https://openalex.org/W2053339128",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2106918957",
      "https://openalex.org/W2108325777",
      "https://openalex.org/W2250749132",
      "https://openalex.org/W2251183320",
      "https://openalex.org/W2327037637",
      "https://openalex.org/W2517028602",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2612675303",
      "https://openalex.org/W2768957049",
      "https://openalex.org/W2772704197",
      "https://openalex.org/W2796087471",
      "https://openalex.org/W2798821806",
      "https://openalex.org/W2807938752",
      "https://openalex.org/W2889984458",
      "https://openalex.org/W2905137389",
      "https://openalex.org/W2912762447",
      "https://openalex.org/W2949530332",
      "https://openalex.org/W2951855948",
      "https://openalex.org/W2952809536",
      "https://openalex.org/W2952890017",
      "https://openalex.org/W2962704246",
      "https://openalex.org/W2962809918",
      "https://openalex.org/W2962965405",
      "https://openalex.org/W2962985882",
      "https://openalex.org/W2963045354",
      "https://openalex.org/W2963204221",
      "https://openalex.org/W2963926728",
      "https://openalex.org/W2963929190",
      "https://openalex.org/W2964159778",
      "https://openalex.org/W2964262738",
      "https://openalex.org/W2970263339",
      "https://openalex.org/W2970419734",
      "https://openalex.org/W2970641574",
      "https://openalex.org/W3008323921",
      "https://openalex.org/W3014387963",
      "https://openalex.org/W3014468788",
      "https://openalex.org/W3015468748",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3041280310",
      "https://openalex.org/W3100560913",
      "https://openalex.org/W4241891521",
      "https://openalex.org/W4288089799"
    ],
    "abstract": "Text summarization is one of the most challenging and interesting problems in NLP. Although much attention has been paid to summarizing structured text like news reports or encyclopedia articles, summarizing conversations\u2014an essential part of human-human/machine interaction where most important pieces of information are scattered across various utterances of different speakers\u2014remains relatively under-investigated. This work proposes a multi-view sequence-to-sequence model by first extracting conversational structures of unstructured daily chats from different views to represent conversations and then utilizing a multi-view decoder to incorporate different views to generate dialogue summaries. Experiments on a large-scale dialogue summarization corpus demonstrated that our methods significantly outperformed previous state-of-the-art models via both automatic evaluations and human judgment. We also discussed specific challenges that current approaches faced with this task. We have publicly released our code at https://github.com/GT-SALT/Multi-View-Seq2Seq.",
    "match_score": 1.0
  },
  "Multi-Turn Dialogue Generation in E-Commerce Platform with the Context of Historical Dialogue": {
    "openalex_id": "https://openalex.org/W3099382298",
    "publication_year": 2020,
    "cited_by_count": 11,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2769906679",
      "https://openalex.org/W2789033601",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2806935606",
      "https://openalex.org/W2807791032",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2907042160",
      "https://openalex.org/W2908018635",
      "https://openalex.org/W2911994530",
      "https://openalex.org/W2913471463",
      "https://openalex.org/W2951807227",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962896208",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2965453734",
      "https://openalex.org/W2972732298",
      "https://openalex.org/W2982104868",
      "https://openalex.org/W2997793532",
      "https://openalex.org/W2998083599"
    ],
    "abstract": "As an important research topic, customer service dialogue generation tends to generate generic seller responses by leveraging current dialogue information. In this study, we propose a novel and extensible dialogue generation method by leveraging sellers\u2019 historical dialogue information, which can be both accessible and informative. By utilizing innovative historical dialogue representation learning and historical dialogue selection mechanism, the proposed model is capable of detecting most related responses from sellers\u2019 historical dialogues, which can further enhance the current dialogue generation quality. Unlike prior dialogue generation efforts, we treat each seller\u2019s historical dialogues as a list of Customer-Seller utterance pairs and allow the model to measure their different importance, and copy words directly from most relevant pairs. Extensive experimental results show that the proposed approach can generate high-quality responses that cater to specific sellers\u2019 characteristics and exhibit consistent superiority over baselines on a real-world multi-turn customer service dialogue dataset.",
    "match_score": 1.0
  },
  "A Compare Aggregate Transformer for Understanding Document-grounded Dialogue": {
    "openalex_id": "https://openalex.org/W3098595900",
    "publication_year": 2020,
    "cited_by_count": 8,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2140679639",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2551396370",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2752047430",
      "https://openalex.org/W2799176105",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2891103209",
      "https://openalex.org/W2891826200",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2922791555",
      "https://openalex.org/W2945052683",
      "https://openalex.org/W2945525091",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2951225599",
      "https://openalex.org/W2951508633",
      "https://openalex.org/W2952592807",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963212250",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963520511",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963945575",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2966404868",
      "https://openalex.org/W2972664115",
      "https://openalex.org/W2986867746",
      "https://openalex.org/W2995183464",
      "https://openalex.org/W2997300509",
      "https://openalex.org/W2998083599",
      "https://openalex.org/W3006065545",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4294170691",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Unstructured documents serving as external knowledge of the dialogues help to generate more informative responses. Previous research focused on knowledge selection (KS) in the document with dialogue. However, dialogue history that is not related to the current dialogue may introduce noise in the KS processing. In this paper, we propose a Compare Aggregate Transformer (CAT) to jointly denoise the dialogue context and aggregate the document information for response generation. We designed two different comparison mechanisms to reduce noise (before and during decoding). In addition, we propose two metrics for evaluating document utilization efficiency based on word overlap. Experimental results on the CMU_DoG dataset show that the proposed CAT model outperforms the state-of-the-art approach and strong baselines.",
    "match_score": 1.0
  },
  "Dr. Summarize Global Summarization of Medical Dialogue by Exploiting Local Structures.": {
    "openalex_id": "https://openalex.org/W3087025499",
    "publication_year": 2020,
    "cited_by_count": 5,
    "referenced_works": [
      "https://openalex.org/W1964625659",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2434099711",
      "https://openalex.org/W2574535369",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2889984458",
      "https://openalex.org/W2891022667",
      "https://openalex.org/W2898083715",
      "https://openalex.org/W2943249692",
      "https://openalex.org/W2952890017",
      "https://openalex.org/W2963929190",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2981456979",
      "https://openalex.org/W3019006697",
      "https://openalex.org/W3023363161"
    ],
    "abstract": "Understanding a medical conversation between a patient and a physician poses a unique natural language understanding challenge since it combines elements of standard open ended conversation with very domain specific elements that require expertise and medical knowledge. Summarization of medical conversations is a particularly important aspect of medical conversation understanding since it addresses a very real need in medical practice: capturing the most important aspects of a medical encounter so that they can be used for medical decision making and subsequent follow ups. In this paper we present a novel approach to medical conversation summarization that leverages the unique and independent local structures created when gathering a patient's medical history. Our approach is a variation of the pointer generator network where we introduce a penalty on the generator distribution, and we explicitly model negations. The model also captures important properties of medical conversations such as medical knowledge coming from standardized medical ontologies better than when those concepts are introduced explicitly. Through evaluation by doctors, we show that our approach is preferred on twice the number of summaries to the baseline pointer generator model and captures most or all of the information in 80% of the conversations making it a realistic alternative to costly manual summarization by medical experts.",
    "match_score": 0.9942196531791907
  },
  "Spot The Bot A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3092342765",
    "publication_year": 2020,
    "cited_by_count": 12,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1580788756",
      "https://openalex.org/W2029031299",
      "https://openalex.org/W2092817860",
      "https://openalex.org/W2153975459",
      "https://openalex.org/W2168490009",
      "https://openalex.org/W2280612018",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2889963245",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2951000191",
      "https://openalex.org/W2962729880",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2971883198",
      "https://openalex.org/W2990527403",
      "https://openalex.org/W2990787438",
      "https://openalex.org/W2992347006",
      "https://openalex.org/W2996511240",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3034723486"
    ],
    "abstract": "The lack of time-efficient and reliable evaluation methods hamper the development of conversational dialogue systems (chatbots). Evaluations requiring humans to converse with chatbots are time and cost-intensive, put high cognitive demands on the human judges, and yield low-quality results. In this work, we introduce \\emph{Spot The Bot}, a cost-efficient and robust evaluation framework that replaces human-bot conversations with conversations between bots. Human judges then only annotate for each entity in a conversation whether they think it is human or not (assuming there are humans participants in these conversations). These annotations then allow us to rank chatbots regarding their ability to mimic the conversational behavior of humans. Since we expect that all bots are eventually recognized as such, we incorporate a metric that measures which chatbot can uphold human-like behavior the longest, i.e., \\emph{Survival Analysis}. This metric has the ability to correlate a bot's performance to certain of its characteristics (e.g., \\ fluency or sensibleness), yielding interpretable results. The comparably low cost of our framework allows for frequent evaluations of chatbots during their evaluation cycle. We empirically validate our claims by applying \\emph{Spot The Bot} to three domains, evaluating several state-of-the-art chatbots, and drawing comparisons to related work. The framework is released as a ready-to-use tool.",
    "match_score": 0.9949748743718593
  },
  "On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2963064439",
    "publication_year": 2016,
    "cited_by_count": 95,
    "referenced_works": [
      "https://openalex.org/W218896052",
      "https://openalex.org/W744662145",
      "https://openalex.org/W1606347560",
      "https://openalex.org/W1617082848",
      "https://openalex.org/W1746819321",
      "https://openalex.org/W1932421248",
      "https://openalex.org/W1967071444",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1987326241",
      "https://openalex.org/W1989996186",
      "https://openalex.org/W1996957559",
      "https://openalex.org/W2005708641",
      "https://openalex.org/W2007221309",
      "https://openalex.org/W2047335008",
      "https://openalex.org/W2054716580",
      "https://openalex.org/W2057244568",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2078429476",
      "https://openalex.org/W2099201756",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2125031621",
      "https://openalex.org/W2129297552",
      "https://openalex.org/W2140539195",
      "https://openalex.org/W2140656735",
      "https://openalex.org/W2151814822",
      "https://openalex.org/W2153971568",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2157826563",
      "https://openalex.org/W2158139315",
      "https://openalex.org/W2168490009",
      "https://openalex.org/W2187089797",
      "https://openalex.org/W2214131199",
      "https://openalex.org/W2250558341",
      "https://openalex.org/W2250679999",
      "https://openalex.org/W2251221343",
      "https://openalex.org/W2278865652",
      "https://openalex.org/W2289601637",
      "https://openalex.org/W2296712013",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2540392403",
      "https://openalex.org/W2903158431",
      "https://openalex.org/W2950133940",
      "https://openalex.org/W2963252944"
    ],
    "abstract": "The ability to compute an accurate reward function is essential for optimising a dialogue policy via reinforcement learning. In real-world applications, using explicit user feedback as the reward signal is often unreliable and costly to collect. This problem can be mitigated if the user's intent is known in advance or data is available to pre-train a task success predictor off-line. In practice neither of these apply for most real world applications. Here we propose an on-line learning framework whereby the dialogue policy is jointly trained alongside the reward model via active learning with a Gaussian process model. This Gaussian process operates on a continuous space dialogue representation generated in an unsupervised fashion using a recurrent neural network encoder-decoder. The experimental results demonstrate that the proposed framework is able to significantly reduce data annotation costs and mitigate noisy user feedback in dialogue policy learning.",
    "match_score": 1.0
  },
  "Learning Efficient Dialogue Policy from Demonstrations through Shaping": {
    "openalex_id": "https://openalex.org/W3034330559",
    "publication_year": 2020,
    "cited_by_count": 17,
    "referenced_works": [
      "https://openalex.org/W1777239053",
      "https://openalex.org/W1786470251",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2040123554",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2098441518",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2158969944",
      "https://openalex.org/W2164419340",
      "https://openalex.org/W2290053245",
      "https://openalex.org/W2397581010",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2507592741",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2740191615",
      "https://openalex.org/W2759104452",
      "https://openalex.org/W2765111838",
      "https://openalex.org/W2788862220",
      "https://openalex.org/W2798494119",
      "https://openalex.org/W2892043231",
      "https://openalex.org/W2901893112",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2962730405",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963252944",
      "https://openalex.org/W2963376229",
      "https://openalex.org/W2963692154",
      "https://openalex.org/W2964044380",
      "https://openalex.org/W2970828515",
      "https://openalex.org/W3016143584",
      "https://openalex.org/W3104546989",
      "https://openalex.org/W4312609624"
    ],
    "abstract": "Training a task-oriented dialogue agent with reinforcement learning is prohibitively expensive since it requires a large volume of interactions with users. Human demonstrations can be used to accelerate learning progress. However, how to effectively leverage demonstrations to learn dialogue policy remains less explored. In this paper, we present S\u02c62Agent that efficiently learns dialogue policy from demonstrations through policy shaping and reward shaping. We use an imitation model to distill knowledge from demonstrations, based on which policy shaping estimates feedback on how the agent should act in policy space. Reward shaping is then incorporated to bonus state-actions similar to demonstrations explicitly in value space encouraging better exploration. The effectiveness of the proposed S\u02c62Agentt is demonstrated in three dialogue domains and a challenging domain adaptation task with both user simulator evaluation and human evaluation.",
    "match_score": 1.0
  },
  "Counterfactual Off-Policy Training for Neural Dialogue Generation": {
    "openalex_id": "https://openalex.org/W3103857453",
    "publication_year": 2020,
    "cited_by_count": 18,
    "referenced_works": [
      "https://openalex.org/W295828404",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W2006666561",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2094536313",
      "https://openalex.org/W2099471712",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2109814494",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2141708418",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2296701362",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2339852062",
      "https://openalex.org/W2396229782",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2578354947",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2786983967",
      "https://openalex.org/W2799037524",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2890969459",
      "https://openalex.org/W2892153332",
      "https://openalex.org/W2900677074",
      "https://openalex.org/W2903571680",
      "https://openalex.org/W2946442465",
      "https://openalex.org/W2951883832",
      "https://openalex.org/W2952993422",
      "https://openalex.org/W2962681511",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963064439",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963212250",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963371754",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963559013",
      "https://openalex.org/W2963879591",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2963986868",
      "https://openalex.org/W2964238590",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2965718149",
      "https://openalex.org/W2969379005",
      "https://openalex.org/W2970453125",
      "https://openalex.org/W2977235550",
      "https://openalex.org/W2979702391",
      "https://openalex.org/W2985026420",
      "https://openalex.org/W2994934025",
      "https://openalex.org/W3015812362",
      "https://openalex.org/W3106806814",
      "https://openalex.org/W4244151341",
      "https://openalex.org/W4246855866",
      "https://openalex.org/W4289288202",
      "https://openalex.org/W4300125564",
      "https://openalex.org/W4320013936"
    ],
    "abstract": "Open-domain dialogue generation suffers from the data insufficiency problem due to the vast size of potential responses. In this paper, we propose to explore potential responses by counterfactual reasoning. Given an observed response, the counterfactual reasoning model automatically infers the outcome of an alternative policy that could have been taken. The resulting counterfactual response synthesized in hindsight is of higher quality than the response synthesized from scratch. Training on the counterfactual responses under the adversarial learning framework helps to explore the high-reward area of the potential response space. An empirical study on the DailyDialog dataset shows that our approach significantly outperforms the HRED model as well as the conventional adversarial learning approaches.",
    "match_score": 1.0
  },
  "You Impress Me Dialogue Generation via Mutual Persona Perception": {
    "openalex_id": "https://openalex.org/W3035044096",
    "publication_year": 2020,
    "cited_by_count": 141,
    "referenced_works": [
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1821462560",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2127271556",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2155027007",
      "https://openalex.org/W2156718681",
      "https://openalex.org/W2688962481",
      "https://openalex.org/W2796433937",
      "https://openalex.org/W2807791032",
      "https://openalex.org/W2890394457",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2900227126",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2914099135",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2945978556",
      "https://openalex.org/W2949211412",
      "https://openalex.org/W2962852262",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963225934",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963688701",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2965718149",
      "https://openalex.org/W2970794693",
      "https://openalex.org/W2970971581",
      "https://openalex.org/W2971277071",
      "https://openalex.org/W2980282514",
      "https://openalex.org/W2983160116",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4295312788",
      "https://openalex.org/W4300326073",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Despite the continuing efforts to improve the engagingness and consistency of chit-chat dialogue systems, the majority of current work simply focus on mimicking human-like responses, leaving understudied the aspects of modeling understanding between interlocutors. The research in cognitive science, instead, suggests that understanding is an essential signal for a high-quality chit-chat conversation. Motivated by this, we propose P\u02c62 Bot, a transmitter-receiver based framework with the aim of explicitly modeling understanding. Specifically, P\u02c62 Bot incorporates mutual persona perception to enhance the quality of personalized dialogue generation. Experiments on a large public dataset, Persona-Chat, demonstrate the effectiveness of our approach, with a considerable boost over the state-of-the-art baselines across both automatic metrics and human evaluations.",
    "match_score": 0.9922480620155039
  },
  "Deep Active Learning for Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2964133280",
    "publication_year": 2017,
    "cited_by_count": 44,
    "referenced_works": [
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W2125320996",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2153653739",
      "https://openalex.org/W2337601653",
      "https://openalex.org/W2402930259",
      "https://openalex.org/W2412715517",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2418993857",
      "https://openalex.org/W2557436004",
      "https://openalex.org/W2558661633",
      "https://openalex.org/W2565274151",
      "https://openalex.org/W2579486552",
      "https://openalex.org/W2604688337",
      "https://openalex.org/W2605968924",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2949555952",
      "https://openalex.org/W2950314731",
      "https://openalex.org/W2962707484",
      "https://openalex.org/W2962776342",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963319085",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963958388",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W4241645538",
      "https://openalex.org/W4293775587"
    ],
    "abstract": "We propose an online, end-to-end, neural generative conversational model for open-domain dialogue. It is trained using a unique combination of offline two-phase supervised learning and online human-in-the-loop active learning. While most existing research proposes offline supervision or hand-crafted reward functions for online reinforcement, we devise a novel interactive learning mechanism based on hamming-diverse beam search for response generation and one-character user-feedback at each step. Experiments show that our model inherently promotes the generation of semantically relevant and interesting responses, and can be used to train agents with customized personas, moods and conversational styles.",
    "match_score": 1.0
  },
  "Semi-Supervised Dialogue Policy Learning via Stochastic Reward Estimation": {
    "openalex_id": "https://openalex.org/W3034930293",
    "publication_year": 2020,
    "cited_by_count": 18,
    "referenced_works": [
      "https://openalex.org/W592244745",
      "https://openalex.org/W769612788",
      "https://openalex.org/W1486649854",
      "https://openalex.org/W1786470251",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1987326241",
      "https://openalex.org/W2108501770",
      "https://openalex.org/W2514480375",
      "https://openalex.org/W2736601468",
      "https://openalex.org/W2746626573",
      "https://openalex.org/W2756946152",
      "https://openalex.org/W2798494119",
      "https://openalex.org/W2806936550",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2903396356",
      "https://openalex.org/W2915295540",
      "https://openalex.org/W2921218568",
      "https://openalex.org/W2947212824",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2949476504",
      "https://openalex.org/W2951021014",
      "https://openalex.org/W2951519300",
      "https://openalex.org/W2962912551",
      "https://openalex.org/W2963064439",
      "https://openalex.org/W2963508354",
      "https://openalex.org/W2963692154",
      "https://openalex.org/W2963712524",
      "https://openalex.org/W2963858765",
      "https://openalex.org/W2963905903",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964040467",
      "https://openalex.org/W2964113870",
      "https://openalex.org/W2964158321",
      "https://openalex.org/W2970415880",
      "https://openalex.org/W2970828515",
      "https://openalex.org/W2973721503",
      "https://openalex.org/W2976051099",
      "https://openalex.org/W2977363161",
      "https://openalex.org/W2979805229",
      "https://openalex.org/W2998201756",
      "https://openalex.org/W3103801215",
      "https://openalex.org/W4288322145",
      "https://openalex.org/W4288614963",
      "https://openalex.org/W4306716473",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Dialogue policy optimization often obtains feedback until task completion in task-oriented dialogue systems. This is insufficient for training intermediate dialogue turns since supervision signals (or rewards) are only provided at the end of dialogues. To address this issue, reward learning has been introduced to learn from state-action pairs of an optimal policy to provide turn-by-turn rewards. This approach requires complete state-action annotations of human-to-human dialogues (i.e., expert demonstrations), which is labor intensive. To overcome this limitation, we propose a novel reward learning approach for semi-supervised policy learning. The proposed approach learns a dynamics model as the reward function which models dialogue progress (i.e., state-action sequences) based on expert demonstrations, either with or without annotations. The dynamics model computes rewards by predicting whether the dialogue progress is consistent with expert demonstrations. We further propose to learn action embeddings for a better generalization of the reward function. The proposed approach outperforms competitive policy learning baselines on MultiWOZ, a benchmark multi-domain dataset.",
    "match_score": 1.0
  },
  "Evaluating and Enhancing the Robustness of Dialogue Systems A Case Study on a Negotiation Agent": {
    "openalex_id": "https://openalex.org/W2926587947",
    "publication_year": 2019,
    "cited_by_count": 45,
    "referenced_works": [
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W2243397390",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2327501763",
      "https://openalex.org/W2562979205",
      "https://openalex.org/W2603266952",
      "https://openalex.org/W2603766943",
      "https://openalex.org/W2609368435",
      "https://openalex.org/W2735135478",
      "https://openalex.org/W2766108848",
      "https://openalex.org/W2799194071",
      "https://openalex.org/W2891519874",
      "https://openalex.org/W2891704263",
      "https://openalex.org/W2895033754",
      "https://openalex.org/W2962710014",
      "https://openalex.org/W2962818281",
      "https://openalex.org/W2962852262",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962965405",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963207607",
      "https://openalex.org/W2963217826",
      "https://openalex.org/W2963496101",
      "https://openalex.org/W2963834268",
      "https://openalex.org/W2963857521",
      "https://openalex.org/W2963881016",
      "https://openalex.org/W2963969878",
      "https://openalex.org/W2964153729",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964253222",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964346747",
      "https://openalex.org/W2979450790",
      "https://openalex.org/W2998277219",
      "https://openalex.org/W3013371788",
      "https://openalex.org/W3093419064"
    ],
    "abstract": "Recent research has demonstrated that goal-oriented dialogue agents trained on large datasets can achieve striking performance when interacting with human users. In real world applications, however, it is important to ensure that the agent performs smoothly interacting with not only regular users but also those malicious ones who would attack the system through interactions in order to achieve goals for their own advantage. In this paper, we develop algorithms to evaluate the robustness of a dialogue agent by carefully designed attacks using adversarial agents. Those attacks are performed in both black-box and white-box settings. Furthermore, we demonstrate that adversarial training using our attacks can significantly improve the robustness of a goal-oriented dialogue system. On a case-study of the negotiation agent developed by (Lewis et al., 2017), our attacks reduced the average advantage of rewards between the attacker and the trained RL-based agent from 2.68 to \u22125.76 on a scale from \u221210 to 10 for randomized goals. Moreover, with the proposed adversarial training, we are able to improve the robustness of negotiation agents by 1.5 points on average against all our attacks. \u00a9 2019 Association for Computational Linguistics",
    "match_score": 0.9947643979057592
  },
  "PyDial A Multi-domain Statistical Dialogue System Toolkit": {
    "openalex_id": "https://openalex.org/W2739936944",
    "publication_year": 2017,
    "cited_by_count": 145,
    "referenced_works": [
      "https://openalex.org/W182831726",
      "https://openalex.org/W200223693",
      "https://openalex.org/W1492935830",
      "https://openalex.org/W1503552041",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2047335008",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2120375264",
      "https://openalex.org/W2127838323",
      "https://openalex.org/W2159875193",
      "https://openalex.org/W2168490009",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2288878529",
      "https://openalex.org/W2291723583",
      "https://openalex.org/W2476025067",
      "https://openalex.org/W2508347479",
      "https://openalex.org/W2564070522",
      "https://openalex.org/W2792382948",
      "https://openalex.org/W2963064439",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964269028"
    ],
    "abstract": "Stefan Ultes, Lina M. Rojas-Barahona, Pei-Hao Su, David Vandyke, Dongho Kim, I\u00f1igo Casanueva, Pawe\u0142 Budzianowski, Nikola Mrk\u0161i\u0107, Tsung-Hsien Wen, Milica Ga\u0161i\u0107, Steve Young. Proceedings of ACL 2017, System Demonstrations. 2017.",
    "match_score": 0.991304347826087
  },
  "A Hierarchical Neural Model for Learning Sequences of Dialogue Acts": {
    "openalex_id": "https://openalex.org/W2741675028",
    "publication_year": 2017,
    "cited_by_count": 32,
    "referenced_works": [
      "https://openalex.org/W77001256",
      "https://openalex.org/W1482132414",
      "https://openalex.org/W1526096287",
      "https://openalex.org/W1612268991",
      "https://openalex.org/W1810943226",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1911976934",
      "https://openalex.org/W1934019294",
      "https://openalex.org/W2003458432",
      "https://openalex.org/W2006969979",
      "https://openalex.org/W2024213584",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2106226466",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2142416747",
      "https://openalex.org/W2146502635",
      "https://openalex.org/W2176263492",
      "https://openalex.org/W2193413348",
      "https://openalex.org/W2312383716",
      "https://openalex.org/W2401527985",
      "https://openalex.org/W2949640717",
      "https://openalex.org/W2964139507",
      "https://openalex.org/W2964308564"
    ],
    "abstract": "We propose a novel hierarchical Recurrent Neural Network (RNN) for learning sequences of Dialogue Acts (DAs). The input in this task is a sequence of utterances (i.e., conversational contributions) comprising a sequence of tokens, and the output is a sequence of DA labels (one label per utterance). Our model leverages the hierarchical nature of dialogue data by using two nested RNNs that capture long-range dependencies at the dialogue level and the utterance level. This model is combined with an attention mechanism that focuses on salient tokens in utterances. Our experimental results show that our model outperforms strong baselines on two popular datasets, Switchboard and MapTask; and our detailed empirical analysis highlights the impact of each aspect of our model.",
    "match_score": 1.0
  },
  "Dialogue Natural Language Inference": {
    "openalex_id": "https://openalex.org/W2962989446",
    "publication_year": 2019,
    "cited_by_count": 247,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1840435438",
      "https://openalex.org/W2087451659",
      "https://openalex.org/W2130158090",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2250790822",
      "https://openalex.org/W2608787653",
      "https://openalex.org/W2788496822",
      "https://openalex.org/W2808633496",
      "https://openalex.org/W2890394457",
      "https://openalex.org/W2891308403",
      "https://openalex.org/W2898658996",
      "https://openalex.org/W2923014074",
      "https://openalex.org/W2950819771",
      "https://openalex.org/W2962736243",
      "https://openalex.org/W2962765866",
      "https://openalex.org/W2962843521",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2963310665",
      "https://openalex.org/W2963706350",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963846996",
      "https://openalex.org/W2963918774",
      "https://openalex.org/W2963977107",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964321317",
      "https://openalex.org/W2964352131"
    ],
    "abstract": "Consistency is a long standing issue faced by dialogue models. In this paper, we frame the consistency of dialogue agents as natural language inference (NLI) and create a new natural language inference dataset called Dialogue NLI. We propose a method which demonstrates that a model trained on Dialogue NLI can be used to improve the consistency of a dialogue model, and evaluate the method with human evaluation and with automatic metrics on a suite of evaluation sets designed to measure a dialogue model\u2019s consistency.",
    "match_score": 1.0
  },
  "Will I Sound Like Me Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness": {
    "openalex_id": "https://openalex.org/W3106007100",
    "publication_year": 2020,
    "cited_by_count": 44,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1967679121",
      "https://openalex.org/W1993979041",
      "https://openalex.org/W2107473960",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2159056499",
      "https://openalex.org/W2165155944",
      "https://openalex.org/W2313372168",
      "https://openalex.org/W2506483933",
      "https://openalex.org/W2574790321",
      "https://openalex.org/W2583010282",
      "https://openalex.org/W2784400615",
      "https://openalex.org/W2805984364",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2915330159",
      "https://openalex.org/W2916772188",
      "https://openalex.org/W2921065408",
      "https://openalex.org/W2929900303",
      "https://openalex.org/W2945978556",
      "https://openalex.org/W2951064641",
      "https://openalex.org/W2951583236",
      "https://openalex.org/W2953044442",
      "https://openalex.org/W2962846267",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2962989446",
      "https://openalex.org/W2963109634",
      "https://openalex.org/W2963318456",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963640662",
      "https://openalex.org/W2963726321",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964183327",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2979826702",
      "https://openalex.org/W2983160116",
      "https://openalex.org/W2995969307",
      "https://openalex.org/W3034720580",
      "https://openalex.org/W3035044096",
      "https://openalex.org/W3035068109",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W4288088456",
      "https://openalex.org/W4288624561"
    ],
    "abstract": "We explore the task of improving persona consistency of dialogue agents. Recent models tackling consistency often train with additional Natural Language Inference (NLI) labels or attach trained extra modules to the generative agent for maintaining consistency. However, such additional labels and training can be demanding. Also, we find even the best-performing persona-based agents are insensitive to contradictory words. Inspired by social cognition and pragmatics, we endow existing dialogue agents with public self-consciousness on the fly through an imaginary listener. Our approach, based on the Rational Speech Acts framework (Frank and Goodman, 2012), can enforce dialogue agents to refrain from uttering contradiction. We further extend the framework by learning the distractor selection, which has been usually done manually or randomly. Results on Dialogue NLI (Welleck et al., 2019) and PersonaChat (Zhang et al., 2018) dataset show that our approach reduces contradiction and improves consistency of existing dialogue models. Moreover, we show that it can be generalized to improve context-consistency beyond persona in dialogues.",
    "match_score": 0.9950248756218906
  },
  "Entity-Consistent End-to-end Task-Oriented Dialogue System with KB Retriever": {
    "openalex_id": "https://openalex.org/W2970260827",
    "publication_year": 2019,
    "cited_by_count": 57,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1793121960",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2107598941",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2250265269",
      "https://openalex.org/W2251135946",
      "https://openalex.org/W2251960799",
      "https://openalex.org/W2280798142",
      "https://openalex.org/W2534274346",
      "https://openalex.org/W2547875792",
      "https://openalex.org/W2749436976",
      "https://openalex.org/W2808093377",
      "https://openalex.org/W2949141958",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2962944953",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963134326",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963929190",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W3106274079",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4297728544"
    ],
    "abstract": "Libo Qin, Yijia Liu, Wanxiang Che, Haoyang Wen, Yangming Li, Ting Liu. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "Evaluating Persuasion Strategies and Deep Reinforcement Learning methods for Negotiation Dialogue agents": {
    "openalex_id": "https://openalex.org/W2607380417",
    "publication_year": 2017,
    "cited_by_count": 36,
    "referenced_works": [
      "https://openalex.org/W64203724",
      "https://openalex.org/W1508859482",
      "https://openalex.org/W1757796397",
      "https://openalex.org/W2037892284",
      "https://openalex.org/W2166100419",
      "https://openalex.org/W2175723363",
      "https://openalex.org/W2231198303",
      "https://openalex.org/W2245560598",
      "https://openalex.org/W2251854674",
      "https://openalex.org/W2257979135",
      "https://openalex.org/W2471576823",
      "https://openalex.org/W2614087390",
      "https://openalex.org/W2963993719",
      "https://openalex.org/W4205363819",
      "https://openalex.org/W4298857966"
    ],
    "abstract": "In this paper we present a comparative evaluation of various negotiation strategies within an online version of the game \u201cSettlers of Catan\u201d. The comparison is based on human subjects playing games against artificial game-playingagents (\u2018bots\u2019) which implement different negotiation dialogue strategies, using a chat dialogue interface to negotiate trades. Our results suggest that a negotiation strategy that uses persuasion, as well as a strategy that is trained from data using Deep Reinforcement Learning, both lead to an improved win rate against humans, compared to previous rule-based and supervised learning baseline dialogue negotiators.",
    "match_score": 1.0
  },
  "Using Paraphrasing and Memory-Augmented Models to Combat Data Sparsity in Question Interpretation with a Virtual Patient Dialogue System": {
    "openalex_id": "https://openalex.org/W2807186566",
    "publication_year": 2018,
    "cited_by_count": 14,
    "referenced_works": [
      "https://openalex.org/W6908809",
      "https://openalex.org/W1570452348",
      "https://openalex.org/W1614298861",
      "https://openalex.org/W1665214252",
      "https://openalex.org/W1832693441",
      "https://openalex.org/W2053994556",
      "https://openalex.org/W2081580037",
      "https://openalex.org/W2084413241",
      "https://openalex.org/W2091494174",
      "https://openalex.org/W2131726681",
      "https://openalex.org/W2131744502",
      "https://openalex.org/W2152814412",
      "https://openalex.org/W2158899491",
      "https://openalex.org/W2167662839",
      "https://openalex.org/W2251044566",
      "https://openalex.org/W2251048167",
      "https://openalex.org/W2293665254",
      "https://openalex.org/W2474466460",
      "https://openalex.org/W2508866736",
      "https://openalex.org/W2560203405",
      "https://openalex.org/W2583010282",
      "https://openalex.org/W2741049976",
      "https://openalex.org/W2756554273",
      "https://openalex.org/W2902541777",
      "https://openalex.org/W2952230511",
      "https://openalex.org/W2953044442",
      "https://openalex.org/W2962801832",
      "https://openalex.org/W2963341924",
      "https://openalex.org/W4386506836"
    ],
    "abstract": "When interpreting questions in a virtual patient dialogue system one must inevitably tackle the challenge of a long tail of relatively infrequently asked questions. To make progress on this challenge, we investigate the use of paraphrasing for data augmentation and neural memory-based classification, finding that the two methods work best in combination. In particular, we find that the neural memory-based approach not only outperforms a straight CNN classifier on low frequency questions, but also takes better advantage of the augmented data created by paraphrasing, together yielding a nearly 10% absolute improvement in accuracy on the least frequently asked questions.",
    "match_score": 1.0
  },
  "Global-Locally Self-Attentive Encoder for Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W2798367796",
    "publication_year": 2018,
    "cited_by_count": 233,
    "referenced_works": [
      "https://openalex.org/W1497675750",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W1814992895",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1989996186",
      "https://openalex.org/W2030290736",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2119595900",
      "https://openalex.org/W2133013156",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2148522164",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251044566",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251235149",
      "https://openalex.org/W2251355666",
      "https://openalex.org/W2267186426",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2463565445",
      "https://openalex.org/W2550821151",
      "https://openalex.org/W2551396370",
      "https://openalex.org/W2552027021",
      "https://openalex.org/W2556468274",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2612675303",
      "https://openalex.org/W2626792426",
      "https://openalex.org/W2740765036",
      "https://openalex.org/W2914746235",
      "https://openalex.org/W2962847367",
      "https://openalex.org/W2963243930",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963768805",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963871484",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964222246",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Dialogue state tracking, which estimates user goals and requests given the dialogue context, is an essential part of task-oriented dialogue systems. In this paper, we propose the Global-Locally Self-Attentive Dialogue State Tracker (GLAD), which learns representations of the user utterance and previous system actions with global-local modules. Our model uses global modules to shares parameters between estimators for different types (called slots) of dialogue states, and uses local modules to learn slot-specific features. We show that this significantly improves tracking of rare states. GLAD obtains 88.3% joint goal accuracy and 96.4% request accuracy on the WoZ state tracking task, outperforming prior work by 3.9% and 4.8%. On the DSTC2 task, our model obtains 74.7% joint goal accuracy and 97.3% request accuracy, outperforming prior work by 1.3% and 0.8%",
    "match_score": 1.0
  },
  "Dialogue Generation on Infrequent Sentence Functions via Structured Meta-Learning": {
    "openalex_id": "https://openalex.org/W3098314733",
    "publication_year": 2020,
    "cited_by_count": 3,
    "referenced_works": [
      "https://openalex.org/W1743832209",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1985660488",
      "https://openalex.org/W2039585592",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2604763608",
      "https://openalex.org/W2799037524",
      "https://openalex.org/W2804552794",
      "https://openalex.org/W2888541716",
      "https://openalex.org/W2945978556",
      "https://openalex.org/W2946757877",
      "https://openalex.org/W2949747155",
      "https://openalex.org/W2951980657",
      "https://openalex.org/W2952420867",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962788902",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2964588180",
      "https://openalex.org/W4297813345"
    ],
    "abstract": "Sentence function is an important linguistic feature indicating the communicative purpose in uttering a sentence. Incorporating sentence functions into conversations has shown improvements in the quality of generated responses. However, the number of utterances for different types of fine-grained sentence functions is extremely imbalanced. Besides a small number of high-resource sentence functions, a large portion of sentence functions is infrequent. Consequently, dialogue generation conditioned on these infrequent sentence functions suffers from data deficiency. In this paper, we investigate a structured meta-learning (SML) approach for dialogue generation on infrequent sentence functions. We treat dialogue generation conditioned on different sentence functions as separate tasks, and apply model-agnostic meta-learning to high-resource sentence functions data. Furthermore, SML enhances meta-learning effectiveness by promoting knowledge customization among different sentence functions but simultaneously preserving knowledge generalization for similar sentence functions. Experimental results demonstrate that SML not only improves the informativeness and relevance of generated responses, but also can generate responses consistent with the target sentence functions. Code will be public to facilitate the research along this line.",
    "match_score": 1.0
  },
  "DyKgChat Benchmarking Dialogue Generation Grounding on Dynamic Knowledge Graphs": {
    "openalex_id": "https://openalex.org/W2971236040",
    "publication_year": 2019,
    "cited_by_count": 76,
    "referenced_works": [
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1525961042",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1756422141",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W1958706068",
      "https://openalex.org/W2053154970",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2101848544",
      "https://openalex.org/W2127795553",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2164777277",
      "https://openalex.org/W2250635077",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2739716023",
      "https://openalex.org/W2740107682",
      "https://openalex.org/W2754194354",
      "https://openalex.org/W2769099080",
      "https://openalex.org/W2775082024",
      "https://openalex.org/W2785708181",
      "https://openalex.org/W2799037524",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2890961898",
      "https://openalex.org/W2897513992",
      "https://openalex.org/W2950457956",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2953290652",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2962881743",
      "https://openalex.org/W2962886429",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963371447",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963494889",
      "https://openalex.org/W2963544700",
      "https://openalex.org/W2963546833",
      "https://openalex.org/W2963653601",
      "https://openalex.org/W2963858333",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2964072618",
      "https://openalex.org/W2964152081",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964199361",
      "https://openalex.org/W4285719527",
      "https://openalex.org/W4297733535",
      "https://openalex.org/W4298422451"
    ],
    "abstract": "Yi-Lin Tuan, Yun-Nung Chen, Hung-yi Lee. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 0.9937106918238994
  },
  "Data Manipulation Towards Effective Instance Learning for Neural Dialogue Generation via Learning to Augment and Reweight": {
    "openalex_id": "https://openalex.org/W3035282664",
    "publication_year": 2020,
    "cited_by_count": 57,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1666146316",
      "https://openalex.org/W1958706068",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W2111362445",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2419539795",
      "https://openalex.org/W2516907570",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2547875792",
      "https://openalex.org/W2594978815",
      "https://openalex.org/W2595715041",
      "https://openalex.org/W2752172973",
      "https://openalex.org/W2756978580",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2795282075",
      "https://openalex.org/W2799176105",
      "https://openalex.org/W2808293489",
      "https://openalex.org/W2889326796",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2904444765",
      "https://openalex.org/W2905266130",
      "https://openalex.org/W2947375732",
      "https://openalex.org/W2950142196",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962721878",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963216553",
      "https://openalex.org/W2963330684",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963371670",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963443335",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963545917",
      "https://openalex.org/W2963564796",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963958388",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964137876",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2965282611",
      "https://openalex.org/W2965718149",
      "https://openalex.org/W2970295111",
      "https://openalex.org/W2970418174",
      "https://openalex.org/W2971252690",
      "https://openalex.org/W2982225063",
      "https://openalex.org/W2997657234",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3035331128",
      "https://openalex.org/W4288102237",
      "https://openalex.org/W4295253143",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Current state-of-the-art neural dialogue models learn from human conversations following the data-driven paradigm. As such, a reliable training corpus is the crux of building a robust and well-behaved dialogue model. However, due to the open-ended nature of human conversations, the quality of user-generated training data varies greatly, and effective training samples are typically insufficient while noisy samples frequently appear. This impedes the learning of those data-driven neural dialogue models. Therefore, effective dialogue learning requires not only more reliable learning samples, but also fewer noisy samples. In this paper, we propose a data manipulation framework to proactively reshape the data distribution towards reliable samples by augmenting and highlighting effective learning samples as well as reducing the effect of inefficient samples simultaneously. In particular, the data manipulation model selectively augments the training samples and assigns an importance weight to each instance to reform the training data. Note that, the proposed data manipulation framework is fully data-driven and learnable. It not only manipulates training samples to optimize the dialogue generation model, but also learns to increase its manipulation skills through gradient descent with validation samples. Extensive experiments show that our framework can improve the dialogue generation performance with respect to various automatic evaluation metrics and human judgments.",
    "match_score": 0.9958847736625515
  },
  "Wikification of Concept Mentions within Spoken Dialogues Using Domain Constraints from Wikipedia": {
    "openalex_id": "https://openalex.org/W2252199413",
    "publication_year": 2015,
    "cited_by_count": 3,
    "referenced_works": [
      "https://openalex.org/W86887328",
      "https://openalex.org/W1533642089",
      "https://openalex.org/W1548663377",
      "https://openalex.org/W2047221353",
      "https://openalex.org/W2085337304",
      "https://openalex.org/W2100341149",
      "https://openalex.org/W2104583100",
      "https://openalex.org/W2119821739",
      "https://openalex.org/W2123142779",
      "https://openalex.org/W2131357087",
      "https://openalex.org/W2131753116",
      "https://openalex.org/W2139694477",
      "https://openalex.org/W2151048449",
      "https://openalex.org/W2162638401",
      "https://openalex.org/W2181629536",
      "https://openalex.org/W2250741050",
      "https://openalex.org/W2250869925",
      "https://openalex.org/W2949695381",
      "https://openalex.org/W4239510810",
      "https://openalex.org/W4241676240"
    ],
    "abstract": "While most previous work onWikification has focused on written texts, this paper presents a Wikification approach for spo-ken dialogues. A set of analyzers are pro-posed to learn dialogue-specific properties along with domain knowledge of conver-sations from Wikipedia. Then, the an-alyzed properties are used as constraints for generating candidates, and the candi-dates are ranked to find the appropriate links. The experimental results show that our proposed approach can significantly improve the performances of the task in human-human dialogues. 1",
    "match_score": 1.0
  },
  "The World is Not Binary Learning to Rank with Grayscale Data for Dialogue Response Selection": {
    "openalex_id": "https://openalex.org/W3098379431",
    "publication_year": 2020,
    "cited_by_count": 32,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W295828404",
      "https://openalex.org/W2102531443",
      "https://openalex.org/W2108862644",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2155482025",
      "https://openalex.org/W2170738476",
      "https://openalex.org/W2173361515",
      "https://openalex.org/W2197546379",
      "https://openalex.org/W2338325072",
      "https://openalex.org/W2339852062",
      "https://openalex.org/W2395531022",
      "https://openalex.org/W2561368124",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2805077688",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2949446780",
      "https://openalex.org/W2951287343",
      "https://openalex.org/W2951359136",
      "https://openalex.org/W2952285288",
      "https://openalex.org/W2952813980",
      "https://openalex.org/W2962768358",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963521540",
      "https://openalex.org/W2963522640",
      "https://openalex.org/W2963542836",
      "https://openalex.org/W2963735582",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964150246",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964309167",
      "https://openalex.org/W2970648534",
      "https://openalex.org/W2971190479",
      "https://openalex.org/W2985258882",
      "https://openalex.org/W4252076394",
      "https://openalex.org/W4300125564",
      "https://openalex.org/W4300687842"
    ],
    "abstract": "Response selection plays a vital role in building retrieval-based conversation systems. Despite that response selection is naturally a learning-to-rank problem, most prior works take a point-wise view and train binary classifiers for this task: each response candidate is labeled either relevant (one) or irrelevant (zero). On the one hand, this formalization can be sub-optimal due to its ignorance of the diversity of response quality. On the other hand, annotating grayscale data for learning-to-rank can be prohibitively expensive and challenging. In this work, we show that grayscale data can be automatically constructed without human effort. Our method employs off-the-shelf response retrieval models and response generation models as automatic grayscale data generators. With the constructed grayscale data, we propose multi-level ranking objectives for training, which can (1) teach a matching model to capture more fine-grained context-response relevance difference and (2) reduce the train-test discrepancy in terms of distractor strength. Our method is simple, effective, and universal. Experiments on three benchmark datasets and four state-of-the-art matching models show that the proposed approach brings significant and consistent performance improvements.",
    "match_score": 0.9945945945945946
  },
  "Designing Precise and Robust Dialogue Response Evaluators": {
    "openalex_id": "https://openalex.org/W3034950505",
    "publication_year": 2020,
    "cited_by_count": 41,
    "referenced_works": [
      "https://openalex.org/W2040975718",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2786472963",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2904443424",
      "https://openalex.org/W2938704169",
      "https://openalex.org/W2951000191",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963466651",
      "https://openalex.org/W2963527228",
      "https://openalex.org/W2963640662",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2966292672",
      "https://openalex.org/W2979702391",
      "https://openalex.org/W2996428491",
      "https://openalex.org/W3011411500",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4210764005",
      "https://openalex.org/W4288113479",
      "https://openalex.org/W4288243162"
    ],
    "abstract": "Automatic dialogue response evaluator has been proposed as an alternative to automated metrics and human evaluation. However, existing automatic evaluators achieve only moderate correlation with human judgement and they are not robust. In this work, we propose to build a reference-free evaluator and exploit the power of semi-supervised training and pretrained (masked) language models. Experimental results demonstrate that the proposed evaluator achieves a strong correlation (> 0.6) with human judgement and generalizes robustly to diverse responses and corpora. We open-source the code and data in https://github.com/ZHAOTING/dialog-processing.",
    "match_score": 1.0
  },
  "Dialogue-Act Prediction of Future Responses Based on Conversation History": {
    "openalex_id": "https://openalex.org/W2952100657",
    "publication_year": 2019,
    "cited_by_count": 16,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1526096287",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W2149484506",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2509387270",
      "https://openalex.org/W2573626026",
      "https://openalex.org/W2963411289",
      "https://openalex.org/W2963866450",
      "https://openalex.org/W2964106094",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W4302333880"
    ],
    "abstract": "Sequence-to-sequence models are a common approach to develop a chatbot. They can train a conversational model in an end-to-end manner. One significant drawback of such a neural network based approach is that the response generation process is a black-box, and how a specific response is generated is unclear. To tackle this problem, an interpretable response generation mechanism is desired. As a step toward this direction, we focus on dialogue-acts (DAs) that may provide insight to understand the response generation process. In particular, we propose a method to predict a DA of the next response based on the history of previous utterances and their DAs. Experiments using a Switch Board Dialogue Act corpus show that compared to the baseline considering only a single utterance, our model achieves 10.8% higher F1-score and 3.0% higher accuracy on DA prediction.",
    "match_score": 1.0
  },
  "A Contextual Hierarchical Attention Network with Adaptive Objective for Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W3035633461",
    "publication_year": 2020,
    "cited_by_count": 58,
    "referenced_works": [
      "https://openalex.org/W1602011256",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251235149",
      "https://openalex.org/W2251355666",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2470673105",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2806482527",
      "https://openalex.org/W2808310571",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2934890006",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2951855948",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963351448",
      "https://openalex.org/W2963360026",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2972777589",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2981507717",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W2996317432",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3098057198",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W4289147179"
    ],
    "abstract": "Recent studies in dialogue state tracking (DST) leverage historical information to determine states which are generally represented as slot-value pairs. However, most of them have limitations to efficiently exploit relevant context due to the lack of a powerful mechanism for modeling interactions between the slot and the dialogue history. Besides, existing methods usually ignore the slot imbalance problem and treat all slots indiscriminately, which limits the learning of hard slots and eventually hurts overall performance. In this paper, we propose to enhance the DST through employing a contextual hierarchical attention network to not only discern relevant information at both word level and turn level but also learn contextual representations. We further propose an adaptive objective to alleviate the slot imbalance problem by dynamically adjust weights of different slots during training. Experimental results show that our approach reaches 52.68% and 58.55% joint accuracy on MultiWOZ 2.0 and MultiWOZ 2.1 datasets respectively and achieves new state-of-the-art performance with considerable improvements (+1.24% and +5.98%).",
    "match_score": 1.0
  },
  "Spectral Analysis of Information Density in Dialogue Predicts Collaborative Task Performance": {
    "openalex_id": "https://openalex.org/W2740135329",
    "publication_year": 2017,
    "cited_by_count": 9,
    "referenced_works": [
      "https://openalex.org/W129305155",
      "https://openalex.org/W1518863056",
      "https://openalex.org/W1580807540",
      "https://openalex.org/W1588163064",
      "https://openalex.org/W1619488417",
      "https://openalex.org/W1631260214",
      "https://openalex.org/W1741471588",
      "https://openalex.org/W1974166643",
      "https://openalex.org/W1975994995",
      "https://openalex.org/W1995875735",
      "https://openalex.org/W1998021300",
      "https://openalex.org/W2013056791",
      "https://openalex.org/W2035093168",
      "https://openalex.org/W2056684507",
      "https://openalex.org/W2057563799",
      "https://openalex.org/W2058819080",
      "https://openalex.org/W2060806362",
      "https://openalex.org/W2093230975",
      "https://openalex.org/W2097580026",
      "https://openalex.org/W2100008374",
      "https://openalex.org/W2100750861",
      "https://openalex.org/W2101348300",
      "https://openalex.org/W2102573550",
      "https://openalex.org/W2105672294",
      "https://openalex.org/W2107974377",
      "https://openalex.org/W2118142207",
      "https://openalex.org/W2121706863",
      "https://openalex.org/W2123136325",
      "https://openalex.org/W2129955048",
      "https://openalex.org/W2148545659",
      "https://openalex.org/W2159398820",
      "https://openalex.org/W2166637769",
      "https://openalex.org/W2182998842",
      "https://openalex.org/W2292560873",
      "https://openalex.org/W2316023651",
      "https://openalex.org/W2510737926",
      "https://openalex.org/W2518257277",
      "https://openalex.org/W2579087420",
      "https://openalex.org/W2993383518",
      "https://openalex.org/W3122580054",
      "https://openalex.org/W3123030186",
      "https://openalex.org/W4230644069",
      "https://openalex.org/W4247066346",
      "https://openalex.org/W6605277767",
      "https://openalex.org/W6636811518",
      "https://openalex.org/W6637689594",
      "https://openalex.org/W6643794096",
      "https://openalex.org/W6648982606",
      "https://openalex.org/W6649975542",
      "https://openalex.org/W6659041405",
      "https://openalex.org/W6673748633",
      "https://openalex.org/W6674676611",
      "https://openalex.org/W6675392920",
      "https://openalex.org/W6675861551",
      "https://openalex.org/W6677824845",
      "https://openalex.org/W6682043691",
      "https://openalex.org/W6683469792",
      "https://openalex.org/W6686261312",
      "https://openalex.org/W6725099393",
      "https://openalex.org/W6732333006",
      "https://openalex.org/W6845709182",
      "https://openalex.org/W7073626071"
    ],
    "abstract": "We propose a perspective on dialogue that focuses on relative information contributions of conversation partners as a key to successful communication. We predict the success of collaborative task in English and Danish corpora of task-oriented dialogue. Two features are extracted from the frequency domain representations of the lexical entropy series of each interlocutor, power spectrum overlap (PSO) and relative phase (RP). We find that PSO is a negative predictor of task success, while RP is a positive one. An SVM with these features significantly improved on previous task success prediction models. Our findings suggest that the strategic distribution of information density between interlocutors is relevant to task success.",
    "match_score": 1.0
  },
  "Understanding Linguistic Accommodation in Code-Switched Human-Machine Dialogues": {
    "openalex_id": "https://openalex.org/W3100584004",
    "publication_year": 2020,
    "cited_by_count": 6,
    "referenced_works": [
      "https://openalex.org/W251558267",
      "https://openalex.org/W1532209448",
      "https://openalex.org/W1554274370",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1804881260",
      "https://openalex.org/W1972711991",
      "https://openalex.org/W1976780908",
      "https://openalex.org/W1993598708",
      "https://openalex.org/W2013489815",
      "https://openalex.org/W2080550848",
      "https://openalex.org/W2089652186",
      "https://openalex.org/W2114030807",
      "https://openalex.org/W2133949313",
      "https://openalex.org/W2145588856",
      "https://openalex.org/W2146277089",
      "https://openalex.org/W2160176417",
      "https://openalex.org/W2168708086",
      "https://openalex.org/W2472161733",
      "https://openalex.org/W2524481654",
      "https://openalex.org/W2746009407",
      "https://openalex.org/W2889134004",
      "https://openalex.org/W2889418961",
      "https://openalex.org/W2928484296",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963217826",
      "https://openalex.org/W2963945964",
      "https://openalex.org/W2963952470",
      "https://openalex.org/W2970178946",
      "https://openalex.org/W2990213592",
      "https://openalex.org/W2996699929",
      "https://openalex.org/W3032020872",
      "https://openalex.org/W3034284720",
      "https://openalex.org/W3034319502",
      "https://openalex.org/W3106549878",
      "https://openalex.org/W3196847085"
    ],
    "abstract": "Code-switching is a ubiquitous phenomenon in multilingual communities. Natural language technologies that wish to communicate like humans must therefore adaptively incorporate code-switching techniques when they are deployed in multilingual settings. To this end, we propose a Hindi-English human-machine dialogue system that elicits code-switching conversations in a controlled setting. It uses different code-switching agent strategies to understand how users respond and accommodate to the agent's language choice. Through this system, we collect and release a new dataset CommonDost, comprising of 439 human-machine multilingual conversations. We adapt pre-defined metrics to discover linguistic accommodation from users to agents. Finally, we compare these dialogues with Spanish-English dialogues collected in a similar setting, and analyze the impact of linguistic and socio-cultural factors on code-switching patterns across the two language pairs.",
    "match_score": 1.0
  },
  "Learning an Unreferenced Metric for Online Dialogue Evaluation": {
    "openalex_id": "https://openalex.org/W3022592851",
    "publication_year": 2020,
    "cited_by_count": 9,
    "referenced_works": [
      "https://openalex.org/W1821462560",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2133459682",
      "https://openalex.org/W2152790380",
      "https://openalex.org/W2294370754",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2584220694",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2607892599",
      "https://openalex.org/W2741333084",
      "https://openalex.org/W2885421725",
      "https://openalex.org/W2889326796",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2898658996",
      "https://openalex.org/W2949611393",
      "https://openalex.org/W2949918260",
      "https://openalex.org/W2963527228",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963807318",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963918774",
      "https://openalex.org/W2971883198",
      "https://openalex.org/W2978017171"
    ],
    "abstract": "Evaluating the quality of a dialogue interaction between two agents is a difficult task, especially in open-domain chit-chat style dialogue. There have been recent efforts to develop automatic dialogue evaluation metrics, but most of them do not generalize to unseen datasets and/or need a human-generated reference response during inference, making it infeasible for online evaluation. Here, we propose an unreferenced automated evaluation metric that uses large pre-trained language models to extract latent representations of utterances, and leverages the temporal transitions that exist between them. We show that our model achieves higher correlation with human annotations in an online setting, while not requiring true responses for comparison during inference.",
    "match_score": 1.0
  },
  "What do Entity-Centric Models Learn Insights from Entity Linking in Multi-Party Dialogue": {
    "openalex_id": "https://openalex.org/W2945614092",
    "publication_year": 2019,
    "cited_by_count": 6,
    "referenced_works": [
      "https://openalex.org/W1520352740",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1548663377",
      "https://openalex.org/W1566256432",
      "https://openalex.org/W1677182931",
      "https://openalex.org/W1732222442",
      "https://openalex.org/W1789782362",
      "https://openalex.org/W1793121960",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2085574295",
      "https://openalex.org/W2101268022",
      "https://openalex.org/W2131357087",
      "https://openalex.org/W2141599568",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2160654481",
      "https://openalex.org/W2292919134",
      "https://openalex.org/W2549835527",
      "https://openalex.org/W2563734883",
      "https://openalex.org/W2631715525",
      "https://openalex.org/W2739484150",
      "https://openalex.org/W2773354821",
      "https://openalex.org/W2799124508",
      "https://openalex.org/W2803267010",
      "https://openalex.org/W2805807693",
      "https://openalex.org/W2807377748",
      "https://openalex.org/W2889107415",
      "https://openalex.org/W2891698435",
      "https://openalex.org/W2950527759",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2951976932",
      "https://openalex.org/W2962769558",
      "https://openalex.org/W2963184844",
      "https://openalex.org/W2963290255",
      "https://openalex.org/W2963463993",
      "https://openalex.org/W2963695529",
      "https://openalex.org/W2963751529",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964204621",
      "https://openalex.org/W2964222268",
      "https://openalex.org/W2989631226",
      "https://openalex.org/W3029541414",
      "https://openalex.org/W4230980737",
      "https://openalex.org/W4294170691",
      "https://openalex.org/W4303633609"
    ],
    "abstract": "Humans use language to refer to entities in the external world. Motivated by this, in recent years several models that incorporate a bias towards learning entity representations have been proposed. Such entity-centric models have shown empirical success, but we still know little about why. In this paper we analyze the behavior of two recently proposed entity-centric models in a referential task, Entity Linking in Multi-party Dialogue (SemEval 2018 Task 4). We show that these models outperform the state of the art on this task, and that they do better on lower frequency entities than a counterpart model that is not entity-centric, with the same model size. We argue that making models entity-centric naturally fosters good architectural decisions. However, we also show that these models do not really build entity representations and that they make poor use of linguistic context. These negative results underscore the need for model analysis, to test whether the motivations for particular architectures are borne out in how models behave when deployed.",
    "match_score": 0.9943502824858758
  },
  "Modeling Multi-Action Policy for Task-Oriented Dialogues": {
    "openalex_id": "https://openalex.org/W2970866659",
    "publication_year": 2019,
    "cited_by_count": 8,
    "referenced_works": [
      "https://openalex.org/W1504739411",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1530049455",
      "https://openalex.org/W1998070348",
      "https://openalex.org/W2021151961",
      "https://openalex.org/W2047335008",
      "https://openalex.org/W2122493499",
      "https://openalex.org/W2129405869",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2150775217",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2251062710",
      "https://openalex.org/W2412715517",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2805406810",
      "https://openalex.org/W2884814595",
      "https://openalex.org/W2890832667",
      "https://openalex.org/W2899908862",
      "https://openalex.org/W2952164680",
      "https://openalex.org/W2952798561",
      "https://openalex.org/W2963134326",
      "https://openalex.org/W2964044380",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W3099293669"
    ],
    "abstract": "Lei Shu, Hu Xu, Bing Liu, Piero Molino. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "MedDialog Large-scale Medical Dialogue Datasets": {
    "openalex_id": "https://openalex.org/W3101223450",
    "publication_year": 2020,
    "cited_by_count": 152,
    "referenced_works": [
      "https://openalex.org/W565398442",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1580898361",
      "https://openalex.org/W2078861931",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133512280",
      "https://openalex.org/W2194775991",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2886305736",
      "https://openalex.org/W2890969459",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2903928064",
      "https://openalex.org/W2951883832",
      "https://openalex.org/W2963096510",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2992922049",
      "https://openalex.org/W2997281057",
      "https://openalex.org/W2998186887",
      "https://openalex.org/W3025853514",
      "https://openalex.org/W3025997466",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W4385245566",
      "https://openalex.org/W4394666973"
    ],
    "abstract": "Guangtao Zeng, Wenmian Yang, Zeqian Ju, Yue Yang, Sicheng Wang, Ruisi Zhang, Meng Zhou, Jiaqi Zeng, Xiangyu Dong, Ruoyu Zhang, Hongchao Fang, Penghui Zhu, Shu Chen, Pengtao Xie. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.",
    "match_score": 0.9894736842105263
  },
  "How Time Matters Learning Time-Decay Attention for Contextual Spoken Language Understanding in Dialogues": {
    "openalex_id": "https://openalex.org/W2804780446",
    "publication_year": 2018,
    "cited_by_count": 53,
    "referenced_works": [
      "https://openalex.org/W648947103",
      "https://openalex.org/W1514535095",
      "https://openalex.org/W1551803577",
      "https://openalex.org/W1793121960",
      "https://openalex.org/W1972595521",
      "https://openalex.org/W2004672974",
      "https://openalex.org/W2131774270",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2274861244",
      "https://openalex.org/W2293453011",
      "https://openalex.org/W2335262272",
      "https://openalex.org/W2464790259",
      "https://openalex.org/W2473329891",
      "https://openalex.org/W2473965551",
      "https://openalex.org/W2520305281",
      "https://openalex.org/W2551571666",
      "https://openalex.org/W2575321326",
      "https://openalex.org/W2756320212",
      "https://openalex.org/W2759621817",
      "https://openalex.org/W2761412636",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2963031169",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963974338",
      "https://openalex.org/W2964156885",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W4285719527",
      "https://openalex.org/W4295249402"
    ],
    "abstract": "Shang-Yu Su, Pei-Chieh Yuan, Yun-Nung Chen. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). 2018.",
    "match_score": 0.9952153110047847
  },
  "A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses": {
    "openalex_id": "https://openalex.org/W3102260352",
    "publication_year": 2020,
    "cited_by_count": 7,
    "referenced_works": [
      "https://openalex.org/W165283731",
      "https://openalex.org/W1651093245",
      "https://openalex.org/W1686810756",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2184540135",
      "https://openalex.org/W2194775991",
      "https://openalex.org/W2493916176",
      "https://openalex.org/W2577171178",
      "https://openalex.org/W2583186419",
      "https://openalex.org/W2584723080",
      "https://openalex.org/W2767263466",
      "https://openalex.org/W2767415038",
      "https://openalex.org/W2768661419",
      "https://openalex.org/W2775491667",
      "https://openalex.org/W2795571593",
      "https://openalex.org/W2798685833",
      "https://openalex.org/W2807844885",
      "https://openalex.org/W2835434549",
      "https://openalex.org/W2883284130",
      "https://openalex.org/W2892245540",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2897182555",
      "https://openalex.org/W2962749469",
      "https://openalex.org/W2962835968",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963351776",
      "https://openalex.org/W2963748384",
      "https://openalex.org/W2963904606",
      "https://openalex.org/W2964213933",
      "https://openalex.org/W2980282514"
    ],
    "abstract": "In real-world dialogue, first-person visual information about where the other speakers are and what they are paying attention to is crucial to understand their intentions. Non-verbal responses also play an important role in social interactions. In this paper, we propose a visually-grounded first-person dialogue (VFD) dataset with verbal and non-verbal responses. The VFD dataset provides manually annotated (1) first-person images of agents, (2) utterances of human speakers, (3) eye-gaze locations of the speakers, and (4) the agents\u2019 verbal and non-verbal responses. We present experimental results obtained using the proposed VFD dataset and recent neural network models (e.g., BERT, ResNet). The results demonstrate that first-person vision helps neural network models correctly understand human intentions, and the production of non-verbal responses is a challenging task like that of verbal responses. Our dataset is publicly available.",
    "match_score": 1.0
  },
  "On-line Dialogue Policy Learning with Companion Teaching": {
    "openalex_id": "https://openalex.org/W2740191615",
    "publication_year": 2017,
    "cited_by_count": 17,
    "referenced_works": [
      "https://openalex.org/W121023703",
      "https://openalex.org/W950880443",
      "https://openalex.org/W1539975474",
      "https://openalex.org/W1778387566",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1990671169",
      "https://openalex.org/W1999874108",
      "https://openalex.org/W2054795804",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2074056782",
      "https://openalex.org/W2115101920",
      "https://openalex.org/W2121110499",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2164419340",
      "https://openalex.org/W2166493072",
      "https://openalex.org/W2168359464",
      "https://openalex.org/W2250456405",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2412715517",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2963993502"
    ],
    "abstract": "Lu Chen, Runzhe Yang, Cheng Chang, Zihao Ye, Xiang Zhou, Kai Yu. Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers. 2017.",
    "match_score": 1.0
  },
  "Dialogue Learning with Human Teaching and Feedback in End-to-End Trainable Task-Oriented Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2963567240",
    "publication_year": 2018,
    "cited_by_count": 150,
    "referenced_works": [
      "https://openalex.org/W140747314",
      "https://openalex.org/W178897730",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1931877416",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2021151961",
      "https://openalex.org/W2037897789",
      "https://openalex.org/W2047335008",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2137871902",
      "https://openalex.org/W2142641780",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251235149",
      "https://openalex.org/W2412715517",
      "https://openalex.org/W2435467204",
      "https://openalex.org/W2473329891",
      "https://openalex.org/W2534274346",
      "https://openalex.org/W2583816737",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2749436976",
      "https://openalex.org/W2772001136",
      "https://openalex.org/W2806600904",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2962776342",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2962957031",
      "https://openalex.org/W2963043030",
      "https://openalex.org/W2963050422",
      "https://openalex.org/W2963064439",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964044380",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W3104546989",
      "https://openalex.org/W4295249402"
    ],
    "abstract": "Bing Liu, Gokhan T\u00fcr, Dilek Hakkani-T\u00fcr, Pararth Shah, Larry Heck. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). 2018.",
    "match_score": 1.0
  },
  "Guided Dialogue Policy Learning without Adversarial Learning in the Loop": {
    "openalex_id": "https://openalex.org/W3105184920",
    "publication_year": 2020,
    "cited_by_count": 20,
    "referenced_works": [
      "https://openalex.org/W10548402",
      "https://openalex.org/W648786980",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W2047335008",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2099471712",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2396229782",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2547875792",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2736601468",
      "https://openalex.org/W2765111838",
      "https://openalex.org/W2798494119",
      "https://openalex.org/W2806936550",
      "https://openalex.org/W2889186204",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2962996309",
      "https://openalex.org/W2963064439",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963277051",
      "https://openalex.org/W2963692154",
      "https://openalex.org/W2963712524",
      "https://openalex.org/W2964044380",
      "https://openalex.org/W2964268978",
      "https://openalex.org/W2970828515",
      "https://openalex.org/W3104546989",
      "https://openalex.org/W3121541553",
      "https://openalex.org/W4312609624",
      "https://openalex.org/W4320013936"
    ],
    "abstract": "Reinforcement learning methods have emerged as a popular choice for training an efficient and effective dialogue policy. However, these methods suffer from sparse and unstable reward signals returned by a user simulator only when a dialogue finishes. Besides, the reward signal is manually designed by human experts, which requires domain knowledge. Recently, a number of adversarial learning methods have been proposed to learn the reward function together with the dialogue policy. However, to alternatively update the dialogue policy and the reward model on the fly, we are limited to policy-gradient-based algorithms, such as REINFORCE and PPO. Moreover, the alternating training of a dialogue agent and the reward model can easily get stuck in local optima or result in mode collapse. To overcome the listed issues, we propose to decompose the adversarial training into two steps. First, we train the discriminator with an auxiliary dialogue generator and then incorporate a derived reward model into a common reinforcement learning method to guide the dialogue policy learning. This approach is applicable to both on-policy and off-policy reinforcement learning methods. Based on our extensive experimentation, we can conclude the proposed method: (1) achieves a remarkable task success rate using both on-policy and off-policy reinforcement learning methods; and (2) has potential to transfer knowledge from existing domains to a new domain.",
    "match_score": 1.0
  },
  "Meta-Reinforced Multi-Domain State Generator for Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3034956542",
    "publication_year": 2020,
    "cited_by_count": 30,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591801644",
      "https://openalex.org/W1836465849",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2108806737",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2176263492",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2472819217",
      "https://openalex.org/W2550182557",
      "https://openalex.org/W2578206533",
      "https://openalex.org/W2604763608",
      "https://openalex.org/W2612675303",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2888541716",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2912438391",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2945978556",
      "https://openalex.org/W2951980657",
      "https://openalex.org/W2963084599",
      "https://openalex.org/W2963248296",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963768805",
      "https://openalex.org/W2963866663",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2968831808",
      "https://openalex.org/W2969301397",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2972777589",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W3104402684",
      "https://openalex.org/W4300971732"
    ],
    "abstract": "A Dialogue State Tracker (DST) is a core component of a modular task-oriented dialogue system. Tremendous progress has been made in recent years. However, the major challenges remain. The state-of-the-art accuracy for DST is below 50% for a multi-domain dialogue task. A learnable DST for any new domain requires a large amount of labeled in-domain data and training from scratch. In this paper, we propose a Meta-Reinforced Multi-Domain State Generator (MERET). Our first contribution is to improve the DST accuracy. We enhance a neural model based DST generator with a reward manager, which is built on policy gradient reinforcement learning (RL) to fine-tune the generator. With this change, we are able to improve the joint accuracy of DST from 48.79% to 50.91% on the MultiWOZ corpus. Second, we explore to train a DST meta-learning model with a few domains as source domains and a new domain as target domain. We apply the model-agnostic meta-learning algorithm (MAML) to DST and the obtained meta-learning model is used for new domain adaptation. Our experimental results show this solution is able to outperform the traditional training approach with extremely less training data in target domain.",
    "match_score": 1.0
  },
  "Observing Dialogue in Therapy Categorizing and Forecasting Behavioral Codes": {
    "openalex_id": "https://openalex.org/W2964331476",
    "publication_year": 2019,
    "cited_by_count": 39,
    "referenced_works": [
      "https://openalex.org/W109922458",
      "https://openalex.org/W182831726",
      "https://openalex.org/W836999996",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1594982765",
      "https://openalex.org/W1841959837",
      "https://openalex.org/W1961463694",
      "https://openalex.org/W1965394545",
      "https://openalex.org/W1971094734",
      "https://openalex.org/W1976847947",
      "https://openalex.org/W1991002414",
      "https://openalex.org/W1993378086",
      "https://openalex.org/W2009419346",
      "https://openalex.org/W2051576505",
      "https://openalex.org/W2053072887",
      "https://openalex.org/W2102582267",
      "https://openalex.org/W2115613106",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2149129894",
      "https://openalex.org/W2154608152",
      "https://openalex.org/W2161466446",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2265658025",
      "https://openalex.org/W2397246247",
      "https://openalex.org/W2509943063",
      "https://openalex.org/W2551396370",
      "https://openalex.org/W2599618731",
      "https://openalex.org/W2603612888",
      "https://openalex.org/W2740747242",
      "https://openalex.org/W2740811869",
      "https://openalex.org/W2748463297",
      "https://openalex.org/W2884561390",
      "https://openalex.org/W2891331025",
      "https://openalex.org/W2912279724",
      "https://openalex.org/W2962739339",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963351448",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963955897",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W3018382390",
      "https://openalex.org/W3125532913",
      "https://openalex.org/W4236521339",
      "https://openalex.org/W4237138749",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Automatically analyzing dialogue can help understand and guide behavior in domains such as counseling, where interactions are largely mediated by conversation. In this paper, we study modeling behavioral codes used to asses a psychotherapy treatment style called Motivational Interviewing (MI), which is effective for addressing substance abuse and related problems. Specifically, we address the problem of providing real-time guidance to therapists with a dialogue observer that (1) categorizes therapist and client MI behavioral codes and, (2) forecasts codes for upcoming utterances to help guide the conversation and potentially alert the therapist. For both tasks, we define neural network models that build upon recent successes in dialogue modeling. Our experiments demonstrate that our models can outperform several baselines for both tasks. We also report the results of a careful analysis that reveals the impact of the various network design tradeoffs for modeling therapy dialogue.",
    "match_score": 0.9933774834437086
  },
  "\u201cI Object!\u201d Modeling Latent Pragmatic Effects in Courtroom Dialogues": {
    "openalex_id": "https://openalex.org/W2250353434",
    "publication_year": 2014,
    "cited_by_count": 8,
    "referenced_works": [
      "https://openalex.org/W123366752",
      "https://openalex.org/W1497300277",
      "https://openalex.org/W1533917153",
      "https://openalex.org/W1570771333",
      "https://openalex.org/W1787105636",
      "https://openalex.org/W1816599501",
      "https://openalex.org/W1993027114",
      "https://openalex.org/W2028651375",
      "https://openalex.org/W2040512654",
      "https://openalex.org/W2087347434",
      "https://openalex.org/W2088622183",
      "https://openalex.org/W2096765155",
      "https://openalex.org/W2096968458",
      "https://openalex.org/W2101534792",
      "https://openalex.org/W2112729630",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2138260386",
      "https://openalex.org/W2145451908",
      "https://openalex.org/W2147196093",
      "https://openalex.org/W2151295812",
      "https://openalex.org/W2156953626",
      "https://openalex.org/W2158794898",
      "https://openalex.org/W2166957049",
      "https://openalex.org/W2168356304",
      "https://openalex.org/W2176475152",
      "https://openalex.org/W2250281182",
      "https://openalex.org/W2251426493",
      "https://openalex.org/W2465041517",
      "https://openalex.org/W2788850978",
      "https://openalex.org/W2949089885",
      "https://openalex.org/W4249258521"
    ],
    "abstract": "Understanding the actionable outcomes of a dialogue requires effectively modeling situational roles of dialogue participants, the structure of the dialogue and the relevance of each utterance to an eventual action.We develop a latent-variable model that can capture these notions and apply it in the context of courtroom dialogues, in which the objection speech act is used as binary supervision to drive the learning process.We demonstrate quantitatively and qualitatively that our model is able to uncover natural discourse structure from this distant supervision.",
    "match_score": 0.9705882352941176
  },
  "Pretrained Language Models for Dialogue Generation with Multiple Input Sources": {
    "openalex_id": "https://openalex.org/W3101068439",
    "publication_year": 2020,
    "cited_by_count": 21,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2133512280",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2525778437",
      "https://openalex.org/W2742079690",
      "https://openalex.org/W2742947407",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2922709902",
      "https://openalex.org/W2953039584",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963854351",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2988647680",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2997892440",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Large-scale pretrained language models have achieved outstanding performance on natural language understanding tasks. However, it is still under investigating how to apply them to dialogue generation tasks, especially those with responses conditioned on multiple sources. Previous work simply concatenates all input sources or averages information from different input sources. In this work, we study dialogue models with multiple input sources adapted from the pretrained language model GPT2. We explore various methods to fuse multiple separate attention information corresponding to different sources. Our experimental results show that proper fusion methods deliver higher relevance with dialogue history than simple fusion baselines.",
    "match_score": 1.0
  },
  "ReCoSa Detecting the Relevant Contexts with Self-Attention for Multi-turn Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2962896208",
    "publication_year": 2019,
    "cited_by_count": 126,
    "referenced_works": [
      "https://openalex.org/W1899504021",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W1993378086",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2267186426",
      "https://openalex.org/W2413794162",
      "https://openalex.org/W2418993857",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2561368124",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2584185835",
      "https://openalex.org/W2612675303",
      "https://openalex.org/W2741363662",
      "https://openalex.org/W2789033601",
      "https://openalex.org/W2798984671",
      "https://openalex.org/W2807791032",
      "https://openalex.org/W2862781886",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2949446780",
      "https://openalex.org/W2962707484",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963360026",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963986868",
      "https://openalex.org/W2964189376",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "In multi-turn dialogue generation, response is usually related with only a few contexts. Therefore, an ideal model should be able to detect these relevant contexts and produce a suitable response accordingly. However, the widely used hierarchical recurrent encoder-decoder models just treat all the contexts indiscriminately, which may hurt the following response generation process. Some researchers try to use the cosine similarity or the traditional attention mechanism to find the relevant contexts, but they suffer from either insufficient relevance assumption or position bias problem. In this paper, we propose a new model, named ReCoSa, to tackle this problem. Firstly, a word level LSTM encoder is conducted to obtain the initial representation of each context. Then, the self-attention mechanism is utilized to update both the context and masked response representation. Finally, the attention weights between each context and response representations are computed and used in the further decoding process. Experimental results on both Chinese customer services dataset and English Ubuntu dialogue dataset show that ReCoSa significantly outperforms baseline models, in terms of both metric-based and human evaluations. Further analysis on attention shows that the detected relevant contexts by ReCoSa are highly coherent with human\u2019s understanding, validating the correctness and interpretability of ReCoSa.",
    "match_score": 0.9946524064171123
  },
  "Modeling Dialogue Acts with Content Word Filtering and Speaker Preferences": {
    "openalex_id": "https://openalex.org/W2756640946",
    "publication_year": 2017,
    "cited_by_count": 9,
    "referenced_works": [
      "https://openalex.org/W598680636",
      "https://openalex.org/W1508927691",
      "https://openalex.org/W1535960497",
      "https://openalex.org/W1541437296",
      "https://openalex.org/W1573993894",
      "https://openalex.org/W1576632330",
      "https://openalex.org/W1654173042",
      "https://openalex.org/W1895273801",
      "https://openalex.org/W1913627016",
      "https://openalex.org/W2009490757",
      "https://openalex.org/W2010532052",
      "https://openalex.org/W2082484572",
      "https://openalex.org/W2101231682",
      "https://openalex.org/W2138615112",
      "https://openalex.org/W2141230360",
      "https://openalex.org/W2163074454",
      "https://openalex.org/W2167212741",
      "https://openalex.org/W2251183320",
      "https://openalex.org/W2270699505",
      "https://openalex.org/W2583461040",
      "https://openalex.org/W2963308744",
      "https://openalex.org/W2963681578",
      "https://openalex.org/W3037265734"
    ],
    "abstract": "We present an unsupervised model of dialogue act sequences in conversation. By modeling topical themes as transitioning more slowly than dialogue acts in conversation, our model de-emphasizes content-related words in order to focus on conversational function words that signal dialogue acts. We also incorporate speaker tendencies to use some acts more than others as an additional predictor of dialogue act prevalence beyond temporal dependencies. According to the evaluation presented on two dissimilar corpora, the CNET forum and NPS Chat corpus, the effectiveness of each modeling assumption is found to vary depending on characteristics of the data. De-emphasizing content-related words yields improvement on the CNET corpus, while utilizing speaker tendencies is advantageous on the NPS corpus. The components of our model complement one another to achieve robust performance on both corpora and outperform state-of-the-art baseline models.",
    "match_score": 1.0
  },
  "Modeling Long Context for Task-Oriented Dialogue State Generation": {
    "openalex_id": "https://openalex.org/W3035194816",
    "publication_year": 2020,
    "cited_by_count": 22,
    "referenced_works": [
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2556468274",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963527209",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2970705401",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W2996317432",
      "https://openalex.org/W3008966357",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W4288027128",
      "https://openalex.org/W4289147179"
    ],
    "abstract": "Based on the recently proposed transferable dialogue state generator (TRADE) that predicts dialogue states from utterance-concatenated dialogue context, we propose a multi-task learning model with a simple yet effective utterance tagging technique and a bidirectional language model as an auxiliary task for task-oriented dialogue state generation. By enabling the model to learn a better representation of the long dialogue context, our approaches attempt to solve the problem that the performance of the baseline significantly drops when the input dialogue context sequence is long. In our experiments, our proposed model achieves a 7.03% relative improvement over the baseline, establishing a new state-of-the-art joint goal accuracy of 52.04% on the MultiWOZ 2.0 dataset.",
    "match_score": 1.0
  },
  "Dialogue Coherence Assessment Without Explicit Dialogue Act Labels": {
    "openalex_id": "https://openalex.org/W3033475175",
    "publication_year": 2020,
    "cited_by_count": 2,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W73128518",
      "https://openalex.org/W1557757161",
      "https://openalex.org/W1585586388",
      "https://openalex.org/W1728737950",
      "https://openalex.org/W2015933299",
      "https://openalex.org/W2115615127",
      "https://openalex.org/W2117417596",
      "https://openalex.org/W2140676672",
      "https://openalex.org/W2141236834",
      "https://openalex.org/W2152052831",
      "https://openalex.org/W2159128165",
      "https://openalex.org/W2159757335",
      "https://openalex.org/W2160133507",
      "https://openalex.org/W2167702024",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251761864",
      "https://openalex.org/W2280612018",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2408567386",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2740181799",
      "https://openalex.org/W2794509261",
      "https://openalex.org/W2807791032",
      "https://openalex.org/W2808636610",
      "https://openalex.org/W2889765309",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2949918260",
      "https://openalex.org/W2953272915",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963640662",
      "https://openalex.org/W2963677766",
      "https://openalex.org/W2963712524",
      "https://openalex.org/W2963866450",
      "https://openalex.org/W2964089584",
      "https://openalex.org/W2964134121",
      "https://openalex.org/W2964609953"
    ],
    "abstract": "Recent dialogue coherence models use the coherence features designed for monologue texts, e.g. nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels. It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels. We address these issues by introducing a novel approach to dialogue coherence assessment. We use dialogue act prediction as an auxiliary task in a multi-task learning scenario to obtain informative utterance representations for coherence assessment. Our approach alleviates the need for explicit dialogue act labels during evaluation. The results of our experiments show that our model substantially (more than 20 accuracy points) outperforms its strong competitors on the DailyDialogue corpus, and performs on par with them on the SwitchBoard corpus for ranking dialogues concerning their coherence.",
    "match_score": 1.0
  },
  "GRADE Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3105218667",
    "publication_year": 2020,
    "cited_by_count": 70,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2123301721",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2561529111",
      "https://openalex.org/W2584220694",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2916772188",
      "https://openalex.org/W2936695845",
      "https://openalex.org/W2950299257",
      "https://openalex.org/W2951490152",
      "https://openalex.org/W2951583236",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962767366",
      "https://openalex.org/W2962786758",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2963285578",
      "https://openalex.org/W2963527228",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963858333",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964178377",
      "https://openalex.org/W2964207259",
      "https://openalex.org/W2970252402",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2996268457",
      "https://openalex.org/W2996403597",
      "https://openalex.org/W2998563994",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3034715226",
      "https://openalex.org/W3035252911",
      "https://openalex.org/W3037026762",
      "https://openalex.org/W3113148688",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W4287900772",
      "https://openalex.org/W4294558607",
      "https://openalex.org/W4297733535"
    ],
    "abstract": "Automatically evaluating dialogue coherence is a challenging but high-demand ability for developing high-quality open-domain dialogue systems. However, current evaluation metrics consider only surface features or utterance-level semantics, without explicitly considering the fine-grained topic transition dynamics of dialogue flows. Here, we first consider that the graph structure constituted with topics in a dialogue can accurately depict the underlying communication logic, which is a more natural way to produce persuasive metrics. Capitalized on the topic-level dialogue graph, we propose a new evaluation metric GRADE, which stands for Graph-enhanced Representations for Automatic Dialogue Evaluation. Specifically, GRADE incorporates both coarse-grained utterance-level contextualized representations and fine-grained topic-level graph representations to evaluate dialogue coherence. The graph representations are obtained by reasoning over topic-level dialogue graphs enhanced with the evidence from a commonsense graph, including k-hop neighboring representations and hop-attention weights. Experimental results show that our GRADE significantly outperforms other state-of-the-art metrics on measuring diverse dialogue models in terms of the Pearson and Spearman correlations with human judgments. Besides, we release a new large-scale human evaluation benchmark to facilitate future research on automatic metrics.",
    "match_score": 0.994535519125683
  },
  "PLATO Pre-trained Dialogue Generation Model with Discrete Latent Variable": {
    "openalex_id": "https://openalex.org/W3035451444",
    "publication_year": 2020,
    "cited_by_count": 227,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1566289585",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1889081078",
      "https://openalex.org/W1958706068",
      "https://openalex.org/W2133012565",
      "https://openalex.org/W2143177362",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2525778437",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2805005636",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2916898195",
      "https://openalex.org/W2945260553",
      "https://openalex.org/W2948336019",
      "https://openalex.org/W2951583236",
      "https://openalex.org/W2951697502",
      "https://openalex.org/W2953039584",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963330684",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963411289",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964213933",
      "https://openalex.org/W2964587107",
      "https://openalex.org/W2970597249",
      "https://openalex.org/W2970682219",
      "https://openalex.org/W2973049837",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W4247864677",
      "https://openalex.org/W4288246040",
      "https://openalex.org/W4288624561"
    ],
    "abstract": "Pre-training models have been proved effective for a wide range of natural language processing tasks. Inspired by this, we propose a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering. In this framework, we adopt flexible attention mechanisms to fully leverage the bi-directional context and the uni-directional characteristic of language generation. We also introduce discrete latent variables to tackle the inherent one-to-many mapping problem in response generation. Two reciprocal tasks of response generation and latent act recognition are designed and carried out simultaneously within a shared network. Comprehensive experiments on three publicly available datasets verify the effectiveness and superiority of the proposed framework.",
    "match_score": 0.9931972789115646
  },
  "AttnIO Knowledge Graph Exploration with In-and-Out Attention Flow for Knowledge-Grounded Dialogue": {
    "openalex_id": "https://openalex.org/W3105732730",
    "publication_year": 2020,
    "cited_by_count": 33,
    "referenced_works": [
      "https://openalex.org/W2127795553",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2432356473",
      "https://openalex.org/W2728059831",
      "https://openalex.org/W2769099080",
      "https://openalex.org/W2774837955",
      "https://openalex.org/W2799176105",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2889344053",
      "https://openalex.org/W2891501508",
      "https://openalex.org/W2898987665",
      "https://openalex.org/W2900252255",
      "https://openalex.org/W2950457956",
      "https://openalex.org/W2951105272",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963432357",
      "https://openalex.org/W2963520511",
      "https://openalex.org/W2963858333",
      "https://openalex.org/W2964116313",
      "https://openalex.org/W2970236742",
      "https://openalex.org/W2970283086",
      "https://openalex.org/W2970971581",
      "https://openalex.org/W2970988759",
      "https://openalex.org/W2971933740",
      "https://openalex.org/W2982879526",
      "https://openalex.org/W2996428491",
      "https://openalex.org/W4295312788",
      "https://openalex.org/W4297733535",
      "https://openalex.org/W4297895859",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Retrieving the proper knowledge relevant to conversational context is an important challenge in dialogue systems, to engage users with more informative response. Several recent works propose to formulate this knowledge selection problem as a path traversal over an external knowledge graph (KG), but show only a limited utilization of KG structure, leaving rooms of improvement in performance. To this effect, we present AttnIO, a new dialog-conditioned path traversal model that makes a full use of rich structural information in KG based on two directions of attention flows. Through the attention flows, AttnIO is not only capable of exploring a broad range of multi-hop knowledge paths, but also learns to flexibly adjust the varying range of plausible nodes and edges to attend depending on the dialog context. Empirical evaluations present a marked performance improvement of AttnIO compared to all baselines in OpenDialKG dataset. Also, we find that our model can be trained to generate an adequate knowledge path even when the paths are not available and only the destination nodes are given as label, making it more applicable to real-world dialogue systems.",
    "match_score": 0.9948717948717949
  },
  "Improving Open-Domain Dialogue Systems via Multi-Turn Incomplete Utterance Restoration": {
    "openalex_id": "https://openalex.org/W2970960706",
    "publication_year": 2019,
    "cited_by_count": 53,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2099517310",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2108724304",
      "https://openalex.org/W2115691521",
      "https://openalex.org/W2148952635",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2179359904",
      "https://openalex.org/W2251344114",
      "https://openalex.org/W2565926555",
      "https://openalex.org/W2566267116",
      "https://openalex.org/W2579689822",
      "https://openalex.org/W2584185835",
      "https://openalex.org/W2741363662",
      "https://openalex.org/W2742113702",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2808293489",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2949446780",
      "https://openalex.org/W2952723239",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963217826",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963360026",
      "https://openalex.org/W3128714985",
      "https://openalex.org/W4298159411"
    ],
    "abstract": "Zhufeng Pan, Kun Bai, Yan Wang, Lianqiang Zhou, Xiaojiang Liu. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "Discriminative Deep Dyna-Q Robust Planning for Dialogue Policy Learning": {
    "openalex_id": "https://openalex.org/W2889186204",
    "publication_year": 2018,
    "cited_by_count": 74,
    "referenced_works": [
      "https://openalex.org/W1491843047",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2109038907",
      "https://openalex.org/W2117989772",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2290354866",
      "https://openalex.org/W2295072214",
      "https://openalex.org/W2412899141",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2473329891",
      "https://openalex.org/W2507592741",
      "https://openalex.org/W2567374473",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2765111838",
      "https://openalex.org/W2783543950",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2950471160",
      "https://openalex.org/W2962776342",
      "https://openalex.org/W2962996309",
      "https://openalex.org/W2963043030",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963140401",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964077562",
      "https://openalex.org/W2964080167",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W3021208093",
      "https://openalex.org/W3104546989",
      "https://openalex.org/W4293396018",
      "https://openalex.org/W4295249402"
    ],
    "abstract": "This paper presents a Discriminative Deep Dyna-Q (D3Q) approach to improving the effectiveness and robustness of Deep Dyna-Q (DDQ), a recently proposed framework that extends the Dyna-Q algorithm to integrate planning for task-completion dialogue policy learning. To obviate DDQ's high dependency on the quality of simulated experiences, we incorporate an RNN-based discriminator in D3Q to differentiate simulated experience from real user experience in order to control the quality of training data. Experiments show that D3Q significantly outperforms DDQ by controlling the quality of simulated experience used for planning. The effectiveness and robustness of D3Q is further demonstrated in a domain extension setting, where the agent's capability of adapting to a changing environment is tested.",
    "match_score": 0.993006993006993
  },
  "Joint Modeling of Content and Discourse Relations in Dialogues": {
    "openalex_id": "https://openalex.org/W2963983466",
    "publication_year": 2017,
    "cited_by_count": 24,
    "referenced_works": [
      "https://openalex.org/W35388109",
      "https://openalex.org/W142805243",
      "https://openalex.org/W225641137",
      "https://openalex.org/W1526096287",
      "https://openalex.org/W1591607137",
      "https://openalex.org/W1752174299",
      "https://openalex.org/W1923455183",
      "https://openalex.org/W1969700396",
      "https://openalex.org/W1982722967",
      "https://openalex.org/W1989115577",
      "https://openalex.org/W2017187090",
      "https://openalex.org/W2044120473",
      "https://openalex.org/W2097606805",
      "https://openalex.org/W2104367213",
      "https://openalex.org/W2105685762",
      "https://openalex.org/W2107875902",
      "https://openalex.org/W2112383723",
      "https://openalex.org/W2125336414",
      "https://openalex.org/W2125420881",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2130472671",
      "https://openalex.org/W2131780215",
      "https://openalex.org/W2145588856",
      "https://openalex.org/W2146769536",
      "https://openalex.org/W2150815390",
      "https://openalex.org/W2150824314",
      "https://openalex.org/W2158699754",
      "https://openalex.org/W2161068821",
      "https://openalex.org/W2165887782",
      "https://openalex.org/W2171986392",
      "https://openalex.org/W2181235373",
      "https://openalex.org/W2250749132",
      "https://openalex.org/W2251023158",
      "https://openalex.org/W2251442452",
      "https://openalex.org/W2251521080",
      "https://openalex.org/W2338342029",
      "https://openalex.org/W2469477431",
      "https://openalex.org/W2964036636",
      "https://openalex.org/W2964106094",
      "https://openalex.org/W4253555784"
    ],
    "abstract": "We present a joint modeling approach to identify salient discussion points in spoken meetings as well as to label the discourse relations between speaker turns. A variation of our model is also discussed when discourse relations are treated as latent variables. Experimental results on two popular meeting corpora show that our joint model can outperform state-of-the-art approaches for both phrase-based content selection and discourse relation prediction tasks. We also evaluate our model on predicting the consistency among team members\u2019 understanding of their group decisions. Classifiers trained with features constructed from our model achieve significant better predictive performance than the state-of-the-art.",
    "match_score": 1.0
  },
  "Hello, It\u2019s GPT-2 - How Can I Help You Towards the Use of Pretrained Language Models for Task-Oriented Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2956901422",
    "publication_year": 2019,
    "cited_by_count": 37,
    "referenced_works": [
      "https://openalex.org/W1654173042",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2132339004",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2611029872",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2898658996",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2915295540",
      "https://openalex.org/W2938704169",
      "https://openalex.org/W2947480709",
      "https://openalex.org/W2948110372",
      "https://openalex.org/W2950444459",
      "https://openalex.org/W2953039584",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962784628",
      "https://openalex.org/W2963026768",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963706742",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2972437240",
      "https://openalex.org/W2984520708",
      "https://openalex.org/W3088987271"
    ],
    "abstract": "Data scarcity is a long-standing and crucial challenge that hinders quick development of task-oriented dialogue systems across multiple domains: task-oriented dialogue models are expected to learn grammar, syntax, dialogue reasoning, decision making, and language generation from absurdly small amounts of task-specific data. In this paper, we demonstrate that recent progress in language modeling pre-training and transfer learning shows promise to overcome this problem. We propose a task-oriented dialogue model that operates solely on text input: it effectively bypasses explicit policy and language generation modules. Building on top of the TransferTransfo framework and generative model pre-training, we validate the approach on complex multi-domain task-oriented dialogues from the MultiWOZ dataset. Our automatic and human evaluations show that the proposed model is on par with a strong task-specific neural baseline. In the long run, our approach holds promise to mitigate the data scarcity problem, and to support the construction of more engaging and more eloquent task-oriented conversational agents.",
    "match_score": 0.99581589958159
  },
  "Hidden Softmax Sequence Model for Dialogue Structure Analysis": {
    "openalex_id": "https://openalex.org/W2508101854",
    "publication_year": 2016,
    "cited_by_count": 4,
    "referenced_works": [
      "https://openalex.org/W35388109",
      "https://openalex.org/W1513873506",
      "https://openalex.org/W1516111018",
      "https://openalex.org/W1516554472",
      "https://openalex.org/W1654173042",
      "https://openalex.org/W1853745982",
      "https://openalex.org/W1985514943",
      "https://openalex.org/W2042096436",
      "https://openalex.org/W2044120473",
      "https://openalex.org/W2089285937",
      "https://openalex.org/W2096192494",
      "https://openalex.org/W2100002341",
      "https://openalex.org/W2102409316",
      "https://openalex.org/W2116064496",
      "https://openalex.org/W2116825644",
      "https://openalex.org/W2118370253",
      "https://openalex.org/W2144100511",
      "https://openalex.org/W2146447174",
      "https://openalex.org/W2169218343",
      "https://openalex.org/W2170323078",
      "https://openalex.org/W2251949648",
      "https://openalex.org/W2294861638",
      "https://openalex.org/W2567948266",
      "https://openalex.org/W2949952668",
      "https://openalex.org/W4237840503",
      "https://openalex.org/W4239181501",
      "https://openalex.org/W4293503257"
    ],
    "abstract": "We propose a new unsupervised learning model, hidden softmax sequence model (HSSM), based on Boltzmann machine for dialogue structure analysis.The model employs three types of units in the hidden layer to discovery dialogue latent structures: softmax units which represent latent states of utterances; binary units which represent latent topics specified by dialogues; and a binary unit that represents the global general topic shared across the whole dialogue corpus.In addition, the model contains extra connections between adjacent hidden softmax units to formulate the dependency between latent states.Two different kinds of real world dialogue corpora, Twitter-Post and AirTicketBooking, are utilized for extensive comparing experiments, and the results illustrate that the proposed model outperforms sate-ofthe-art popular approaches.",
    "match_score": 1.0
  },
  "Natural Language Generation for Spoken Dialogue System using RNN Encoder-Decoder Networks": {
    "openalex_id": "https://openalex.org/W2620635248",
    "publication_year": 2017,
    "cited_by_count": 19,
    "referenced_works": [],
    "abstract": "Natural language generation (NLG) is a critical component in a spoken\\ndialogue system. This paper presents a Recurrent Neural Network based\\nEncoder-Decoder architecture, in which an LSTM-based decoder is introduced to\\nselect, aggregate semantic elements produced by an attention mechanism over the\\ninput elements, and to produce the required utterances. The proposed generator\\ncan be jointly trained both sentence planning and surface realization to\\nproduce natural language sentences. The proposed model was extensively\\nevaluated on four different NLG datasets. The experimental results showed that\\nthe proposed generators not only consistently outperform the previous methods\\nacross all the NLG domains but also show an ability to generalize from a new,\\nunseen domain and learn from multi-domain datasets.\\n",
    "match_score": 1.0
  },
  "ConvLab-2 An Open-Source Toolkit for Building, Evaluating, and Diagnosing Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3037879762",
    "publication_year": 2020,
    "cited_by_count": 67,
    "referenced_works": [
      "https://openalex.org/W1948566616",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2159875193",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2736601468",
      "https://openalex.org/W2739936944",
      "https://openalex.org/W2772604077",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2899908862",
      "https://openalex.org/W2915295540",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2953071719",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2962852262",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963692154",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2970828515",
      "https://openalex.org/W2997108628",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W3000027512",
      "https://openalex.org/W3036362489",
      "https://openalex.org/W3104546989",
      "https://openalex.org/W4293459943",
      "https://openalex.org/W4306716473"
    ],
    "abstract": "Qi Zhu, Zheng Zhang, Yan Fang, Xiang Li, Ryuichi Takanobu, Jinchao Li, Baolin Peng, Jianfeng Gao, Xiaoyan Zhu, Minlie Huang. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations. 2020.",
    "match_score": 0.994475138121547
  },
  "Dual Latent Variable Model for Low-Resource Natural Language Generation in Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2898790713",
    "publication_year": 2018,
    "cited_by_count": 14,
    "referenced_works": [
      "https://openalex.org/W592244745",
      "https://openalex.org/W648786980",
      "https://openalex.org/W1753530705",
      "https://openalex.org/W1947758080",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W2161181481",
      "https://openalex.org/W2188365844",
      "https://openalex.org/W2291723583",
      "https://openalex.org/W2510842514",
      "https://openalex.org/W2586756136",
      "https://openalex.org/W2749498836",
      "https://openalex.org/W2756946152",
      "https://openalex.org/W2951176429",
      "https://openalex.org/W2962800561",
      "https://openalex.org/W2962814609",
      "https://openalex.org/W2962956378",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963600562",
      "https://openalex.org/W2963713328",
      "https://openalex.org/W2963735467",
      "https://openalex.org/W3100380967"
    ],
    "abstract": "Recent deep learning models have shown improving results to natural language generation (NLG) irrespective of providing sufficient annotated data. However, a modest training data may harm such models\u2019 performance. Thus, how to build a generator that can utilize as much of knowledge from a low-resource setting data is a crucial issue in NLG. This paper presents a variational neural-based generation model to tackle the NLG problem of having limited labeled dataset, in which we integrate a variational inference into an encoder-decoder generator and introduce a novel auxiliary auto-encoding with an effective training procedure. Experiments showed that the proposed methods not only outperform the previous models when having sufficient training dataset but also demonstrate strong ability to work acceptably well when the training data is scarce.",
    "match_score": 1.0
  },
  "Constrained Decoding for Neural NLG from Compositional Representations in Task-Oriented Dialogue": {
    "openalex_id": "https://openalex.org/W2949413855",
    "publication_year": 2019,
    "cited_by_count": 74,
    "referenced_works": [
      "https://openalex.org/W40565524",
      "https://openalex.org/W122915500",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1574901103",
      "https://openalex.org/W1733954365",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1978078764",
      "https://openalex.org/W2045738181",
      "https://openalex.org/W2059857707",
      "https://openalex.org/W2064296938",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2080656168",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2099542783",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2107298945",
      "https://openalex.org/W2114544007",
      "https://openalex.org/W2116716943",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133341864",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2164259714",
      "https://openalex.org/W2168814553",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2291723583",
      "https://openalex.org/W2293959043",
      "https://openalex.org/W2295512956",
      "https://openalex.org/W2429300145",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2561658355",
      "https://openalex.org/W2613904329",
      "https://openalex.org/W2739046565",
      "https://openalex.org/W2806532810",
      "https://openalex.org/W2889009749",
      "https://openalex.org/W2902141901",
      "https://openalex.org/W2903428882",
      "https://openalex.org/W2914397182",
      "https://openalex.org/W2935206035",
      "https://openalex.org/W2962729880",
      "https://openalex.org/W2962801572",
      "https://openalex.org/W2962905474",
      "https://openalex.org/W2963084773",
      "https://openalex.org/W2963352809",
      "https://openalex.org/W2963592583",
      "https://openalex.org/W2963672599",
      "https://openalex.org/W2963910262",
      "https://openalex.org/W2964116568",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W3124386704",
      "https://openalex.org/W4254255610",
      "https://openalex.org/W4288375073"
    ],
    "abstract": "Generating fluent natural language responses from structured semantic representations is a critical step in task-oriented conversational systems. Avenues like the E2E NLG Challenge have encouraged the development of neural approaches, particularly sequence-to-sequence (Seq2Seq) models for this problem. The semantic representations used, however, are often underspecified, which places a higher burden on the generation model for sentence planning, and also limits the extent to which generated responses can be controlled in a live system. In this paper, we (1) propose using tree-structured semantic representations, like those used in traditional rule-based NLG systems, for better discourse-level structuring and sentence-level planning; (2) introduce a challenging dataset using this representation for the weather domain; (3) introduce a constrained decoding approach for Seq2Seq models that leverages this representation to improve semantic correctness; and (4) demonstrate promising results on our dataset and the E2E dataset.",
    "match_score": 1.0
  },
  "A Practical Dialogue-Act-Driven Conversation Model for Multi-Turn Response Selection": {
    "openalex_id": "https://openalex.org/W2970688662",
    "publication_year": 2019,
    "cited_by_count": 12,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W295828404",
      "https://openalex.org/W635530177",
      "https://openalex.org/W1591607137",
      "https://openalex.org/W2048101965",
      "https://openalex.org/W2120333797",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2220374841",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2593751037",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2786983967",
      "https://openalex.org/W2836574416",
      "https://openalex.org/W2884970917",
      "https://openalex.org/W2889793905",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2963134326",
      "https://openalex.org/W2963411289",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963765493",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W3121541553",
      "https://openalex.org/W4300125564"
    ],
    "abstract": "Harshit Kumar, Arvind Agarwal, Sachindra Joshi. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "Semantic Role Labeling Guided Multi-turn Dialogue ReWriter": {
    "openalex_id": "https://openalex.org/W3098694757",
    "publication_year": 2020,
    "cited_by_count": 21,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W2061397531",
      "https://openalex.org/W2103076621",
      "https://openalex.org/W2123442489",
      "https://openalex.org/W2126851059",
      "https://openalex.org/W2151170651",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2734443755",
      "https://openalex.org/W2806070455",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2915816387",
      "https://openalex.org/W2936215830",
      "https://openalex.org/W2945260553",
      "https://openalex.org/W2949769095",
      "https://openalex.org/W2952855649",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962803243",
      "https://openalex.org/W2963022746",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963560594",
      "https://openalex.org/W2963691697",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2970960706",
      "https://openalex.org/W2970996870",
      "https://openalex.org/W2971274815",
      "https://openalex.org/W2997349160",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4288373939",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4298870559"
    ],
    "abstract": "For multi-turn dialogue rewriting, the capacity of effectively modeling the linguistic knowledge in dialog context and getting ride of the noises is essential to improve its performance. Existing attentive models attend to all words without prior focus, which results in inaccurate concentration on some dispensable words. In this paper, we propose to use semantic role labeling (SRL), which highlights the core semantic information of who did what to whom, to provide additional guidance for the rewriter model. Experiments show that this information significantly improves a RoBERTa-based model that already outperforms previous state-of-the-art systems.",
    "match_score": 1.0
  },
  "GraphDialog Integrating Graph Knowledge into End-to-End Task-Oriented Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3102521862",
    "publication_year": 2020,
    "cited_by_count": 46,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1793121960",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1979299372",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2335875860",
      "https://openalex.org/W2396229782",
      "https://openalex.org/W2427764808",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2473965551",
      "https://openalex.org/W2514480375",
      "https://openalex.org/W2564070522",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2612364175",
      "https://openalex.org/W2746626573",
      "https://openalex.org/W2797625445",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2798494119",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2889186204",
      "https://openalex.org/W2889224519",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2953071719",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2962944953",
      "https://openalex.org/W2963020213",
      "https://openalex.org/W2963201498",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963924362",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2998201756",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3034930293",
      "https://openalex.org/W4285719527",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "End-to-end task-oriented dialogue systems aim to generate system responses directly from plain text inputs. There are two challenges for such systems: one is how to effectively incorporate external knowledge bases (KBs) into the learning framework; the other is how to accurately capture the semantics of dialogue history. In this paper, we address these two challenges by exploiting the graph structural information in the knowledge base and in the dependency parsing tree of the dialogue. To effectively leverage the structural information in dialogue history, we propose a new recurrent cell architecture which allows representation learning on graphs. To exploit the relations between entities in KBs, the model combines multi-hop reasoning ability based on the graph structure. Experimental results show that the proposed model achieves consistent improvement over state-of-the-art models on two different task-oriented dialogue datasets.",
    "match_score": 0.9942196531791907
  },
  "Parallel Interactive Networks for Multi-Domain Dialogue State Generation": {
    "openalex_id": "https://openalex.org/W3099088459",
    "publication_year": 2020,
    "cited_by_count": 21,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1604102475",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W2016589492",
      "https://openalex.org/W2115101920",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2556468274",
      "https://openalex.org/W2560376840",
      "https://openalex.org/W2561293850",
      "https://openalex.org/W2586719289",
      "https://openalex.org/W2592094563",
      "https://openalex.org/W2804010326",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2962847367",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963243930",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3034956542",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W4288094254",
      "https://openalex.org/W4288288848",
      "https://openalex.org/W4289147179"
    ],
    "abstract": "The dependencies between system and user utterances in the same turn and across different turns are not fully considered in existing multidomain dialogue state tracking (MDST) models. In this study, we argue that the incorporation of these dependencies is crucial for the design of MDST and propose Parallel Interactive Networks (PIN) to model these dependencies. Specifically, we integrate an interactive encoder to jointly model the in-turn dependencies and cross-turn dependencies. The slot-level context is introduced to extract more expressive features for different slots. And a distributed copy mechanism is utilized to selectively copy words from historical system utterances or historical user utterances. Empirical studies demonstrated the superiority of the proposed PIN model.",
    "match_score": 1.0
  },
  "Template Guided Text Generation for Task-Oriented Dialogue": {
    "openalex_id": "https://openalex.org/W3100995786",
    "publication_year": 2020,
    "cited_by_count": 56,
    "referenced_works": [
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1956340063",
      "https://openalex.org/W2012561700",
      "https://openalex.org/W2078861931",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2133512280",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2291723583",
      "https://openalex.org/W2429300145",
      "https://openalex.org/W2518570122",
      "https://openalex.org/W2748261613",
      "https://openalex.org/W2786660442",
      "https://openalex.org/W2798542795",
      "https://openalex.org/W2879018339",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2949760630",
      "https://openalex.org/W2952013107",
      "https://openalex.org/W2953071719",
      "https://openalex.org/W2963018920",
      "https://openalex.org/W2963091658",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963371754",
      "https://openalex.org/W2963578915",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963912046",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964588180",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2970444947",
      "https://openalex.org/W2970597249",
      "https://openalex.org/W2973049837",
      "https://openalex.org/W2994963504",
      "https://openalex.org/W2996176596",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W3014391559",
      "https://openalex.org/W3026997957",
      "https://openalex.org/W3034881347",
      "https://openalex.org/W3035565536",
      "https://openalex.org/W3082274269",
      "https://openalex.org/W3102854726",
      "https://openalex.org/W3115264425",
      "https://openalex.org/W4288089799"
    ],
    "abstract": "Virtual assistants such as Google Assistant, Amazon Alexa, and Apple Siri enable users to interact with a large number of services and APIs on the web using natural language. In this work, we investigate two methods for Natural Language Generation (NLG) using a single domain-independent model across a large number of APIs. First, we propose a schema-guided approach which conditions the generation on a schema describing the API in natural language. Our second method investigates the use of a small number of templates, growing linearly in number of slots, to convey the semantics of the API. To generate utterances for an arbitrary slot combination, a few simple templates are first concatenated to give a semantically correct, but possibly incoherent and ungrammatical utterance. A pre-trained language model is subsequently employed to rewrite it into coherent, natural sounding text. Through automatic metrics and human evaluation, we show that our method improves over strong baselines, is robust to out-of-domain inputs and shows improved sample efficiency.",
    "match_score": 1.0
  },
  "TOD-BERT Pre-trained Natural Language Understanding for Task-Oriented Dialogue": {
    "openalex_id": "https://openalex.org/W3100110884",
    "publication_year": 2020,
    "cited_by_count": 207,
    "referenced_works": [
      "https://openalex.org/W1566289585",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2784070054",
      "https://openalex.org/W2806600904",
      "https://openalex.org/W2884814595",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2899663614",
      "https://openalex.org/W2908510526",
      "https://openalex.org/W2923014074",
      "https://openalex.org/W2943737083",
      "https://openalex.org/W2945260553",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2948110372",
      "https://openalex.org/W2951577137",
      "https://openalex.org/W2951583236",
      "https://openalex.org/W2952267213",
      "https://openalex.org/W2963149412",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963748441",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2971274815",
      "https://openalex.org/W2971737394",
      "https://openalex.org/W2972930415",
      "https://openalex.org/W2973049837",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2977304374",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2985067290",
      "https://openalex.org/W2986193249",
      "https://openalex.org/W2986292373",
      "https://openalex.org/W2988647680",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W3035451444",
      "https://openalex.org/W3082274269",
      "https://openalex.org/W3102854726",
      "https://openalex.org/W3104078590",
      "https://openalex.org/W4288089799",
      "https://openalex.org/W4288351520",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "The underlying difference of linguistic patterns between general text and task-oriented dialogue makes existing pre-trained language models less useful in practice. In this work, we unify nine human-human and multi-turn task-oriented dialogue datasets for language modeling. To better model dialogue behavior during pre-training, we incorporate user and system tokens into the masked language modeling. We propose a contrastive objective function to simulate the response selection task. Our pre-trained task-oriented dialogue BERT (TOD-BERT) outperforms strong baselines like BERT on four downstream task-oriented dialogue applications, including intention recognition, dialogue state tracking, dialogue act prediction, and response selection. We also show that TOD-BERT has a stronger few-shot ability that can mitigate the data scarcity problem for task-oriented dialogue.",
    "match_score": 0.9936305732484076
  },
  "Diverse and Informative Dialogue Generation with Context-Specific Commonsense Knowledge Awareness": {
    "openalex_id": "https://openalex.org/W3035356453",
    "publication_year": 2020,
    "cited_by_count": 103,
    "referenced_works": [
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1965555277",
      "https://openalex.org/W1996121629",
      "https://openalex.org/W2098985784",
      "https://openalex.org/W2127795553",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2304113845",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2557436004",
      "https://openalex.org/W2561529111",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2741363662",
      "https://openalex.org/W2754194354",
      "https://openalex.org/W2757121784",
      "https://openalex.org/W2775082024",
      "https://openalex.org/W2799037524",
      "https://openalex.org/W2799176105",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2828237020",
      "https://openalex.org/W2887253986",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2952420867",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963285578",
      "https://openalex.org/W2963411289",
      "https://openalex.org/W2963520511",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963939249",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2963986868",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964207259",
      "https://openalex.org/W2964238590",
      "https://openalex.org/W2970988759",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3121541553"
    ],
    "abstract": "Generative dialogue systems tend to produce generic responses, which often leads to boring conversations. For alleviating this issue, Recent studies proposed to retrieve and introduce knowledge facts from knowledge graphs. While this paradigm works to a certain extent, it usually retrieves knowledge facts only based on the entity word itself, without considering the specific dialogue context. Thus, the introduction of the context-irrelevant knowledge facts can impact the quality of generations. To this end, this paper proposes a novel commonsense knowledge-aware dialogue generation model, ConKADI. We design a Felicitous Fact mechanism to help the model focus on the knowledge facts that are highly relevant to the context; furthermore, two techniques, Context-Knowledge Fusion and Flexible Mode Fusion are proposed to facilitate the integration of the knowledge in the ConKADI. We collect and build a large-scale Chinese dataset aligned with the commonsense knowledge for dialogue generation. Extensive evaluations over both an open-released English dataset and our Chinese dataset demonstrate that our approach ConKADI outperforms the state-of-the-art approach CCM, in most experiments.",
    "match_score": 1.0
  },
  "Importance-Driven Turn-Bidding for Spoken Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2104300420",
    "publication_year": 2010,
    "cited_by_count": 29,
    "referenced_works": [
      "https://openalex.org/W28861688",
      "https://openalex.org/W1515851193",
      "https://openalex.org/W1583748115",
      "https://openalex.org/W1604986327",
      "https://openalex.org/W1860920781",
      "https://openalex.org/W1875550513",
      "https://openalex.org/W1964725106",
      "https://openalex.org/W1986532700",
      "https://openalex.org/W2001050921",
      "https://openalex.org/W2038550763",
      "https://openalex.org/W2045804781",
      "https://openalex.org/W2048008777",
      "https://openalex.org/W2067097374",
      "https://openalex.org/W2088847709",
      "https://openalex.org/W2101308260",
      "https://openalex.org/W2101533859",
      "https://openalex.org/W2107726111",
      "https://openalex.org/W2111248079",
      "https://openalex.org/W2121528300",
      "https://openalex.org/W2132997613",
      "https://openalex.org/W2150609911",
      "https://openalex.org/W2153190547",
      "https://openalex.org/W2161296357",
      "https://openalex.org/W2161345458",
      "https://openalex.org/W2170809941",
      "https://openalex.org/W2911283634",
      "https://openalex.org/W2914656440"
    ],
    "abstract": "Current turn-taking approaches for spoken dialogue systems rely on the speaker releasing the turn before the other can take it. This reliance results in restricted interactions that can lead to inefficient dialogues. In this paper we present a model we refer to as Importance-Driven Turn-Bidding that treats turn-taking as a negotiative process. Each conversant bids for the turn based on the importance of the intended utterance, and Reinforcement Learning is used to indirectly learn this parameter. We find that Importance-Driven Turn-Bidding performs better than two current turntaking approaches in an artificial collaborative slot-filling domain. The negotiative nature of this model creates efficient dialogues, and supports the improvement of mixed-initiative interaction. 1",
    "match_score": 1.0
  },
  "GCDST A Graph-based and Copy-augmented Multi-domain Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W3101131512",
    "publication_year": 2020,
    "cited_by_count": 11,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1989996186",
      "https://openalex.org/W2118434577",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251355666",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2556468274",
      "https://openalex.org/W2567525733",
      "https://openalex.org/W2600702321",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2808293684",
      "https://openalex.org/W2892094955",
      "https://openalex.org/W2905224888",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2951231735",
      "https://openalex.org/W2951682790",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2962944953",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963224980",
      "https://openalex.org/W2963243930",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963548995",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963662654",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964015378",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2979318799",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W2996317432",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W2998432370",
      "https://openalex.org/W3008966357",
      "https://openalex.org/W3021096583",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3034908682",
      "https://openalex.org/W4288027128",
      "https://openalex.org/W4288094254",
      "https://openalex.org/W4289147179"
    ],
    "abstract": "As an essential component of task-oriented dialogue systems, Dialogue State Tracking (DST) takes charge of estimating user intentions and requests in dialogue contexts and extracting substantial goals (states) from user utterances to help the downstream modules to determine the next actions of dialogue systems. For practical usages, a major challenge to constructing a robust DST model is to process a conversation with multi-domain states. However, most existing approaches trained DST on a single domain independently, ignoring the information across domains. To tackle the multi-domain DST task, we first construct a dialogue state graph to transfer structured features among related domain-slot pairs across domains. Then, we encode the graph information of dialogue states by graph convolutional networks and utilize a hard copy mechanism to directly copy historical states from the previous conversation. Experimental results show that our model improves the performances of the multi-domain DST baseline (TRADE) with the absolute joint accuracy of 2.0% and 1.0% on the MultiWOZ 2.0 and 2.1 dialogue datasets, respectively.",
    "match_score": 0.9933774834437086
  },
  "Representing Movie Characters in Dialogues": {
    "openalex_id": "https://openalex.org/W2984342455",
    "publication_year": 2019,
    "cited_by_count": 12,
    "referenced_works": [
      "https://openalex.org/W168564468",
      "https://openalex.org/W1503441655",
      "https://openalex.org/W1525961042",
      "https://openalex.org/W1602711325",
      "https://openalex.org/W1614298861",
      "https://openalex.org/W1662133657",
      "https://openalex.org/W2101234009",
      "https://openalex.org/W2131744502",
      "https://openalex.org/W2134036914",
      "https://openalex.org/W2140945425",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2158899491",
      "https://openalex.org/W2163814903",
      "https://openalex.org/W2163922914",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2250861254",
      "https://openalex.org/W2251846762",
      "https://openalex.org/W2252211741",
      "https://openalex.org/W2278717175",
      "https://openalex.org/W2295759824",
      "https://openalex.org/W2461267643",
      "https://openalex.org/W2475151947",
      "https://openalex.org/W2563734883",
      "https://openalex.org/W2566509507",
      "https://openalex.org/W2739967154",
      "https://openalex.org/W2751916302",
      "https://openalex.org/W2773798543",
      "https://openalex.org/W2804433558",
      "https://openalex.org/W2949952998",
      "https://openalex.org/W2950577311",
      "https://openalex.org/W2951976932",
      "https://openalex.org/W2952230511",
      "https://openalex.org/W2962739339",
      "https://openalex.org/W2962795068",
      "https://openalex.org/W2963529986",
      "https://openalex.org/W2963541336",
      "https://openalex.org/W2963781647",
      "https://openalex.org/W2963890755",
      "https://openalex.org/W2963925965",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W4294170691",
      "https://openalex.org/W4297805485"
    ],
    "abstract": "We introduce a new embedding model to represent movie characters and their interactions in a dialogue by encoding in the same representation the language used by these characters as well as information about the other participants in the dialogue. We evaluate the performance of these new character embeddings on two tasks: (1) character relatedness, using a dataset we introduce consisting of a dense character interaction matrix for 4,378 unique character pairs over 22 hours of dialogue from eighteen movies; and (2) character relation classification, for fine- and coarse-grained relations, as well as sentiment relations. Our experiments show that our model significantly outperforms the traditional Word2Vec continuous bag-of-words and skip-gram models, demonstrating the effectiveness of the character embeddings we introduce. We further show how these embeddings can be used in conjunction with a visual question answering system to improve over previous results.",
    "match_score": 1.0
  },
  "Probing Task-Oriented Dialogue Representation from Language Models": {
    "openalex_id": "https://openalex.org/W3100532709",
    "publication_year": 2020,
    "cited_by_count": 20,
    "referenced_works": [
      "https://openalex.org/W1546503963",
      "https://openalex.org/W2150593711",
      "https://openalex.org/W2162833336",
      "https://openalex.org/W2515741950",
      "https://openalex.org/W2593864460",
      "https://openalex.org/W2624448691",
      "https://openalex.org/W2886305736",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2908510526",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2946359678",
      "https://openalex.org/W2962776659",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963844597",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2978017171",
      "https://openalex.org/W2980282514",
      "https://openalex.org/W2986193249",
      "https://openalex.org/W2988647680",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2996428491",
      "https://openalex.org/W3013571468",
      "https://openalex.org/W3016625483",
      "https://openalex.org/W3035305735",
      "https://openalex.org/W3035451444",
      "https://openalex.org/W3037026762",
      "https://openalex.org/W3099668342",
      "https://openalex.org/W3100110884",
      "https://openalex.org/W3100128199",
      "https://openalex.org/W3104078590",
      "https://openalex.org/W4287824654",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4299585995",
      "https://openalex.org/W4300672471",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "This paper investigates pre-trained language models to find out which model intrinsically carries the most informative representation for task-oriented dialogue tasks. We approach the problem from two aspects: supervised classifier probe and unsupervised mutual information probe. We fine-tune a feed-forward layer as the classifier probe on top of a fixed pre-trained language model with annotated labels in a supervised way. Meanwhile, we propose an unsupervised mutual information probe to evaluate the mutual dependence between a real clustering and a representation clustering. The goals of this empirical paper are to 1) investigate probing techniques, especially from the unsupervised mutual information aspect, 2) provide guidelines of pre-trained language model selection for the dialogue research community, 3) find insights of pre-training factors for dialogue application that may be the key to success.",
    "match_score": 1.0
  },
  "Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning": {
    "openalex_id": "https://openalex.org/W3104546989",
    "publication_year": 2017,
    "cited_by_count": 153,
    "referenced_works": [
      "https://openalex.org/W16046748",
      "https://openalex.org/W137851535",
      "https://openalex.org/W638006253",
      "https://openalex.org/W1489525520",
      "https://openalex.org/W1492935830",
      "https://openalex.org/W1494114146",
      "https://openalex.org/W1552182777",
      "https://openalex.org/W1584761227",
      "https://openalex.org/W1592847719",
      "https://openalex.org/W1700691926",
      "https://openalex.org/W1763968285",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1956340063",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1982897610",
      "https://openalex.org/W2021618504",
      "https://openalex.org/W2024632416",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2062295023",
      "https://openalex.org/W2078745840",
      "https://openalex.org/W2078861931",
      "https://openalex.org/W2098651115",
      "https://openalex.org/W2107587102",
      "https://openalex.org/W2109910161",
      "https://openalex.org/W2118462278",
      "https://openalex.org/W2120045257",
      "https://openalex.org/W2121325257",
      "https://openalex.org/W2121517924",
      "https://openalex.org/W2123891489",
      "https://openalex.org/W2128856065",
      "https://openalex.org/W2132997613",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2149327368",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2158548602",
      "https://openalex.org/W2161181481",
      "https://openalex.org/W2164777277",
      "https://openalex.org/W2204900930",
      "https://openalex.org/W2250530145",
      "https://openalex.org/W2251165062",
      "https://openalex.org/W2251251208",
      "https://openalex.org/W2251291469",
      "https://openalex.org/W2251818274",
      "https://openalex.org/W2291723583",
      "https://openalex.org/W2294065713",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2427764808",
      "https://openalex.org/W2473329891",
      "https://openalex.org/W2483402000",
      "https://openalex.org/W2512152365",
      "https://openalex.org/W2518570122",
      "https://openalex.org/W2530291685",
      "https://openalex.org/W2558661633",
      "https://openalex.org/W2564590796",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2578330760",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2604688337",
      "https://openalex.org/W2745039414",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2951577137",
      "https://openalex.org/W2962682659",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963262099",
      "https://openalex.org/W2963503801",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963912046",
      "https://openalex.org/W4302353911"
    ],
    "abstract": "The majority of NLG evaluation relies on automatic metrics, such as BLEU . In this paper, we motivate the need for novel, system- and data-independent automatic evaluation methods: We investigate a wide range of metrics, including state-of-the-art word-based and novel grammar-based ones, and demonstrate that they only weakly reflect human judgements of system outputs as generated by data-driven, end-to-end NLG. We also show that metric performance is data- and system-specific. Nevertheless, our results also suggest that automatic metrics perform reliably at system-level and can support system development by finding cases where a system performs poorly.",
    "match_score": 1.0
  },
  "Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings": {
    "openalex_id": "https://openalex.org/W2429300145",
    "publication_year": 2016,
    "cited_by_count": 60,
    "referenced_works": [],
    "abstract": "We present a natural language generator based on the sequence-to-sequence\\napproach that can be trained to produce natural language strings as well as\\ndeep syntax dependency trees from input dialogue acts, and we use it to\\ndirectly compare two-step generation with separate sentence planning and\\nsurface realization stages to a joint, one-step approach. We were able to train\\nboth setups successfully using very little training data. The joint setup\\noffers better performance, surpassing state-of-the-art with regards to\\nn-gram-based scores while providing more relevant outputs.\\n",
    "match_score": 1.0
  },
  "Implicit Discourse Relation Identification for Open-domain Dialogues": {
    "openalex_id": "https://openalex.org/W2964226791",
    "publication_year": 2019,
    "cited_by_count": 15,
    "referenced_works": [
      "https://openalex.org/W100948856",
      "https://openalex.org/W941608337",
      "https://openalex.org/W1969634691",
      "https://openalex.org/W2040960947",
      "https://openalex.org/W2123442489",
      "https://openalex.org/W2131861279",
      "https://openalex.org/W2135112693",
      "https://openalex.org/W2152197045",
      "https://openalex.org/W2153365547",
      "https://openalex.org/W2163074454",
      "https://openalex.org/W2164567676",
      "https://openalex.org/W2166957049",
      "https://openalex.org/W2251579496",
      "https://openalex.org/W2251939518",
      "https://openalex.org/W2252182164",
      "https://openalex.org/W2294607529",
      "https://openalex.org/W2564875206",
      "https://openalex.org/W2759361123",
      "https://openalex.org/W2781846447",
      "https://openalex.org/W2783549597",
      "https://openalex.org/W2798990287",
      "https://openalex.org/W2824107965",
      "https://openalex.org/W2864258299",
      "https://openalex.org/W2889581899",
      "https://openalex.org/W2890802255",
      "https://openalex.org/W2907283777",
      "https://openalex.org/W2962739339",
      "https://openalex.org/W2963209355",
      "https://openalex.org/W2963299810",
      "https://openalex.org/W2963391789",
      "https://openalex.org/W2963448047",
      "https://openalex.org/W4237453526",
      "https://openalex.org/W4294338648",
      "https://openalex.org/W4301488752"
    ],
    "abstract": "Discourse relation identification has been an active area of research for many years, and the challenge of identifying implicit relations remains largely an unsolved task, especially in the context of an open-domain dialogue system. Previous work primarily relies on a corpora of formal text which is inherently non-dialogic, i.e., news and journals. This data however is not suitable to handle the nuances of informal dialogue nor is it capable of navigating the plethora of valid topics present in open-domain dialogue. In this paper, we designed a novel discourse relation identification pipeline specifically tuned for open-domain dialogue systems. We firstly propose a method to automatically extract the implicit discourse relation argument pairs and labels from a dataset of dialogic turns, resulting in a novel corpus of discourse relation pairs; the first of its kind to attempt to identify the discourse relations connecting the dialogic turns in open-domain discourse. Moreover, we have taken the first steps to leverage the dialogue features unique to our task to further improve the identification of such relations by performing feature ablation and incorporating dialogue features to enhance the state-of-the-art model.",
    "match_score": 1.0
  },
  "Task-Completion Dialogue Policy Learning via Monte Carlo Tree Search with Dueling Network": {
    "openalex_id": "https://openalex.org/W3099605929",
    "publication_year": 2020,
    "cited_by_count": 10,
    "referenced_works": [
      "https://openalex.org/W50296447",
      "https://openalex.org/W183472599",
      "https://openalex.org/W1491843047",
      "https://openalex.org/W1625390266",
      "https://openalex.org/W1681299129",
      "https://openalex.org/W1758031947",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2115211925",
      "https://openalex.org/W2121863487",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2155027007",
      "https://openalex.org/W2173564293",
      "https://openalex.org/W2257979135",
      "https://openalex.org/W2396961959",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2766447205",
      "https://openalex.org/W2915295540",
      "https://openalex.org/W2951091467",
      "https://openalex.org/W2952546452",
      "https://openalex.org/W2962996309",
      "https://openalex.org/W2963170138",
      "https://openalex.org/W2963433587",
      "https://openalex.org/W2970028737"
    ],
    "abstract": "We introduce a framework of Monte Carlo Tree Search with Double-q Dueling network (MCTS-DDU) for task-completion dialogue policy learning. Different from the previous deep model-based reinforcement learning methods, which uses background planning and may suffer from low-quality simulated experiences, MCTS-DDU performs decision-time planning based on dialogue state search trees built by Monte Carlo simulations and is robust to the simulation errors. Such idea arises naturally in human behaviors, e.g. predicting others' responses and then deciding our own actions. In the simulated movie-ticket booking task, our method outperforms the background planning approaches significantly. We demonstrate the effectiveness of MCTS and the dueling network in detailed ablation studies, and also compare the performance upper bounds of these two planning methods.",
    "match_score": 1.0
  },
  "DialogueGCN A Graph Convolutional Neural Network for Emotion Recognition in Conversation": {
    "openalex_id": "https://openalex.org/W2971222961",
    "publication_year": 2019,
    "cited_by_count": 62,
    "referenced_works": [
      "https://openalex.org/W1530785623",
      "https://openalex.org/W1551039219",
      "https://openalex.org/W1662382123",
      "https://openalex.org/W1665214252",
      "https://openalex.org/W1793121960",
      "https://openalex.org/W1832693441",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2092206588",
      "https://openalex.org/W2116341502",
      "https://openalex.org/W2132555391",
      "https://openalex.org/W2146334809",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2519887557",
      "https://openalex.org/W2553397501",
      "https://openalex.org/W2578994755",
      "https://openalex.org/W2604314403",
      "https://openalex.org/W2606780347",
      "https://openalex.org/W2740550900",
      "https://openalex.org/W2788420618",
      "https://openalex.org/W2791506524",
      "https://openalex.org/W2792352584",
      "https://openalex.org/W2805662932",
      "https://openalex.org/W2891359673",
      "https://openalex.org/W2926337278",
      "https://openalex.org/W2962718314",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2963686995",
      "https://openalex.org/W2963710346",
      "https://openalex.org/W2963873807",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964300796",
      "https://openalex.org/W2964321699"
    ],
    "abstract": "Emotion recognition in conversation (ERC) has received much attention, lately, from researchers due to its potential widespread applications in diverse areas, such as health-care, education, and human resources.In this paper, we present Dialogue Graph Convolutional Network (DialogueGCN), a graph neural network based approach to ERC.We leverage self and inter-speaker dependency of the interlocutors to model conversational context for emotion recognition.Through the graph network, DialogueGCN addresses context propagation issues present in the current RNN-based methods.We empirically show that this method alleviates such issues, while outperforming the current state of the art on a number of benchmark emotion classification datasets.",
    "match_score": 0.9943502824858758
  },
  "Group-wise Contrastive Learning for Neural Dialogue Generation": {
    "openalex_id": "https://openalex.org/W3100955355",
    "publication_year": 2020,
    "cited_by_count": 30,
    "referenced_works": [
      "https://openalex.org/W932413789",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2053154970",
      "https://openalex.org/W2099471712",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2120861206",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2138204974",
      "https://openalex.org/W2138621090",
      "https://openalex.org/W2155482025",
      "https://openalex.org/W2419539795",
      "https://openalex.org/W2493916176",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2584185835",
      "https://openalex.org/W2752461516",
      "https://openalex.org/W2784400615",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2807791032",
      "https://openalex.org/W2821503932",
      "https://openalex.org/W2842511635",
      "https://openalex.org/W2890969459",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2908747729",
      "https://openalex.org/W2944870985",
      "https://openalex.org/W2951883832",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963084471",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963330684",
      "https://openalex.org/W2963360026",
      "https://openalex.org/W2963360726",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963879591",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963958388",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964134121",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2970648534",
      "https://openalex.org/W2996068536",
      "https://openalex.org/W2997657234",
      "https://openalex.org/W3005680577",
      "https://openalex.org/W3015322406",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3035044096",
      "https://openalex.org/W4252076394",
      "https://openalex.org/W4287824654",
      "https://openalex.org/W4297808394",
      "https://openalex.org/W4320013936",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Neural dialogue response generation has gained much popularity in recent years. Maximum Likelihood Estimation (MLE) objective is widely adopted in existing dialogue model learning. However, models trained with MLE objective function are plagued by the low-diversity issue when it comes to the open-domain conversational setting. Inspired by the observation that humans not only learn from the positive signals but also benefit from correcting behaviors of undesirable actions, in this work, we introduce contrastive learning into dialogue generation, where the model explicitly perceives the difference between the well-chosen positive and negative utterances. Specifically, we employ a pretrained baseline model as a reference. During contrastive learning, the target dialogue model is trained to give higher conditional probabilities for the positive samples, and lower conditional probabilities for those negative samples, compared to the reference model. To manage the multi-mapping relations prevalent in human conversation, we augment contrastive dialogue learning with group-wise dual sampling. Extensive experimental results show that the proposed group-wise contrastive learning framework is suited for training a wide range of neural dialogue generation models with very favorable performance over the baseline training approaches.",
    "match_score": 1.0
  },
  "Multi-turn Response Selection using Dialogue Dependency Relations": {
    "openalex_id": "https://openalex.org/W3101471490",
    "publication_year": 2020,
    "cited_by_count": 31,
    "referenced_works": [
      "https://openalex.org/W1566289585",
      "https://openalex.org/W1574440611",
      "https://openalex.org/W2339852062",
      "https://openalex.org/W2579198228",
      "https://openalex.org/W2582886532",
      "https://openalex.org/W2593751037",
      "https://openalex.org/W2608787653",
      "https://openalex.org/W2785414597",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2890394457",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2908602207",
      "https://openalex.org/W2949446780",
      "https://openalex.org/W2949600515",
      "https://openalex.org/W2952576857",
      "https://openalex.org/W2952813980",
      "https://openalex.org/W2953071719",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962952612",
      "https://openalex.org/W2963041453",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2967674528",
      "https://openalex.org/W2969574947",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2972437240",
      "https://openalex.org/W2973054254",
      "https://openalex.org/W2985258882",
      "https://openalex.org/W2985686011",
      "https://openalex.org/W2986292373",
      "https://openalex.org/W2986683329",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W3015071427",
      "https://openalex.org/W3181035168"
    ],
    "abstract": "Multi-turn response selection is a task designed for developing dialogue agents. The performance on this task has a remarkable improvement with pre-trained language models. However, these models simply concatenate the turns in dialogue history as the input and largely ignore the dependencies between the turns. In this paper, we propose a dialogue extraction algorithm to transform a dialogue history into threads based on their dependency relations. Each thread can be regarded as a self-contained sub-dialogue. We also propose Thread-Encoder model to encode threads and candidates into compact representations by pre-trained Transformers and finally get the matching score through an attention layer. The experiments show that dependency relations are helpful for dialogue context understanding, and our model outperforms the state-of-the-art baselines on both DSTC7 and DSTC8*, with competitive results on UbuntuV2.",
    "match_score": 1.0
  },
  "Actor-Double-Critic Incorporating Model-Based Critic for Task-Oriented Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3103837004",
    "publication_year": 2020,
    "cited_by_count": 6,
    "referenced_works": [
      "https://openalex.org/W1491843047",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1758031947",
      "https://openalex.org/W1778387566",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2000936041",
      "https://openalex.org/W2035934535",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2117989772",
      "https://openalex.org/W2120045257",
      "https://openalex.org/W2290354866",
      "https://openalex.org/W2396229782",
      "https://openalex.org/W2408200822",
      "https://openalex.org/W2559038528",
      "https://openalex.org/W2567374473",
      "https://openalex.org/W2736601468",
      "https://openalex.org/W2739936944",
      "https://openalex.org/W2759567155",
      "https://openalex.org/W2772217324",
      "https://openalex.org/W2783543950",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2889186204",
      "https://openalex.org/W2947212824",
      "https://openalex.org/W2949476504",
      "https://openalex.org/W2950314731",
      "https://openalex.org/W2950471160",
      "https://openalex.org/W2950517718",
      "https://openalex.org/W2962872206",
      "https://openalex.org/W2963064439",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963095800",
      "https://openalex.org/W2963433587",
      "https://openalex.org/W2963567240",
      "https://openalex.org/W2963674921",
      "https://openalex.org/W2963993502",
      "https://openalex.org/W2964044380",
      "https://openalex.org/W2964077562",
      "https://openalex.org/W2964080167",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964220198",
      "https://openalex.org/W2970028737",
      "https://openalex.org/W2970828515",
      "https://openalex.org/W3016142228",
      "https://openalex.org/W3021208093",
      "https://openalex.org/W4293396018",
      "https://openalex.org/W4297789121",
      "https://openalex.org/W4297806413",
      "https://openalex.org/W4306716473"
    ],
    "abstract": "In order to improve the sample-efficiency of deep reinforcement learning (DRL), we implemented imagination augmented agent (I2A) in spoken dialogue systems (SDS). Although I2A achieves a higher success rate than baselines by augmenting predicted future into a policy network, its complicated architecture introduces unwanted instability. In this work, we propose actor-double-critic (ADC) to improve the stability and overall performance of I2A. ADC simplifies the architecture of I2A to reduce excessive parameters and hyper-parameters. More importantly, a separate model-based critic shares parameters between actions and makes back-propagation explicit. In our experiments on Cambridge Restaurant Booking task, ADC enhances success rates considerably and shows robustness to imperfect environment models. In addition, ADC exhibits the stability and sample-efficiency as significantly reducing the baseline standard deviation of success rates and reaching the 80% success rate with half training data.",
    "match_score": 0.9942857142857143
  },
  "Knowledge Diffusion for Neural Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2799176105",
    "publication_year": 2018,
    "cited_by_count": 181,
    "referenced_works": [
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1552847225",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1993378086",
      "https://openalex.org/W2039133703",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2131774270",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2557436004",
      "https://openalex.org/W2583741591",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2593696076",
      "https://openalex.org/W2740107682",
      "https://openalex.org/W2754194354",
      "https://openalex.org/W2769934148",
      "https://openalex.org/W2789033601",
      "https://openalex.org/W2949555952",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963546833",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963957489",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W3022187094"
    ],
    "abstract": "End-to-end neural dialogue generation has shown promising results recently, but it does not employ knowledge to guide the generation and hence tends to generate short, general, and meaningless responses. In this paper, we propose a neural knowledge diffusion (NKD) model to introduce knowledge into dialogue generation. This method can not only match the relevant facts for the input utterance but diffuse them to similar entities. With the help of facts matching and entity diffusion, the neural dialogue generation is augmented with the ability of convergent and divergent thinking over the knowledge base. Our empirical study on a real-world dataset prove that our model is capable of generating meaningful, diverse and natural responses for both factoid-questions and knowledge grounded chi-chats. The experiment results also show that our model outperforms competitive baseline models significantly.",
    "match_score": 1.0
  },
  "Goal-Embedded Dual Hierarchical Model for Task-Oriented Dialogue Generation": {
    "openalex_id": "https://openalex.org/W4288104350",
    "publication_year": 2019,
    "cited_by_count": 1,
    "referenced_works": [],
    "abstract": "Hierarchical neural networks are often used to model inherent structures\\nwithin dialogues. For goal-oriented dialogues, these models miss a mechanism\\nadhering to the goals and neglect the distinct conversational patterns between\\ntwo interlocutors. In this work, we propose Goal-Embedded Dual Hierarchical\\nAttentional Encoder-Decoder (G-DuHA) able to center around goals and capture\\ninterlocutor-level disparity while modeling goal-oriented dialogues.\\nExperiments on dialogue generation, response generation, and human evaluations\\ndemonstrate that the proposed model successfully generates higher-quality, more\\ndiverse and goal-centric dialogues. Moreover, we apply data augmentation via\\ngoal-oriented dialogue generation for task-oriented dialog systems with better\\nperformance achieved.\\n",
    "match_score": 0.9868421052631579
  },
  "UniConv A Unified Conversational Neural Architecture for Multi-domain Task-oriented Dialogues": {
    "openalex_id": "https://openalex.org/W3101469874",
    "publication_year": 2020,
    "cited_by_count": 30,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2183341477",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2534274346",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2749436976",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2798494119",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2804491889",
      "https://openalex.org/W2915295540",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2953071719",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2956474441",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963201498",
      "https://openalex.org/W2963412005",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2969708789",
      "https://openalex.org/W2970260827",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2979478117",
      "https://openalex.org/W2979520138",
      "https://openalex.org/W2979813451",
      "https://openalex.org/W2988647680",
      "https://openalex.org/W2997108628",
      "https://openalex.org/W3008966357",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3034656193",
      "https://openalex.org/W3104546989",
      "https://openalex.org/W3106274079",
      "https://openalex.org/W4288027128",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4385245566",
      "https://openalex.org/W4394666973"
    ],
    "abstract": "Building an end-to-end conversational agent for multi-domain task-oriented dialogues has been an open challenge for two main reasons. First, tracking dialogue states of multiple domains is non-trivial as the dialogue agent must obtain complete states from all relevant domains, some of which might have shared slots among domains as well as unique slots specifically for one domain only. Second, the dialogue agent must also process various types of information across domains, including dialogue context, dialogue states, and database, to generate natural responses to users. Unlike the existing approaches that are often designed to train each module separately, we propose \u201cUniConv\u201d - a novel unified neural architecture for end-to-end conversational systems in multi-domain task-oriented dialogues, which is designed to jointly train (i) a Bi-level State Tracker which tracks dialogue states by learning signals at both slot and domain level independently, and (ii) a Joint Dialogue Act and Response Generator which incorporates information from various input components and models dialogue acts and target responses simultaneously. We conduct comprehensive experiments in dialogue state tracking, context-to-text, and end-to-end settings on the MultiWOZ2.1 benchmark, achieving superior performance over competitive baselines.",
    "match_score": 0.9946524064171123
  },
  "KdConv A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation": {
    "openalex_id": "https://openalex.org/W3035148359",
    "publication_year": 2020,
    "cited_by_count": 102,
    "referenced_works": [
      "https://openalex.org/W13682356",
      "https://openalex.org/W836999996",
      "https://openalex.org/W1482214997",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1654173042",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2140679639",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2166637769",
      "https://openalex.org/W2271840356",
      "https://openalex.org/W2294078178",
      "https://openalex.org/W2295754318",
      "https://openalex.org/W2575772232",
      "https://openalex.org/W2583741591",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2754194354",
      "https://openalex.org/W2799176105",
      "https://openalex.org/W2804552794",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2888541716",
      "https://openalex.org/W2891103209",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2891826200",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2899771611",
      "https://openalex.org/W2938704169",
      "https://openalex.org/W2938830017",
      "https://openalex.org/W2945367412",
      "https://openalex.org/W2948519922",
      "https://openalex.org/W2949769095",
      "https://openalex.org/W2950457956",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963448850",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963945575",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964588180",
      "https://openalex.org/W2971236040",
      "https://openalex.org/W2972664115",
      "https://openalex.org/W2996287690",
      "https://openalex.org/W3004150797",
      "https://openalex.org/W4285719527",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "The research of knowledge-driven conversational systems is largely limited due to the lack of dialog data which consists of multi-turn conversations on multiple topics and with knowledge annotations. In this paper, we propose a Chinese multi-domain knowledge-driven conversation dataset, KdConv, which grounds the topics in multi-turn conversations to knowledge graphs. Our corpus contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. These conversations contain in-depth discussions on related topics and natural transition between multiple topics. To facilitate the following research on this corpus, we provide several benchmark models. Comparative results show that the models can be enhanced by introducing background knowledge, yet there is still a large space for leveraging knowledge to model multi-turn conversations for further research. Results also show that there are obvious performance differences between different domains, indicating that it is worth further explore transfer learning and domain adaptation. The corpus and benchmark models are publicly available.",
    "match_score": 0.9947643979057592
  },
  "Improving Response Selection in Multi-Turn Dialogue Systems by Incorporating Domain Knowledge": {
    "openalex_id": "https://openalex.org/W2899035231",
    "publication_year": 2018,
    "cited_by_count": 0,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W40565524",
      "https://openalex.org/W295828404",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1646707810",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2096145771",
      "https://openalex.org/W2102531443",
      "https://openalex.org/W2107878631",
      "https://openalex.org/W2118434577",
      "https://openalex.org/W2121725465",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2173361515",
      "https://openalex.org/W2197546379",
      "https://openalex.org/W2251235149",
      "https://openalex.org/W2295512956",
      "https://openalex.org/W2306229986",
      "https://openalex.org/W2339852062",
      "https://openalex.org/W2346566861",
      "https://openalex.org/W2395531022",
      "https://openalex.org/W2561368124",
      "https://openalex.org/W2621404689",
      "https://openalex.org/W2785414597",
      "https://openalex.org/W2787462651",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2899771611",
      "https://openalex.org/W2952566282",
      "https://openalex.org/W2962776342",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963522640",
      "https://openalex.org/W2963542836",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964210218"
    ],
    "abstract": "Building systems that can communicate with humans is a core problem in Artificial Intelligence. This work proposes a novel neural network architecture for response selection in an end-to-end multi-turn conversational dialogue setting. The architecture applies context level attention and incorporates additional external knowledge provided by descriptions of domain-specific words. It uses a bi-directional Gated Recurrent Unit (GRU) for encoding context and responses and learns to attend over the context words given the latent response representation and vice versa.In addition, it incorporates external domain specific information using another GRU for encoding the domain keyword descriptions. This allows better representation of domain-specific keywords in responses and hence improves the overall performance. Experimental results show that our model outperforms all other state-of-the-art methods for response selection in multi-turn conversations.",
    "match_score": 1.0
  },
  "Personalizing Dialogue Agents I have a dog, do you have pets too": {
    "openalex_id": "https://openalex.org/W2963825865",
    "publication_year": 2018,
    "cited_by_count": 1157,
    "referenced_works": [
      "https://openalex.org/W836999996",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1627609287",
      "https://openalex.org/W1958706068",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2086511124",
      "https://openalex.org/W2106111649",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2139575250",
      "https://openalex.org/W2160219061",
      "https://openalex.org/W2161466446",
      "https://openalex.org/W2220374841",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2550893117",
      "https://openalex.org/W2688962481",
      "https://openalex.org/W2751124354",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2962779279",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962985038",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963448850",
      "https://openalex.org/W2963748441",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2964119254",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4297809080",
      "https://openalex.org/W4300326073"
    ],
    "abstract": "Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, Jason Weston. Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2018.",
    "match_score": 0.9846153846153847
  },
  "Dirichlet Latent Variable Hierarchical Recurrent Encoder-Decoder in Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2970603474",
    "publication_year": 2019,
    "cited_by_count": 18,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1880262756",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W2016944307",
      "https://openalex.org/W2089150068",
      "https://openalex.org/W2125320996",
      "https://openalex.org/W2140679639",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2250645967",
      "https://openalex.org/W2804766086",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963620441",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963879591",
      "https://openalex.org/W2963916785",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4231510805",
      "https://openalex.org/W4285719527"
    ],
    "abstract": "Min Zeng, Yisen Wang, Yuan Luo. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "Decoupling Strategy and Generation in Negotiation Dialogues": {
    "openalex_id": "https://openalex.org/W2963170138",
    "publication_year": 2018,
    "cited_by_count": 128,
    "referenced_works": [
      "https://openalex.org/W1480477506",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1521219245",
      "https://openalex.org/W1830940278",
      "https://openalex.org/W1920532145",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2001050921",
      "https://openalex.org/W2136152952",
      "https://openalex.org/W2146502635",
      "https://openalex.org/W2166100419",
      "https://openalex.org/W2174703168",
      "https://openalex.org/W2175723363",
      "https://openalex.org/W2246008130",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251854674",
      "https://openalex.org/W2405601855",
      "https://openalex.org/W2468710617",
      "https://openalex.org/W2579198228",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2593696076",
      "https://openalex.org/W2593751037",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2607380417",
      "https://openalex.org/W2769917417",
      "https://openalex.org/W2886444114",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962766710",
      "https://openalex.org/W2962852262",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963134326",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963217826",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963993719",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W4230563027",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W6600669541"
    ],
    "abstract": "We consider negotiation settings in which two agents use natural language to bargain on goods. Agents need to decide on both high-level strategy (e.g., proposing $50) and the execution of that strategy (e.g., generating \u201cThe bike is brand new. Selling for just $50!\u201d). Recent work on negotiation trains neural models, but their end-to-end nature makes it hard to control their strategy, and reinforcement learning tends to lead to degenerate solutions. In this paper, we propose a modular approach based on coarse dialogue acts (e.g., propose(price=50)) that decouples strategy and generation. We show that we can flexibly set the strategy using supervised learning, reinforcement learning, or domain-specific knowledge without degeneracy, while our retrieval-based generation can maintain context-awareness and produce diverse utterances. We test our approach on the recently proposed DEALORNODEAL game, and we also collect a richer dataset based on real items on Craigslist. Human evaluation shows that our systems achieve higher task success rate and more human-like negotiation behavior than previous approaches.",
    "match_score": 1.0
  },
  "Personalizing Dialogue Agents via Meta-Learning": {
    "openalex_id": "https://openalex.org/W2945978556",
    "publication_year": 2019,
    "cited_by_count": 185,
    "referenced_works": [
      "https://openalex.org/W99485931",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1598377843",
      "https://openalex.org/W1627609287",
      "https://openalex.org/W2089217417",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2140804329",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2472819217",
      "https://openalex.org/W2604763608",
      "https://openalex.org/W2608787653",
      "https://openalex.org/W2688962481",
      "https://openalex.org/W2753160622",
      "https://openalex.org/W2787501667",
      "https://openalex.org/W2797625445",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2888541716",
      "https://openalex.org/W2890394457",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2898178263",
      "https://openalex.org/W2898658996",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2962989446",
      "https://openalex.org/W2963225934",
      "https://openalex.org/W2963341924",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963775850",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963866663",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964316912",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2970192826",
      "https://openalex.org/W2979478117",
      "https://openalex.org/W3099023595",
      "https://openalex.org/W3106274079",
      "https://openalex.org/W4288631924",
      "https://openalex.org/W4300326073",
      "https://openalex.org/W4306716473",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Existing personalized dialogue models use human designed persona descriptions to improve dialogue consistency. Collecting such descriptions from existing dialogues is expensive and requires hand-crafted feature designs. In this paper, we propose to extend Model-Agnostic Meta-Learning (MAML) (Finn et al., 2017) to personalized dialogue learning without using any persona descriptions. Our model learns to quickly adapt to new personas by leveraging only a few dialogue samples collected from the same user, which is fundamentally different from conditioning the response on the persona descriptions. Empirical results on Persona-chat dataset (Zhang et al., 2018) indicate that our solution outperforms non-metalearning baselines using automatic evaluation metrics, and in terms of human-evaluated fluency and consistency.",
    "match_score": 1.0
  },
  "An Auto-Encoder Matching Model for Learning Utterance-Level Semantic Dependency in Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2888093771",
    "publication_year": 2018,
    "cited_by_count": 38,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2136939460",
      "https://openalex.org/W2181347294",
      "https://openalex.org/W2251241778",
      "https://openalex.org/W2286300105",
      "https://openalex.org/W2418993857",
      "https://openalex.org/W2536015822",
      "https://openalex.org/W2551884415",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2774104751",
      "https://openalex.org/W2807278718",
      "https://openalex.org/W2888396831",
      "https://openalex.org/W2892153332",
      "https://openalex.org/W2951359136",
      "https://openalex.org/W2962676842",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963246629",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963970666",
      "https://openalex.org/W2964183117",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Generating semantically coherent responses is still a major challenge in dialogue generation. Different from conventional text generation tasks, the mapping between inputs and responses in conversations is more complicated, which highly demands the understanding of utterance-level semantic dependency, a relation between the whole meanings of inputs and outputs. To address this problem, we propose an Auto-Encoder Matching (AEM) model to learn such dependency. The model contains two auto-encoders and one mapping module. The auto-encoders learn the semantic representations of inputs and responses, and the mapping module learns to connect the utterance-level representations. Experimental results from automatic and human evaluations demonstrate that our model is capable of generating responses of high coherence and fluency compared to baseline models.",
    "match_score": 1.0
  },
  "Queens are Powerful too Mitigating Gender Bias in Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2983931018",
    "publication_year": 2020,
    "cited_by_count": 14,
    "referenced_works": [
      "https://openalex.org/W2483215953",
      "https://openalex.org/W2528130257",
      "https://openalex.org/W2550893117",
      "https://openalex.org/W2573660794",
      "https://openalex.org/W2604487042",
      "https://openalex.org/W2615146352",
      "https://openalex.org/W2741179140",
      "https://openalex.org/W2768716007",
      "https://openalex.org/W2770618123",
      "https://openalex.org/W2774008708",
      "https://openalex.org/W2798583685",
      "https://openalex.org/W2798664956",
      "https://openalex.org/W2799258637",
      "https://openalex.org/W2804377263",
      "https://openalex.org/W2889624842",
      "https://openalex.org/W2891389695",
      "https://openalex.org/W2898081668",
      "https://openalex.org/W2899501643",
      "https://openalex.org/W2899513582",
      "https://openalex.org/W2908709331",
      "https://openalex.org/W2913222130",
      "https://openalex.org/W2916772188",
      "https://openalex.org/W2926555354",
      "https://openalex.org/W2941985495",
      "https://openalex.org/W2942580297",
      "https://openalex.org/W2947283491",
      "https://openalex.org/W2949744925",
      "https://openalex.org/W2950866572",
      "https://openalex.org/W2950997402",
      "https://openalex.org/W2951864292",
      "https://openalex.org/W2952328691",
      "https://openalex.org/W2952355715",
      "https://openalex.org/W2953029503",
      "https://openalex.org/W2953245949",
      "https://openalex.org/W2962990575",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963526187",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963919731",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2969117066",
      "https://openalex.org/W2969574947",
      "https://openalex.org/W2970252402",
      "https://openalex.org/W2970387952",
      "https://openalex.org/W2970408399",
      "https://openalex.org/W2970712718",
      "https://openalex.org/W2970723691",
      "https://openalex.org/W2970730986",
      "https://openalex.org/W2970800693",
      "https://openalex.org/W2970879410",
      "https://openalex.org/W2970948593",
      "https://openalex.org/W2971015127",
      "https://openalex.org/W2971307358",
      "https://openalex.org/W2971883198",
      "https://openalex.org/W2972051251",
      "https://openalex.org/W2972654913",
      "https://openalex.org/W2972668795",
      "https://openalex.org/W2979463066",
      "https://openalex.org/W2982277189",
      "https://openalex.org/W2982560432",
      "https://openalex.org/W2987440089",
      "https://openalex.org/W2997607995",
      "https://openalex.org/W3023029948",
      "https://openalex.org/W3034515982",
      "https://openalex.org/W3036997889",
      "https://openalex.org/W3037132330",
      "https://openalex.org/W3037286488",
      "https://openalex.org/W3037378535",
      "https://openalex.org/W3037541370",
      "https://openalex.org/W3037696302",
      "https://openalex.org/W3037697022",
      "https://openalex.org/W3042791954"
    ],
    "abstract": "Models often easily learn biases present in the training data, and their predictions directly reflect this bias. We analyze gender bias in dialogue data, and examine how this bias is actually amplified in subsequent generative chit-chat dialogue models. We measure gender bias in six existing dialogue datasets, and focus on the most biased one, the multi-player text-based fantasy adventure dataset LIGHT, as a testbed for our bias mitigation techniques. The LIGHT dataset is highly imbalanced with respect to gender, containing predominantly male characters, likely because it is entirely collected by crowdworkers and reflects common biases that exist in fantasy or medieval settings. We consider three techniques to mitigate gender bias: counterfactual data augmentation, targeted data collection, and bias controlled training. We show that our proposed techniques mitigate gender bias in LIGHT by balancing the genderedness of generated dialogue utterances and are particularly effective in combination. We quantify performance using various evaluation methods---such as quantity of gendered words, a dialogue safety classifier, and human studies---all of which show that our models generate less gendered, but equally engaging chit-chat responses.",
    "match_score": 0.9928057553956835
  },
  "Neural Dialogue State Tracking with Temporally Expressive Networks": {
    "openalex_id": "https://openalex.org/W3099289136",
    "publication_year": 2020,
    "cited_by_count": 3,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1604102475",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W2004858782",
      "https://openalex.org/W2055537935",
      "https://openalex.org/W2080045301",
      "https://openalex.org/W2107559689",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2137813581",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250456405",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2556468274",
      "https://openalex.org/W2560376840",
      "https://openalex.org/W2561293850",
      "https://openalex.org/W2586719289",
      "https://openalex.org/W2592094563",
      "https://openalex.org/W2788635322",
      "https://openalex.org/W2804010326",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2962847367",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963243930",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964218959",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W3034956542",
      "https://openalex.org/W4288027128",
      "https://openalex.org/W4289147179"
    ],
    "abstract": "Dialogue state tracking (DST) is an important part of a spoken dialogue system. Existing DST models either ignore temporal feature dependencies across dialogue turns or fail to explicitly model temporal state dependencies in a dialogue. In this work, we propose Temporally Expressive Networks (TEN) to jointly model the two types of temporal dependencies in DST. The TEN model utilizes the power of recurrent networks and probabilistic graphical models. Evaluating on standard datasets, TEN is demonstrated to improve the accuracy of turn-level-state prediction and the state aggregation.",
    "match_score": 1.0
  },
  "Knowledge-Grounded Dialogue Generation with Pre-trained Language Models": {
    "openalex_id": "https://openalex.org/W3104777900",
    "publication_year": 2020,
    "cited_by_count": 150,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2155027007",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2583186419",
      "https://openalex.org/W2584185835",
      "https://openalex.org/W2613904329",
      "https://openalex.org/W2795571593",
      "https://openalex.org/W2798888952",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2807880213",
      "https://openalex.org/W2891826200",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2899513582",
      "https://openalex.org/W2914120296",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2916772188",
      "https://openalex.org/W2923978210",
      "https://openalex.org/W2938224028",
      "https://openalex.org/W2944815030",
      "https://openalex.org/W2945260553",
      "https://openalex.org/W2950457956",
      "https://openalex.org/W2951508633",
      "https://openalex.org/W2952420867",
      "https://openalex.org/W2952468927",
      "https://openalex.org/W2954278700",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962785754",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962896208",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963167649",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963360026",
      "https://openalex.org/W2963395792",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963904606",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964082993",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964265128",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2964458951",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2966715458",
      "https://openalex.org/W2969876226",
      "https://openalex.org/W2970597249",
      "https://openalex.org/W2970608575",
      "https://openalex.org/W2971236040",
      "https://openalex.org/W2971274815",
      "https://openalex.org/W2972664115",
      "https://openalex.org/W2981851019",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2995183464",
      "https://openalex.org/W2996227762",
      "https://openalex.org/W2997300509",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3082274269",
      "https://openalex.org/W4287900772",
      "https://openalex.org/W4288089799",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "We study knowledge-grounded dialogue generation with pre-trained language models. To leverage the redundant external knowledge under capacity constraint, we propose equipping response generation defined by a pre-trained language model with a knowledge selection module, and an unsupervised approach to jointly optimizing knowledge selection and response generation with unlabeled dialogues. Empirical results on two benchmarks indicate that our model can significantly outperform state-of-the-art methods in both automatic evaluation and human judgment.",
    "match_score": 1.0
  },
  "Affordable On-line Dialogue Policy Learning": {
    "openalex_id": "https://openalex.org/W2759567155",
    "publication_year": 2017,
    "cited_by_count": 16,
    "referenced_works": [
      "https://openalex.org/W1529399279",
      "https://openalex.org/W1539975474",
      "https://openalex.org/W1589064538",
      "https://openalex.org/W1757796397",
      "https://openalex.org/W1778387566",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W1947758080",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1989996186",
      "https://openalex.org/W2054716580",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2117989772",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2121110499",
      "https://openalex.org/W2168359464",
      "https://openalex.org/W2186615578",
      "https://openalex.org/W2250456405",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251221343",
      "https://openalex.org/W2291723583",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2563829177",
      "https://openalex.org/W2740191615",
      "https://openalex.org/W2913340405",
      "https://openalex.org/W2951176429",
      "https://openalex.org/W2963064439",
      "https://openalex.org/W2963993502",
      "https://openalex.org/W4298857966"
    ],
    "abstract": "The key to building an evolvable dialogue system in real-world scenarios is to ensure an affordable on-line dialogue policy learning, which requires the on-line learning process to be safe, efficient and economical. But in reality, due to the scarcity of real interaction data, the dialogue system usually grows slowly. Besides, the poor initial dialogue policy easily leads to bad user experience and incurs a failure of attracting users to contribute training data, so that the learning process is unsustainable. To accurately depict this, two quantitative metrics are proposed to assess safety and efficiency issues. For solving the unsustainable learning problem, we proposed a complete companion teaching framework incorporating the guidance from the human teacher. Since the human teaching is expensive, we compared various teaching schemes answering the question how and when to teach, to economically utilize teaching budget, so that make the online learning process affordable.",
    "match_score": 1.0
  },
  "A Semi-Supervised Stable Variational Network for Promoting Replier-Consistency in Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2970182362",
    "publication_year": 2019,
    "cited_by_count": 10,
    "referenced_works": [
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1847211030",
      "https://openalex.org/W1909320841",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W2080094394",
      "https://openalex.org/W2108501770",
      "https://openalex.org/W2125320996",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2131774270",
      "https://openalex.org/W2133012565",
      "https://openalex.org/W2156876426",
      "https://openalex.org/W2188365844",
      "https://openalex.org/W2271840356",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2560512785",
      "https://openalex.org/W2586756136",
      "https://openalex.org/W2587284713",
      "https://openalex.org/W2594978815",
      "https://openalex.org/W2756540778",
      "https://openalex.org/W2789033601",
      "https://openalex.org/W2796335507",
      "https://openalex.org/W2953046278",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962897886",
      "https://openalex.org/W2963018920",
      "https://openalex.org/W2963081964",
      "https://openalex.org/W2963090522",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963443335",
      "https://openalex.org/W2963600562",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964042872",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3121541553",
      "https://openalex.org/W4297940714"
    ],
    "abstract": "Jinxin Chang, Ruifang He, Longbiao Wang, Xiangyu Zhao, Ting Yang, Ruifang Wang. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "Learning a Matching Model with Co-teaching for Multi-turn Response Selection in Retrieval-based Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2951287343",
    "publication_year": 2019,
    "cited_by_count": 29,
    "referenced_works": [
      "https://openalex.org/W295828404",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1527783480",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W2100913937",
      "https://openalex.org/W2102531443",
      "https://openalex.org/W2128892113",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2170738476",
      "https://openalex.org/W2256388387",
      "https://openalex.org/W2296073425",
      "https://openalex.org/W2339852062",
      "https://openalex.org/W2418993857",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2561368124",
      "https://openalex.org/W2767802162",
      "https://openalex.org/W2786471719",
      "https://openalex.org/W2798033004",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2807880213",
      "https://openalex.org/W2809210859",
      "https://openalex.org/W2885593519",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2892359699",
      "https://openalex.org/W2908331278",
      "https://openalex.org/W2949446780",
      "https://openalex.org/W2951359136",
      "https://openalex.org/W2962707484",
      "https://openalex.org/W2962768358",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2962838727",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963386594",
      "https://openalex.org/W2963780286",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963826056",
      "https://openalex.org/W2963962154",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2963986868",
      "https://openalex.org/W2964092386",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964150246",
      "https://openalex.org/W2964309167",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W4294170691",
      "https://openalex.org/W4300125564"
    ],
    "abstract": "We study learning of a matching model for response selection in retrieval-based dialogue systems. The problem is equally important with designing the architecture of a model, but is less explored in existing literature. To learn a robust matching model from noisy training data, we propose a general co-teaching framework with three specific teaching strategies that cover both teaching with loss functions and teaching with data curriculum. Under the framework, we simultaneously learn two matching models with independent training sets. In each iteration, one model transfers the knowledge learned from its training set to the other model, and at the same time receives the guide from the other model on how to overcome noise in training. Through being both a teacher and a student, the two models learn from each other and get improved together. Evaluation results on two public data sets indicate that the proposed learning approach can generally and significantly improve the performance of existing matching models.",
    "match_score": 1.0
  },
  "Skeleton-to-Response Dialogue Generation Guided by Retrieval Memory": {
    "openalex_id": "https://openalex.org/W2963521540",
    "publication_year": 2019,
    "cited_by_count": 63,
    "referenced_works": [
      "https://openalex.org/W295828404",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1958706068",
      "https://openalex.org/W1970026646",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2099471712",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2159640018",
      "https://openalex.org/W2161466446",
      "https://openalex.org/W2170738476",
      "https://openalex.org/W2399880602",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2539809671",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2593696076",
      "https://openalex.org/W2605246398",
      "https://openalex.org/W2611714756",
      "https://openalex.org/W2740258984",
      "https://openalex.org/W2795601629",
      "https://openalex.org/W2798463315",
      "https://openalex.org/W2798970679",
      "https://openalex.org/W2801454967",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2885421725",
      "https://openalex.org/W2897139265",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2951359136",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962985882",
      "https://openalex.org/W2963034998",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963371754",
      "https://openalex.org/W2963411289",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963958388",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4230563027",
      "https://openalex.org/W4300125564",
      "https://openalex.org/W6635590879",
      "https://openalex.org/W6642850889",
      "https://openalex.org/W6698480918",
      "https://openalex.org/W6727329663"
    ],
    "abstract": "Deng Cai, Yan Wang, Wei Bi, Zhaopeng Tu, Xiaojiang Liu, Wai Lam, Shuming Shi. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019.",
    "match_score": 0.9925925925925926
  },
  "Towards Low-Resource Semi-Supervised Dialogue Generation with Meta-Learning": {
    "openalex_id": "https://openalex.org/W3100938283",
    "publication_year": 2020,
    "cited_by_count": 2,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2293363371",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2604763608",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2808093377",
      "https://openalex.org/W2889448364",
      "https://openalex.org/W2889494558",
      "https://openalex.org/W2949141958",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2963201498",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2970182362",
      "https://openalex.org/W2970260827",
      "https://openalex.org/W2970529793",
      "https://openalex.org/W2997108628",
      "https://openalex.org/W2998572029",
      "https://openalex.org/W3034956542",
      "https://openalex.org/W3101893606",
      "https://openalex.org/W3102854726"
    ],
    "abstract": "In this paper, we propose a meta-learning based semi-supervised explicit dialogue state tracker (SEDST) for neural dialogue generation, denoted as MEDST. Our main motivation is to further bridge the chasm between the need for high accuracy dialogue state tracker and the common reality that only scarce annotated data is available for most real-life dialogue tasks. Specifically, MEDST has two core steps: meta-training with adequate unlabelled data in an automatic way and meta-testing with a few annotated data by supervised learning. In particular, we enhance SEDST via entropy regularization, and investigate semi-supervised learning frameworks based on model-agnostic meta-learning (MAML) that are able to reduce the amount of required intermediate state labelling. We find that by leveraging un-annotated data in meta-way instead, the amount of dialogue state annotations can be reduced below 10% while maintaining equivalent system performance. Experimental results show MEDST outperforms SEDST substantially by 18.7% joint goal accuracy and 14.3% entity match rate on the KVRET corpus with 2% labelled data in semi-supervision.",
    "match_score": 1.0
  },
  "Conditional Generation and Snapshot Learning in Neural Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2963412005",
    "publication_year": 2016,
    "cited_by_count": 73,
    "referenced_works": [
      "https://openalex.org/W179875071",
      "https://openalex.org/W196214544",
      "https://openalex.org/W1514535095",
      "https://openalex.org/W1544827683",
      "https://openalex.org/W1552182777",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1793121960",
      "https://openalex.org/W1810943226",
      "https://openalex.org/W1947758080",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1954715867",
      "https://openalex.org/W1969152782",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1987326241",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2107598941",
      "https://openalex.org/W2115101920",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2132679783",
      "https://openalex.org/W2142086811",
      "https://openalex.org/W2171928131",
      "https://openalex.org/W2220374841",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2291723583",
      "https://openalex.org/W2295953541",
      "https://openalex.org/W2296073425",
      "https://openalex.org/W2296712013",
      "https://openalex.org/W2950178297",
      "https://openalex.org/W2950635152",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962905474",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963295373",
      "https://openalex.org/W2963606038",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964119254",
      "https://openalex.org/W2964267515",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964325845",
      "https://openalex.org/W2964352131"
    ],
    "abstract": "Tsung-Hsien Wen, Milica Ga\u0161i\u0107, Nikola Mrk\u0161i\u0107, Lina M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes, David Vandyke, Steve Young. Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. 2016.",
    "match_score": 1.0
  },
  "Multi-Domain Dialogue Acts and Response Co-Generation": {
    "openalex_id": "https://openalex.org/W3035337525",
    "publication_year": 2020,
    "cited_by_count": 45,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2612675303",
      "https://openalex.org/W2749436976",
      "https://openalex.org/W2751124354",
      "https://openalex.org/W2804010326",
      "https://openalex.org/W2804491889",
      "https://openalex.org/W2888779557",
      "https://openalex.org/W2888849322",
      "https://openalex.org/W2892248135",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2915295540",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2953071719",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2956474441",
      "https://openalex.org/W2963134326",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963260202",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963442512",
      "https://openalex.org/W2963677766",
      "https://openalex.org/W2963699608",
      "https://openalex.org/W2963768805",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964044380",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2979520138",
      "https://openalex.org/W2988536330",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W4288025838",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Generating fluent and informative responses is of critical importance for task-oriented dialogue systems. Existing pipeline approaches generally predict multiple dialogue acts first and use them to assist response generation. There are at least two shortcomings with such approaches. First, the inherent structures of multi-domain dialogue acts are neglected. Second, the semantic associations between acts and responses are not taken into account for response generation. To address these issues, we propose a neural co-generation model that generates dialogue acts and responses concurrently. Unlike those pipeline approaches, our act generation module preserves the semantic structures of multi-domain dialogue acts and our response generation module dynamically attends to different acts as needed. We train the two modules jointly using an uncertainty loss to adjust their task weights adaptively. Extensive experiments are conducted on the large-scale MultiWOZ dataset and the results show that our model achieves very favorable improvement over several state-of-the-art models in both automatic and human evaluations.",
    "match_score": 1.0
  },
  "Toward Stance-based Personas for Opinionated Dialogues": {
    "openalex_id": "https://openalex.org/W3092134391",
    "publication_year": 2020,
    "cited_by_count": 0,
    "referenced_works": [
      "https://openalex.org/W1895577753",
      "https://openalex.org/W1970260754",
      "https://openalex.org/W2043909051",
      "https://openalex.org/W2062812566",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2112006025",
      "https://openalex.org/W2130995195",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2327805699",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2548441712",
      "https://openalex.org/W2562522356",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2612675303",
      "https://openalex.org/W2688962481",
      "https://openalex.org/W2739836857",
      "https://openalex.org/W2800044557",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2890771450",
      "https://openalex.org/W2892037875",
      "https://openalex.org/W2900220550",
      "https://openalex.org/W2900227126",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2916898195",
      "https://openalex.org/W2962717047",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963672599",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963945575",
      "https://openalex.org/W2971274815",
      "https://openalex.org/W2996287690",
      "https://openalex.org/W2997020034",
      "https://openalex.org/W3034758820",
      "https://openalex.org/W3082274269",
      "https://openalex.org/W3100111242",
      "https://openalex.org/W3102649892",
      "https://openalex.org/W3103944220",
      "https://openalex.org/W3117055973"
    ],
    "abstract": "In the context of chit-chat dialogues it has been shown that endowing systems with a persona profile is important to produce more coherent and meaningful conversations. Still, the representation of such personas has thus far been limited to a fact-based representation (e.g. \"I have two cats.\"). We argue that these representations remain superficial w.r.t. the complexity of human personality. In this work, we propose to make a step forward and investigate stance-based persona, trying to grasp more profound characteristics, such as opinions, values, and beliefs to drive language generation. To this end, we introduce a novel dataset allowing to explore different stance-based persona representations and their impact on claim generation, showing that they are able to grasp abstract and profound aspects of the author persona.",
    "match_score": 1.0
  },
  "Task-oriented Dialogue System for Automatic Diagnosis": {
    "openalex_id": "https://openalex.org/W2886305736",
    "publication_year": 2018,
    "cited_by_count": 197,
    "referenced_works": [
      "https://openalex.org/W1808652302",
      "https://openalex.org/W1839682376",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2168490009",
      "https://openalex.org/W2169767637",
      "https://openalex.org/W2175723363",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2518582440",
      "https://openalex.org/W2529481617",
      "https://openalex.org/W2604580630",
      "https://openalex.org/W2623759943",
      "https://openalex.org/W2765111838",
      "https://openalex.org/W2772001136",
      "https://openalex.org/W2772633986",
      "https://openalex.org/W2788477667",
      "https://openalex.org/W2798161840",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2950722229",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963993719",
      "https://openalex.org/W3104546989"
    ],
    "abstract": "Zhongyu Wei, Qianlong Liu, Baolin Peng, Huaixiao Tou, Ting Chen, Xuanjing Huang, Kam-fai Wong, Xiangying Dai. Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 2018.",
    "match_score": 1.0
  },
  "Harnessing Sequence Labeling for Sarcasm Detection in Dialogue from TV Series \u2018Friends\u2019": {
    "openalex_id": "https://openalex.org/W2510141903",
    "publication_year": 2016,
    "cited_by_count": 69,
    "referenced_works": [
      "https://openalex.org/W169052826",
      "https://openalex.org/W1551909886",
      "https://openalex.org/W1576520375",
      "https://openalex.org/W1842080548",
      "https://openalex.org/W1973914601",
      "https://openalex.org/W2008217938",
      "https://openalex.org/W2024011160",
      "https://openalex.org/W2038634595",
      "https://openalex.org/W2038997150",
      "https://openalex.org/W2064594469",
      "https://openalex.org/W2077018496",
      "https://openalex.org/W2097726431",
      "https://openalex.org/W2098437222",
      "https://openalex.org/W2099653665",
      "https://openalex.org/W2101234009",
      "https://openalex.org/W2104146993",
      "https://openalex.org/W2127467141",
      "https://openalex.org/W2138260386",
      "https://openalex.org/W2139686264",
      "https://openalex.org/W2142112646",
      "https://openalex.org/W2157961599",
      "https://openalex.org/W2158349948",
      "https://openalex.org/W2162860143",
      "https://openalex.org/W2165044314",
      "https://openalex.org/W2250247764",
      "https://openalex.org/W2250489604",
      "https://openalex.org/W2251920663",
      "https://openalex.org/W2251971374",
      "https://openalex.org/W2263859238",
      "https://openalex.org/W2294058101",
      "https://openalex.org/W2405202646",
      "https://openalex.org/W2419539795",
      "https://openalex.org/W2489406233",
      "https://openalex.org/W2949600092",
      "https://openalex.org/W4231096565"
    ],
    "abstract": "This paper is a novel study that views sarcasm detection in dialogue as a sequence labeling task, where a dialogue is made up of a sequence of utterances.We create a manuallylabeled dataset of dialogue from TV series 'Friends' annotated with sarcasm.Our goal is to predict sarcasm in each utterance, using sequential nature of a scene.We show performance gain using sequence labeling as compared to classification-based approaches.Our experiments are based on three sets of features, one is derived from information in our dataset, the other two are from past works.Two sequence labeling algorithms (SVM-HMM and SEARN) outperform three classification algorithms (SVM, Naive Bayes) for all these feature sets, with an increase in F-score of around 4%.Our observations highlight the viability of sequence labeling techniques for sarcasm detection of dialogue.",
    "match_score": 0.9770114942528736
  },
  "Structured Attention for Unsupervised Dialogue Structure Induction": {
    "openalex_id": "https://openalex.org/W3087176213",
    "publication_year": 2020,
    "cited_by_count": 29,
    "referenced_works": [
      "https://openalex.org/W138607541",
      "https://openalex.org/W140467209",
      "https://openalex.org/W592244745",
      "https://openalex.org/W962073815",
      "https://openalex.org/W1654173042",
      "https://openalex.org/W1831406492",
      "https://openalex.org/W1877570817",
      "https://openalex.org/W1889081078",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W1978470410",
      "https://openalex.org/W1993378086",
      "https://openalex.org/W2005900670",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2115615127",
      "https://openalex.org/W2121738076",
      "https://openalex.org/W2167702024",
      "https://openalex.org/W2169218343",
      "https://openalex.org/W2170323078",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251949648",
      "https://openalex.org/W2930865789",
      "https://openalex.org/W2934842096",
      "https://openalex.org/W2947622595",
      "https://openalex.org/W2949847915",
      "https://openalex.org/W2951004968",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963411289",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2970726176",
      "https://openalex.org/W3004162225",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3037738964",
      "https://openalex.org/W4245826738",
      "https://openalex.org/W4288345685",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Inducing a meaningful structural representation from one or a set of\\ndialogues is a crucial but challenging task in computational linguistics.\\nAdvancement made in this area is critical for dialogue system design and\\ndiscourse analysis. It can also be extended to solve grammatical inference. In\\nthis work, we propose to incorporate structured attention layers into a\\nVariational Recurrent Neural Network (VRNN) model with discrete latent states\\nto learn dialogue structure in an unsupervised fashion. Compared to a vanilla\\nVRNN, structured attention enables a model to focus on different parts of the\\nsource sentence embeddings while enforcing a structural inductive bias.\\nExperiments show that on two-party dialogue datasets, VRNN with structured\\nattention learns semantic structures that are similar to templates used to\\ngenerate this dialogue corpus. While on multi-party dialogue datasets, our\\nmodel learns an interactive structure demonstrating its capability of\\ndistinguishing speakers or addresses, automatically disentangling dialogues\\nwithout explicit human annotation.\\n",
    "match_score": 1.0
  },
  "Game-Based Video-Context Dialogue": {
    "openalex_id": "https://openalex.org/W2889844776",
    "publication_year": 2018,
    "cited_by_count": 20,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W62710299",
      "https://openalex.org/W154525918",
      "https://openalex.org/W836999996",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1544827683",
      "https://openalex.org/W1548360242",
      "https://openalex.org/W1591607137",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1973674431",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1995945562",
      "https://openalex.org/W2014571624",
      "https://openalex.org/W2016522586",
      "https://openalex.org/W2041065123",
      "https://openalex.org/W2059857707",
      "https://openalex.org/W2099603084",
      "https://openalex.org/W2106547558",
      "https://openalex.org/W2108366050",
      "https://openalex.org/W2113850638",
      "https://openalex.org/W2120804913",
      "https://openalex.org/W2126891226",
      "https://openalex.org/W2133459682",
      "https://openalex.org/W2139501017",
      "https://openalex.org/W2144717869",
      "https://openalex.org/W2144960104",
      "https://openalex.org/W2153501885",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2154764394",
      "https://openalex.org/W2155898337",
      "https://openalex.org/W2160219061",
      "https://openalex.org/W2161466446",
      "https://openalex.org/W2163068732",
      "https://openalex.org/W2288380077",
      "https://openalex.org/W2335122196",
      "https://openalex.org/W2396614874",
      "https://openalex.org/W2418993857",
      "https://openalex.org/W2550936021",
      "https://openalex.org/W2551396370",
      "https://openalex.org/W2558809543",
      "https://openalex.org/W2562335618",
      "https://openalex.org/W2571175805",
      "https://openalex.org/W2575870198",
      "https://openalex.org/W2583186419",
      "https://openalex.org/W2583816737",
      "https://openalex.org/W2597655663",
      "https://openalex.org/W2606982687",
      "https://openalex.org/W2756923502",
      "https://openalex.org/W2768661419",
      "https://openalex.org/W2769997045",
      "https://openalex.org/W2774005037",
      "https://openalex.org/W2784820185",
      "https://openalex.org/W2796084947",
      "https://openalex.org/W2949615363",
      "https://openalex.org/W2950697717",
      "https://openalex.org/W2952982889",
      "https://openalex.org/W2962684798",
      "https://openalex.org/W2962707484",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963064439",
      "https://openalex.org/W2963109634",
      "https://openalex.org/W2963386218",
      "https://openalex.org/W2963545239",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963800628",
      "https://openalex.org/W2963834699",
      "https://openalex.org/W2963890755",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4294170691",
      "https://openalex.org/W4310299640",
      "https://openalex.org/W4317607572"
    ],
    "abstract": "Current dialogue systems focus more on textual and speech context knowledge and are usually based on two speakers. Some recent work has investigated static image-based dialogue. However, several real-world human interactions also involve dynamic visual context (similar to videos) as well as dialogue exchanges among multiple speakers. To move closer towards such multimodal conversational skills and visually-situated applications, we introduce a new video-context, many-speaker dialogue dataset based on live-broadcast soccer game videos and chats from Twitch.tv. This challenging testbed allows us to develop visually-grounded dialogue models that should generate relevant temporal and spatial event language from the live video, while also being relevant to the chat history. For strong baselines, we also present several discriminative and generative models, e.g., based on tridirectional attention flow (TriDAF). We evaluate these models via retrieval ranking-recall, automatic phrase-matching metrics, as well as human evaluation studies. We also present dataset analyses, model ablations, and visualizations to understand the contribution of different modalities and model components.",
    "match_score": 1.0
  },
  "Deal or No Deal End-to-End Learning of Negotiation Dialogues": {
    "openalex_id": "https://openalex.org/W2625113742",
    "publication_year": 2017,
    "cited_by_count": 51,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1625390266",
      "https://openalex.org/W1681299129",
      "https://openalex.org/W1830940278",
      "https://openalex.org/W1920532145",
      "https://openalex.org/W1958706068",
      "https://openalex.org/W2040123554",
      "https://openalex.org/W2043985309",
      "https://openalex.org/W2104067325",
      "https://openalex.org/W2167149475",
      "https://openalex.org/W2175723363",
      "https://openalex.org/W2188321399",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2257979135",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2340944142",
      "https://openalex.org/W2403702038",
      "https://openalex.org/W2410983263",
      "https://openalex.org/W2410985346",
      "https://openalex.org/W2598220062",
      "https://openalex.org/W2602275733",
      "https://openalex.org/W2608175740",
      "https://openalex.org/W2886444114",
      "https://openalex.org/W2953119472",
      "https://openalex.org/W2953158660",
      "https://openalex.org/W2964119254",
      "https://openalex.org/W2964199361",
      "https://openalex.org/W2964308564"
    ],
    "abstract": "Much of human dialogue occurs in semi-cooperative settings, where agents with different goals attempt to agree on common decisions. Negotiations require complex communication and reasoning skills, but success is easy to measure, making this an interesting task for AI. We gather a large dataset of human-human negotiations on a multi-issue bargaining task, where agents who cannot observe each other's reward functions must reach an agreement (or a deal) via natural language dialogue. For the first time, we show it is possible to train end-to-end models for negotiation, which must learn both linguistic and reasoning skills with no annotated dialogue states. We also introduce dialogue rollouts, in which the model plans ahead by simulating possible complete continuations of the conversation, and find that this technique dramatically improves performance. Our code and dataset are publicly available (https://github.com/facebookresearch/end-to-end-negotiator).",
    "match_score": 0.9917355371900827
  },
  "Retrieval-guided Dialogue Response Generation via a Matching-to-Generation Framework": {
    "openalex_id": "https://openalex.org/W2970579055",
    "publication_year": 2019,
    "cited_by_count": 58,
    "referenced_works": [
      "https://openalex.org/W295828404",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W2025768430",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2161466446",
      "https://openalex.org/W2170738476",
      "https://openalex.org/W2183341477",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2539809671",
      "https://openalex.org/W2584220694",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2611029872",
      "https://openalex.org/W2616969219",
      "https://openalex.org/W2739046565",
      "https://openalex.org/W2788330850",
      "https://openalex.org/W2798463315",
      "https://openalex.org/W2803267010",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2808293489",
      "https://openalex.org/W2885421725",
      "https://openalex.org/W2888213795",
      "https://openalex.org/W2889009749",
      "https://openalex.org/W2890274659",
      "https://openalex.org/W2949747155",
      "https://openalex.org/W2949782788",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2951359136",
      "https://openalex.org/W2951824008",
      "https://openalex.org/W2952723239",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963018920",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963371754",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963411289",
      "https://openalex.org/W2963939249",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2963986868",
      "https://openalex.org/W2964178377",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W4236521339",
      "https://openalex.org/W4300125564",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Deng Cai, Yan Wang, Wei Bi, Zhaopeng Tu, Xiaojiang Liu, Shuming Shi. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "Mitigating Gender Bias for Neural Dialogue Generation with Adversarial Learning": {
    "openalex_id": "https://openalex.org/W3100355408",
    "publication_year": 2020,
    "cited_by_count": 54,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2054192854",
      "https://openalex.org/W2143017621",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2187089797",
      "https://openalex.org/W2483215953",
      "https://openalex.org/W2510955516",
      "https://openalex.org/W2547875792",
      "https://openalex.org/W2565378226",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2618825949",
      "https://openalex.org/W2758912220",
      "https://openalex.org/W2760062370",
      "https://openalex.org/W2890719433",
      "https://openalex.org/W2940009958",
      "https://openalex.org/W2950018712",
      "https://openalex.org/W2953320089",
      "https://openalex.org/W2962917899",
      "https://openalex.org/W2963078909",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963363122",
      "https://openalex.org/W2963524705",
      "https://openalex.org/W2963526187",
      "https://openalex.org/W2963612262",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2964119254",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2972766508",
      "https://openalex.org/W3013520104",
      "https://openalex.org/W3015001695",
      "https://openalex.org/W3031668985",
      "https://openalex.org/W3103639864",
      "https://openalex.org/W3104617516",
      "https://openalex.org/W3117655171",
      "https://openalex.org/W3181414820",
      "https://openalex.org/W4285790115",
      "https://openalex.org/W4288104702",
      "https://openalex.org/W4294294142"
    ],
    "abstract": "Dialogue systems play an increasingly important role in various aspects of our daily life. It is evident from recent research that dialogue systems trained on human conversation data are biased. In particular, they can produce responses that reflect people\u2019s gender prejudice. Many debiasing methods have been developed for various NLP tasks, such as word embedding. However, they are not directly applicable to dialogue systems because they are likely to force dialogue models to generate similar responses for different genders. This greatly degrades the diversity of the generated responses and immensely hurts the performance of the dialogue models. In this paper, we propose a novel adversarial learning framework Debiased-Chat to train dialogue models free from gender bias while keeping their performance. Extensive experiments on two real-world conversation datasets show that our framework significantly reduces gender bias in dialogue models while maintaining the response quality.",
    "match_score": 1.0
  },
  "Sequicity Simplifying Task-oriented Dialogue Systems with Single Sequence-to-Sequence Architectures": {
    "openalex_id": "https://openalex.org/W2798914047",
    "publication_year": 2018,
    "cited_by_count": 350,
    "referenced_works": [
      "https://openalex.org/W10050918",
      "https://openalex.org/W1767747848",
      "https://openalex.org/W1905882502",
      "https://openalex.org/W1969152782",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1993567041",
      "https://openalex.org/W2061495585",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2108806737",
      "https://openalex.org/W2115101920",
      "https://openalex.org/W2175723363",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251149342",
      "https://openalex.org/W2251235149",
      "https://openalex.org/W2464790259",
      "https://openalex.org/W2470040910",
      "https://openalex.org/W2552839021",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2759621817",
      "https://openalex.org/W2919873176",
      "https://openalex.org/W2949558714",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2962905474",
      "https://openalex.org/W2963043030",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963134326",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963412005",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963993719",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964268978",
      "https://openalex.org/W3121541553",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "10.18653/v1/P18-1133",
    "match_score": 0.9949748743718593
  },
  "Preserving Distributional Information in Dialogue Act Classification": {
    "openalex_id": "https://openalex.org/W2760623195",
    "publication_year": 2017,
    "cited_by_count": 12,
    "referenced_works": [
      "https://openalex.org/W77001256",
      "https://openalex.org/W648786980",
      "https://openalex.org/W1526096287",
      "https://openalex.org/W1810943226",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2106226466",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2166637769",
      "https://openalex.org/W2176263492",
      "https://openalex.org/W2312383716",
      "https://openalex.org/W2401527985",
      "https://openalex.org/W2741675028",
      "https://openalex.org/W2950304420",
      "https://openalex.org/W2964036636",
      "https://openalex.org/W2964139507"
    ],
    "abstract": "This paper introduces a novel training/decoding strategy for sequence labeling.<br/>Instead of greedily choosing a label at each time step, and using it for<br/>the next prediction, we retain the probability distribution over the current label,<br/>and pass this distribution to the next prediction. This approach allows us to avoid the effect of label bias and error propagation in sequence learning/decoding. Our experiments on dialogue act classification demonstrate the effectiveness of this approach. Even though our underlying neural network model is relatively simple, it outperforms more complex neural models, achieving state-of-the-art results on<br/>the MapTask and Switchboard corpora.",
    "match_score": 1.0
  },
  "Ordinal and Attribute Aware Response Generation in a Multimodal Dialogue System": {
    "openalex_id": "https://openalex.org/W2951450739",
    "publication_year": 2019,
    "cited_by_count": 29,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1533861849",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1686810756",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W2016589492",
      "https://openalex.org/W2062989416",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133512280",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2183341477",
      "https://openalex.org/W2293453011",
      "https://openalex.org/W2296712013",
      "https://openalex.org/W2412393473",
      "https://openalex.org/W2558809543",
      "https://openalex.org/W2583186419",
      "https://openalex.org/W2603266952",
      "https://openalex.org/W2605246398",
      "https://openalex.org/W2729046720",
      "https://openalex.org/W2740747242",
      "https://openalex.org/W2768661419",
      "https://openalex.org/W2785523195",
      "https://openalex.org/W2808503835",
      "https://openalex.org/W2897182555",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962764403",
      "https://openalex.org/W2962814079",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963049308",
      "https://openalex.org/W2963150162",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963287297",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963579811",
      "https://openalex.org/W2963717374",
      "https://openalex.org/W2963748384",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963917086",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964011461",
      "https://openalex.org/W2964042872",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2969576497",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3101313921",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Multimodal dialogue systems have opened new frontiers in the traditional goal-oriented dialogue systems. The state-of-the-art dialogue systems are primarily based on unimodal sources, predominantly the text, and hence cannot capture the information present in the other sources such as videos, audios, images etc. With the availability of large scale multimodal dialogue dataset (MMD) (Saha et al., 2018) on the fashion domain, the visual appearance of the products is essential for understanding the intention of the user. Without capturing the information from both the text and image, the system will be incapable of generating correct and desirable responses. In this paper, we propose a novel position and attribute aware attention mechanism to learn enhanced image representation conditioned on the user utterance. Our evaluation shows that the proposed model can generate appropriate responses while preserving the position and attribute information. Experimental results also prove that our proposed approach attains superior performance compared to the baseline models, and outperforms the state-of-the-art approaches on text similarity based evaluation metrics.",
    "match_score": 1.0
  },
  "MuTual A Dataset for Multi-Turn Dialogue Reasoning": {
    "openalex_id": "https://openalex.org/W3034446185",
    "publication_year": 2020,
    "cited_by_count": 114,
    "referenced_works": [
      "https://openalex.org/W1599016936",
      "https://openalex.org/W2086511124",
      "https://openalex.org/W2561529111",
      "https://openalex.org/W2606964149",
      "https://openalex.org/W2608787653",
      "https://openalex.org/W2742320045",
      "https://openalex.org/W2747329762",
      "https://openalex.org/W2794325560",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2804897457",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2912904516",
      "https://openalex.org/W2919420119",
      "https://openalex.org/W2925618549",
      "https://openalex.org/W2948947170",
      "https://openalex.org/W2949446780",
      "https://openalex.org/W2950444459",
      "https://openalex.org/W2952813980",
      "https://openalex.org/W2962838727",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962989446",
      "https://openalex.org/W2963159690",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963520511",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2963995027",
      "https://openalex.org/W2964207259",
      "https://openalex.org/W2964223283",
      "https://openalex.org/W2964309167",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2967674528",
      "https://openalex.org/W2970780738",
      "https://openalex.org/W2970960706",
      "https://openalex.org/W2971034336",
      "https://openalex.org/W2972324944",
      "https://openalex.org/W3099023595",
      "https://openalex.org/W3105492289",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Non-task oriented dialogue systems have achieved great success in recent years due to largely accessible conversation data and the development of deep learning techniques. Given a context, current systems are able to yield a relevant and fluent response, but sometimes make logical mistakes because of weak reasoning capabilities. To facilitate the conversation reasoning research, we introduce MuTual, a novel dataset for Multi-Turn dialogue Reasoning, consisting of 8,860 manually annotated dialogues based on Chinese student English listening comprehension exams. Compared to previous benchmarks for non-task oriented dialogue systems, MuTual is much more challenging since it requires a model that be able to handle various reasoning problems. Empirical results show that state-of-the-art methods only reach 71%, which is far behind human performance of 94%, indicating that there is ample room for improving reasoning ability.",
    "match_score": 0.9900990099009901
  },
  "Feudal Reinforcement Learning for Dialogue Management in Large Domains": {
    "openalex_id": "https://openalex.org/W2789327587",
    "publication_year": 2018,
    "cited_by_count": 8,
    "referenced_works": [
      "https://openalex.org/W1757796397",
      "https://openalex.org/W2040123554",
      "https://openalex.org/W2154740693",
      "https://openalex.org/W2160371091",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250558341",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2312609093",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2558661633",
      "https://openalex.org/W2772217324",
      "https://openalex.org/W2887703723",
      "https://openalex.org/W2964044380",
      "https://openalex.org/W6701898310"
    ],
    "abstract": "Reinforcement learning (RL) is a promising approach to solve dialogue policy optimisation. Traditional RL algorithms, however, fail to scale to large domains due to the curse of dimensionality. We propose a novel Dialogue Management architecture, based on Feudal RL, which decomposes the decision into two steps; a first step where a master policy selects a subset of primitive actions, and a second step where a primitive action is chosen from the selected subset. The structural information included in the domain ontology is used to abstract the dialogue state space, taking the decisions at each step using different parts of the abstracted state. This, combined with an information sharing mechanism between slots, increases the scalability to large domains. We show that an implementation of this approach, based on Deep-Q Networks, significantly outperforms previous state of the art in several dialogue domains and environments, without the need of any additional reward signal.",
    "match_score": 1.0
  },
  "BiST Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues": {
    "openalex_id": "https://openalex.org/W3102037269",
    "publication_year": 2020,
    "cited_by_count": 29,
    "referenced_works": [
      "https://openalex.org/W1514535095",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1522734439",
      "https://openalex.org/W1533861849",
      "https://openalex.org/W1575833922",
      "https://openalex.org/W1933349210",
      "https://openalex.org/W1947481528",
      "https://openalex.org/W1956340063",
      "https://openalex.org/W1957740064",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2123301721",
      "https://openalex.org/W2131774270",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2156303437",
      "https://openalex.org/W2183341477",
      "https://openalex.org/W2194775991",
      "https://openalex.org/W2337252826",
      "https://openalex.org/W2342662179",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2508429489",
      "https://openalex.org/W2526050071",
      "https://openalex.org/W2526449353",
      "https://openalex.org/W2549139847",
      "https://openalex.org/W2560730294",
      "https://openalex.org/W2565656701",
      "https://openalex.org/W2606982687",
      "https://openalex.org/W2810643877",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2904291752",
      "https://openalex.org/W2904452845",
      "https://openalex.org/W2905141912",
      "https://openalex.org/W2937305817",
      "https://openalex.org/W2938555542",
      "https://openalex.org/W2948048211",
      "https://openalex.org/W2951390634",
      "https://openalex.org/W2954199749",
      "https://openalex.org/W2956387449",
      "https://openalex.org/W2962934715",
      "https://openalex.org/W2962949233",
      "https://openalex.org/W2963383024",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963524571",
      "https://openalex.org/W2963529931",
      "https://openalex.org/W2963541336",
      "https://openalex.org/W2963576560",
      "https://openalex.org/W2963748441",
      "https://openalex.org/W2963823251",
      "https://openalex.org/W2963890755",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964213933",
      "https://openalex.org/W2964218959",
      "https://openalex.org/W2968553732",
      "https://openalex.org/W2972745026",
      "https://openalex.org/W2997344006",
      "https://openalex.org/W2997805943",
      "https://openalex.org/W2998166190",
      "https://openalex.org/W2998476971",
      "https://openalex.org/W3016211260",
      "https://openalex.org/W3034730770",
      "https://openalex.org/W3099388488",
      "https://openalex.org/W4306716473",
      "https://openalex.org/W4385245566",
      "https://openalex.org/W4394666973"
    ],
    "abstract": "Video-grounded dialogues are very challenging due to (i) the complexity of videos which contain both spatial and temporal variations, and (ii) the complexity of user utterances which query different segments and/or different objects in videos over multiple dialogue turns. However, existing approaches to video-grounded dialogues often focus on superficial temporal-level visual cues, but neglect more fine-grained spatial signals from videos. To address this drawback, we proposed Bi-directional Spatio-Temporal Learning (BiST), a vision-language neural framework for high-resolution queries in videos based on textual cues. Specifically, our approach not only exploits both spatial and temporal-level information, but also learns dynamic information diffusion between the two feature spaces through spatial-to-temporal and temporal-to-spatial reasoning. The bidirectional strategy aims to tackle the evolving semantics of user queries in the dialogue setting. The retrieved visual cues are used as contextual information to construct relevant responses to the users. Our empirical results and comprehensive qualitative analysis show that BiST achieves competitive performance and generates reasonable responses on a large-scale AVSD benchmark. We also adapt our BiST models to the Video QA setting, and substantially outperform prior approaches on the TGIF-QA benchmark.",
    "match_score": 0.9932885906040269
  },
  "Using Customer Service Dialogues for Satisfaction Analysis with Context-Assisted Multiple Instance Learning": {
    "openalex_id": "https://openalex.org/W2970168865",
    "publication_year": 2019,
    "cited_by_count": 23,
    "referenced_works": [
      "https://openalex.org/W184147902",
      "https://openalex.org/W1614298861",
      "https://openalex.org/W1980287119",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2083306472",
      "https://openalex.org/W2126581182",
      "https://openalex.org/W2133288557",
      "https://openalex.org/W2235475559",
      "https://openalex.org/W2464050240",
      "https://openalex.org/W2470673105",
      "https://openalex.org/W2568951855",
      "https://openalex.org/W2741609276",
      "https://openalex.org/W2757541972",
      "https://openalex.org/W2767329425",
      "https://openalex.org/W2769436106",
      "https://openalex.org/W2788618579",
      "https://openalex.org/W2798600398",
      "https://openalex.org/W2798966390",
      "https://openalex.org/W2808182015",
      "https://openalex.org/W2892217184",
      "https://openalex.org/W2899455119",
      "https://openalex.org/W2950883469",
      "https://openalex.org/W2963240575",
      "https://openalex.org/W2964164368",
      "https://openalex.org/W2964300796",
      "https://openalex.org/W2964871493",
      "https://openalex.org/W2965510113"
    ],
    "abstract": "Customers ask questions and customer service staffs answer their questions, which is the basic service model via multi-turn customer service (CS) dialogues on E-commerce platforms. Existing studies fail to provide comprehensive service satisfaction analysis, namely satisfaction polarity classification (e.g., well satisfied, met and unsatisfied) and sentimental utterance identification (e.g., positive, neutral and negative). In this paper, we conduct a pilot study on the task of service satisfaction analysis (SSA) based on multi-turn CS dialogues. We propose an extensible Context-Assisted Multiple Instance Learning (CAMIL) model to predict the sentiments of all the customer utterances and then aggregate those sentiments into service satisfaction polarity. After that, we propose a novel Context Clue Matching Mechanism (CCMM) to enhance the representations of all customer utterances with their matched context clues, i.e., sentiment and reasoning clues. We construct two CS dialogue datasets from a top E-commerce platform. Extensive experimental results are presented and contrasted against a few previous models to demonstrate the efficacy of our model.",
    "match_score": 1.0
  },
  "Subgoal Discovery for Hierarchical Dialogue Policy Learning": {
    "openalex_id": "https://openalex.org/W2963140401",
    "publication_year": 2018,
    "cited_by_count": 39,
    "referenced_works": [
      "https://openalex.org/W1492935830",
      "https://openalex.org/W1556824961",
      "https://openalex.org/W1586944634",
      "https://openalex.org/W2022677886",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2090170171",
      "https://openalex.org/W2109910161",
      "https://openalex.org/W2114451917",
      "https://openalex.org/W2132997613",
      "https://openalex.org/W2133458291",
      "https://openalex.org/W2135909747",
      "https://openalex.org/W2140016149",
      "https://openalex.org/W2143435603",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2153385324",
      "https://openalex.org/W2160808139",
      "https://openalex.org/W2288878529",
      "https://openalex.org/W2312609093",
      "https://openalex.org/W2412899141",
      "https://openalex.org/W2516334389",
      "https://openalex.org/W2550612212",
      "https://openalex.org/W2558661633",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2592215206",
      "https://openalex.org/W2592647456",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2765111838",
      "https://openalex.org/W2772001136",
      "https://openalex.org/W2783543950",
      "https://openalex.org/W2807142242",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2949267040",
      "https://openalex.org/W2950040888",
      "https://openalex.org/W2962776342",
      "https://openalex.org/W2963043030",
      "https://openalex.org/W2963077280",
      "https://openalex.org/W2963262099",
      "https://openalex.org/W2964080167",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964227312",
      "https://openalex.org/W3029062788",
      "https://openalex.org/W3104546989",
      "https://openalex.org/W4214717370"
    ],
    "abstract": "Developing agents to engage in complex goal-oriented dialogues is challenging partly because the main learning signals are very sparse in long conversations. In this paper, we propose a divide-and-conquer approach that discovers and exploits the hidden structure of the task to enable efficient policy learning. First, given successful example dialogues, we propose the Subgoal Discovery Network (SDN) to divide a complex goal-oriented task into a set of simpler subgoals in an unsupervised fashion. We then use these subgoals to learn a multi-level policy by hierarchical reinforcement learning. We demonstrate our method by building a dialogue agent for the composite task of travel planning. Experiments with simulated and real users show that our approach performs competitively against a state-of-the-art method that requires human-defined subgoals. Moreover, we show that the learned subgoals are often human comprehensible.",
    "match_score": 1.0
  },
  "Approximation of Response Knowledge Retrieval in Knowledge-grounded Dialogue Generation": {
    "openalex_id": "https://openalex.org/W3105049371",
    "publication_year": 2020,
    "cited_by_count": 7,
    "referenced_works": [
      "https://openalex.org/W2014415866",
      "https://openalex.org/W2085030399",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2104049510",
      "https://openalex.org/W2123301721",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2131876387",
      "https://openalex.org/W2136189984",
      "https://openalex.org/W2339852062",
      "https://openalex.org/W2539671052",
      "https://openalex.org/W2547875792",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2610935556",
      "https://openalex.org/W2741363662",
      "https://openalex.org/W2885421725",
      "https://openalex.org/W2891103209",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2936695845",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2962985038",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2964458951",
      "https://openalex.org/W2986867746",
      "https://openalex.org/W2995183464",
      "https://openalex.org/W3011801489",
      "https://openalex.org/W4299606006",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "This paper is concerned with improving dialogue generation models through injection of knowledge, e.g., content relevant to the post that can increase the quality of responses. Past research extends the training of the generative models by incorporating statistical properties of posts, responses and related knowledge, without explicitly assessing the knowledge quality. In our work, we demonstrate the importance of knowledge relevance and adopt a two-phase approach. We first apply a novel method, Transformer & Post based Posterior Approximation (TPPA) to select knowledge, and then use the Transformer with Expanded Decoder (TED) model to generate responses from both the post and the knowledge. TPPA method processes posts, post related knowledge, and response related knowledge at both word and sentence level. Our experiments with the TED generative model demonstrate the effectiveness of TPPA as it outperforms a set of strong baseline models. Our TPPA method is extendable and supports further optimization of knowledge retrieval and injection.",
    "match_score": 1.0
  },
  "Optimising Incremental Dialogue Decisions Using Information Density for Interactive Systems": {
    "openalex_id": "https://openalex.org/W2110633879",
    "publication_year": 2012,
    "cited_by_count": 37,
    "referenced_works": [
      "https://openalex.org/W47495561",
      "https://openalex.org/W102921666",
      "https://openalex.org/W178161411",
      "https://openalex.org/W200223693",
      "https://openalex.org/W1487640415",
      "https://openalex.org/W1515851193",
      "https://openalex.org/W1584761227",
      "https://openalex.org/W1598875788",
      "https://openalex.org/W1630833108",
      "https://openalex.org/W1681299129",
      "https://openalex.org/W1769776978",
      "https://openalex.org/W1944068894",
      "https://openalex.org/W1974821254",
      "https://openalex.org/W1986532700",
      "https://openalex.org/W2021151961",
      "https://openalex.org/W2023612782",
      "https://openalex.org/W2024785476",
      "https://openalex.org/W2026431544",
      "https://openalex.org/W2067097374",
      "https://openalex.org/W2079833689",
      "https://openalex.org/W2102573550",
      "https://openalex.org/W2115101920",
      "https://openalex.org/W2119631826",
      "https://openalex.org/W2121517924",
      "https://openalex.org/W2129955048",
      "https://openalex.org/W2132997613",
      "https://openalex.org/W2134466368",
      "https://openalex.org/W2140188190",
      "https://openalex.org/W2149029524",
      "https://openalex.org/W2153385324",
      "https://openalex.org/W2157134106",
      "https://openalex.org/W2157365695",
      "https://openalex.org/W2160219061",
      "https://openalex.org/W2169430966",
      "https://openalex.org/W2312609093",
      "https://openalex.org/W2914679068",
      "https://openalex.org/W3099293669"
    ],
    "abstract": "Incremental processing allows system designers to address several discourse phenomena that have previously been somewhat neglected in interactive systems, such as backchannels or barge-ins, but that can enhance the responsiveness and naturalness of systems. Unfortunately, prior work has focused largely on deterministic incremental decision making, rendering system behaviour less flexible and adaptive than is desirable. We present a novel approach to incremental decision making that is based on Hierarchical Reinforcement Learning to achieve an interactive optimisation of Information Presentation (IP) strategies, allowing the system to generate and comprehend backchannels and barge-ins, by employing the recent psycholinguistic hypothesis of information density (ID) (Jaeger, 2010). Results in terms of average rewards and a human rating study show that our learnt strategy outperforms several baselines that are not sensitive to ID by more than 23%. 1",
    "match_score": 1.0
  },
  "Slot Attention with Value Normalization for Multi-Domain Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W3099140977",
    "publication_year": 2020,
    "cited_by_count": 26,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2251355666",
      "https://openalex.org/W2741361549",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W3021096583",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W4288288848",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Incompleteness of domain ontology and unavailability of some values are two inevitable problems of dialogue state tracking (DST). Existing approaches generally fall into two extremes: choosing models without ontology or embedding ontology in models leading to over-dependence. In this paper, we propose a new architecture to cleverly exploit ontology, which consists of Slot Attention (SA) and Value Normalization (VN), referred to as SAVN. Moreover, we supplement the annotation of supporting span for MultiWOZ 2.1, which is the shortest span in utterances to support the labeled value. SA shares knowledge between slots and utterances and only needs a simple structure to predict the supporting span. VN is designed specifically for the use of ontology, which can convert supporting spans to the values. Empirical results demonstrate that SAVN achieves the state-of-the-art joint accuracy of 54.52% on MultiWOZ 2.0 and 54.86% on MultiWOZ 2.1. Besides, we evaluate VN with incomplete ontology. The results show that even if only 30% ontology is used, VN can also contribute to our model.",
    "match_score": 1.0
  },
  "Efficient Dialogue State Tracking by Selectively Overwriting Memory": {
    "openalex_id": "https://openalex.org/W3034573951",
    "publication_year": 2020,
    "cited_by_count": 187,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2779809129",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2895976713",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964199361",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2996317432",
      "https://openalex.org/W3005419354",
      "https://openalex.org/W3008966357",
      "https://openalex.org/W3121541553",
      "https://openalex.org/W4288094254",
      "https://openalex.org/W4289147179"
    ],
    "abstract": "Recent works in dialogue state tracking (DST) focus on an open vocabulary-based setting to resolve scalability and generalization issues of the predefined ontology-based approaches. However, they are inefficient in that they predict the dialogue state at every turn from scratch. Here, we consider dialogue state as an explicit fixed-sized memory and propose a selectively overwriting mechanism for more efficient DST. This mechanism consists of two steps: (1) predicting state operation on each of the memory slots, and (2) overwriting the memory with new values, of which only a few are generated according to the predicted state operations. Our method decomposes DST into two sub-tasks and guides the decoder to focus only on one of the tasks, thus reducing the burden of the decoder. This enhances the effectiveness of training and DST performance. Our SOM-DST (Selectively Overwriting Memory for Dialogue State Tracking) model achieves state-of-the-art joint goal accuracy with 51.72% in MultiWOZ 2.0 and 53.01% in MultiWOZ 2.1 in an open vocabulary-based DST setting. In addition, we analyze the accuracy gaps between the current and the ground truth-given situations and suggest that it is a promising direction to improve state operation prediction to boost the DST performance.",
    "match_score": 1.0
  },
  "Amalgamating Knowledge from Two Teachers for Task-oriented Dialogue System with Adversarial Training": {
    "openalex_id": "https://openalex.org/W3102445752",
    "publication_year": 2020,
    "cited_by_count": 21,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1793121960",
      "https://openalex.org/W1821462560",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2113207845",
      "https://openalex.org/W2148952635",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2294370754",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2559094423",
      "https://openalex.org/W2711861986",
      "https://openalex.org/W2729046720",
      "https://openalex.org/W2743289088",
      "https://openalex.org/W2788836009",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2950009015",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2962944953",
      "https://openalex.org/W2963084599",
      "https://openalex.org/W2963248455",
      "https://openalex.org/W2963412005",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963736842",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2970260827",
      "https://openalex.org/W2975451647",
      "https://openalex.org/W3106274079",
      "https://openalex.org/W4294170691",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4297728544"
    ],
    "abstract": "The challenge of both achieving task completion by querying the knowledge base and generating human-like responses for task-oriented dialogue systems is attracting increasing research attention. In this paper, we propose a \"Two-Teacher One-Student\" learning framework (TTOS) for task-oriented dialogue, with the goal of retrieving accurate KB entities and generating human-like responses simultaneously. TTOS amalgamates knowledge from two teacher networks that together provide comprehensive guidance to build a high-quality task-oriented dialogue system (student network). Each teacher network is trained via reinforcement learning with a goal-specific reward, which can be viewed as an expert towards the goal and transfers the professional characteristic to the student network. Instead of adopting the classic student-teacher learning of forcing the output of a student network to exactly mimic the soft targets produced by the teacher networks, we introduce two discriminators as in generative adversarial network (GAN) to transfer knowledge from two teachers to the student. The usage of discriminators relaxes the rigid coupling between the student and teachers. Extensive experiments on two benchmark datasets (i.e., CamRest and In-Car Assistant) demonstrate that TTOS significantly outperforms baseline methods.",
    "match_score": 1.0
  },
  "Automatically Learning Data Augmentation Policies for Dialogue Tasks": {
    "openalex_id": "https://openalex.org/W2970418174",
    "publication_year": 2019,
    "cited_by_count": 36,
    "referenced_works": [
      "https://openalex.org/W4919037",
      "https://openalex.org/W267862395",
      "https://openalex.org/W836999996",
      "https://openalex.org/W1982477054",
      "https://openalex.org/W2016522586",
      "https://openalex.org/W2099471712",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2141125852",
      "https://openalex.org/W2155027007",
      "https://openalex.org/W2156163116",
      "https://openalex.org/W2163605009",
      "https://openalex.org/W2170240176",
      "https://openalex.org/W2176263492",
      "https://openalex.org/W2251658415",
      "https://openalex.org/W2418993857",
      "https://openalex.org/W2604262106",
      "https://openalex.org/W2733239165",
      "https://openalex.org/W2740149041",
      "https://openalex.org/W2751049198",
      "https://openalex.org/W2751134959",
      "https://openalex.org/W2767019926",
      "https://openalex.org/W2770173563",
      "https://openalex.org/W2775795276",
      "https://openalex.org/W2786273134",
      "https://openalex.org/W2796084947",
      "https://openalex.org/W2804047946",
      "https://openalex.org/W2888519496",
      "https://openalex.org/W2890719433",
      "https://openalex.org/W2951751045",
      "https://openalex.org/W2962707484",
      "https://openalex.org/W2962721878",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963012544",
      "https://openalex.org/W2963216553",
      "https://openalex.org/W2963248296",
      "https://openalex.org/W2963352069",
      "https://openalex.org/W2963552443",
      "https://openalex.org/W2963655793",
      "https://openalex.org/W2963736842",
      "https://openalex.org/W2963774520",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963858765",
      "https://openalex.org/W2964081807",
      "https://openalex.org/W2964222296",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4295727797",
      "https://openalex.org/W4320013936"
    ],
    "abstract": "Tong Niu, Mohit Bansal. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "SAS Dialogue State Tracking via Slot Attention and Slot Information Sharing": {
    "openalex_id": "https://openalex.org/W3035470414",
    "publication_year": 2020,
    "cited_by_count": 46,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251355666",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2556468274",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2934890006",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2962847367",
      "https://openalex.org/W2962985038",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963243930",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963970400",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2972892266",
      "https://openalex.org/W4289147179"
    ],
    "abstract": "Dialogue state tracker is responsible for inferring user intentions through dialogue history. Previous methods have difficulties in handling dialogues with long interaction context, due to the excessive information. We propose a Dialogue State Tracker with Slot Attention and Slot Information Sharing (SAS) to reduce redundant information's interference and improve long dialogue context tracking. Specially, we first apply a Slot Attention to learn a set of slot-specific features from the original dialogue and then integrate them using a slot information sharing module. Our model yields a significantly improved performance compared to previous state-of the-art models on the MultiWOZ dataset.",
    "match_score": 0.9933774834437086
  },
  "A Dual-Attention Hierarchical Recurrent Neural Network for Dialogue Act Classification": {
    "openalex_id": "https://openalex.org/W2988157054",
    "publication_year": 2019,
    "cited_by_count": 57,
    "referenced_works": [
      "https://openalex.org/W150462035",
      "https://openalex.org/W192515608",
      "https://openalex.org/W783082550",
      "https://openalex.org/W1503312748",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1526096287",
      "https://openalex.org/W1542146969",
      "https://openalex.org/W1880262756",
      "https://openalex.org/W1991133427",
      "https://openalex.org/W2008689742",
      "https://openalex.org/W2038043464",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2148830595",
      "https://openalex.org/W2167212741",
      "https://openalex.org/W2171986392",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2252245646",
      "https://openalex.org/W2573626026",
      "https://openalex.org/W2624871570",
      "https://openalex.org/W2757599232",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2803437449",
      "https://openalex.org/W2884240866",
      "https://openalex.org/W2931751229",
      "https://openalex.org/W2962902328",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963550483",
      "https://openalex.org/W2963765493",
      "https://openalex.org/W2964036636",
      "https://openalex.org/W2964089584",
      "https://openalex.org/W2964106094",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964199361",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964331270",
      "https://openalex.org/W4212995409"
    ],
    "abstract": "Recognising dialogue acts (DA) is important for many natural language processing tasks such as dialogue generation and intention recognition. In this paper, we propose a dual-attention hierarchical recurrent neural network for DA classification. Our model is partially inspired by the observation that conversational utterances are normally associated with both a DA and a topic, where the former captures the social act and the latter describes the subject matter. However, such a dependency between DAs and topics has not been utilised by most existing systems for DA classification. With a novel dual task-specific attention mechanism, our model is able, for utterances, to capture information about both DAs and topics, as well as information about the interactions between them. Experimental results show that by modelling topic as an auxiliary task, our model can significantly improve DA classification, yielding better or comparable performance to the state-of-the-art method on three public datasets.",
    "match_score": 1.0
  },
  "Enhancing Dialogue Symptom Diagnosis with Global Attention and Symptom Graph": {
    "openalex_id": "https://openalex.org/W2971066408",
    "publication_year": 2019,
    "cited_by_count": 48,
    "referenced_works": [
      "https://openalex.org/W12821309",
      "https://openalex.org/W1533861849",
      "https://openalex.org/W1808652302",
      "https://openalex.org/W1940872118",
      "https://openalex.org/W1991133427",
      "https://openalex.org/W2045016337",
      "https://openalex.org/W2053769007",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2120757740",
      "https://openalex.org/W2133012565",
      "https://openalex.org/W2134036914",
      "https://openalex.org/W2147880316",
      "https://openalex.org/W2158899491",
      "https://openalex.org/W2160379455",
      "https://openalex.org/W2169099542",
      "https://openalex.org/W2798161840",
      "https://openalex.org/W2851886341",
      "https://openalex.org/W2884705011",
      "https://openalex.org/W2886305736",
      "https://openalex.org/W2925613093",
      "https://openalex.org/W2949952998",
      "https://openalex.org/W2952087486",
      "https://openalex.org/W2952230511",
      "https://openalex.org/W2962902328",
      "https://openalex.org/W2963672540"
    ],
    "abstract": "Xinzhu Lin, Xiahui He, Qin Chen, Huaixiao Tou, Zhongyu Wei, Ting Chen. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "CIMA A Large Open Access Dialogue Dataset for Tutoring": {
    "openalex_id": "https://openalex.org/W3038061735",
    "publication_year": 2020,
    "cited_by_count": 22,
    "referenced_works": [
      "https://openalex.org/W131229082",
      "https://openalex.org/W1521764462",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1540372287",
      "https://openalex.org/W1548953971",
      "https://openalex.org/W2009434747",
      "https://openalex.org/W2044249691",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2123159101",
      "https://openalex.org/W2125320996",
      "https://openalex.org/W2133553328",
      "https://openalex.org/W2163640453",
      "https://openalex.org/W2165079349",
      "https://openalex.org/W2193006414",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251591847",
      "https://openalex.org/W2294475924",
      "https://openalex.org/W2553193462",
      "https://openalex.org/W2620761940",
      "https://openalex.org/W2740716165",
      "https://openalex.org/W2759361123",
      "https://openalex.org/W2785847546",
      "https://openalex.org/W2886305736",
      "https://openalex.org/W2936695845",
      "https://openalex.org/W2941035428",
      "https://openalex.org/W2962849532",
      "https://openalex.org/W2963212250",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964046741",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964652672",
      "https://openalex.org/W2996403597",
      "https://openalex.org/W2999995091",
      "https://openalex.org/W3098682828",
      "https://openalex.org/W3103120164",
      "https://openalex.org/W3103692324",
      "https://openalex.org/W4235418491",
      "https://openalex.org/W4285719527",
      "https://openalex.org/W4295249402"
    ],
    "abstract": "One-to-one tutoring is often an effective means to help students learn, and recent experiments with neural conversation systems are promising. However, large open datasets of tutoring conversations are lacking. To remedy this, we propose a novel asynchronous method for collecting tutoring dialogue via crowdworkers that is both amenable to the needs of deep learning algorithms and reflective of pedagogical concerns. In this approach, extended conversations are obtained between crowdworkers role-playing as both students and tutors. The CIMA collection, which we make publicly available, is novel in that students are exposed to overlapping grounded concepts between exercises and multiple relevant tutoring responses are collected for the same input. CIMA contains several compelling properties from an educational perspective: student role-players complete exercises in fewer turns during the course of the conversation and tutor players adopt strategies that conform with some educational conversational norms, such as providing hints versus asking questions in appropriate contexts. The dataset enables a model to be trained to generate the next tutoring utterance in a conversation, conditioned on a provided action strategy.",
    "match_score": 0.9908256880733946
  },
  "LIDA Lightweight Interactive Dialogue Annotator": {
    "openalex_id": "https://openalex.org/W2970377674",
    "publication_year": 2019,
    "cited_by_count": 8,
    "referenced_works": [
      "https://openalex.org/W8550301",
      "https://openalex.org/W1607983314",
      "https://openalex.org/W2053154970",
      "https://openalex.org/W2108598243",
      "https://openalex.org/W2113207145",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2889470921",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2907283777",
      "https://openalex.org/W2964006684"
    ],
    "abstract": "Edward Collins, Nikolai Rozanov, Bingbing Zhang. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations. 2019.",
    "match_score": 0.9894736842105263
  },
  "Dialogue Act Classification with Context-Aware Self-Attention": {
    "openalex_id": "https://openalex.org/W2931751229",
    "publication_year": 2019,
    "cited_by_count": 60,
    "referenced_works": [
      "https://openalex.org/W27394811",
      "https://openalex.org/W1486649854",
      "https://openalex.org/W1576632330",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2131744502",
      "https://openalex.org/W2146785422",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2401527985",
      "https://openalex.org/W2470673105",
      "https://openalex.org/W2573626026",
      "https://openalex.org/W2576526989",
      "https://openalex.org/W2741675028",
      "https://openalex.org/W2757599232",
      "https://openalex.org/W2786396726",
      "https://openalex.org/W2901101385",
      "https://openalex.org/W2962739339",
      "https://openalex.org/W2962803631",
      "https://openalex.org/W2962902328",
      "https://openalex.org/W2963386218",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963550483",
      "https://openalex.org/W2963625095",
      "https://openalex.org/W2963765493",
      "https://openalex.org/W2964036636",
      "https://openalex.org/W2964106094",
      "https://openalex.org/W2964139507",
      "https://openalex.org/W2964189376",
      "https://openalex.org/W2964331270",
      "https://openalex.org/W2988157054"
    ],
    "abstract": "Recent work in Dialogue Act classification has treated the task as a sequence labeling problem using hierarchical deep neural networks. We build on this prior work by leveraging the effectiveness of a context-aware self-attention mechanism coupled with a hierarchical recurrent neural network. We conduct extensive evaluations on standard Dialogue Act classification datasets and show significant improvement over state-of-the-art results on the Switchboard Dialogue Act (SwDA) Corpus. We also investigate the impact of different utterance-level representation learning methods and show that our method is effective at capturing utterance-level semantic text representations while maintaining high accuracy.",
    "match_score": 1.0
  },
  "Linguistically-Informed Specificity and Semantic Plausibility for Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2945554776",
    "publication_year": 2019,
    "cited_by_count": 21,
    "referenced_works": [
      "https://openalex.org/W635530177",
      "https://openalex.org/W759515131",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1976434636",
      "https://openalex.org/W1999374445",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2111305191",
      "https://openalex.org/W2123301721",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2149741699",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2250571530",
      "https://openalex.org/W2261586594",
      "https://openalex.org/W2411447339",
      "https://openalex.org/W2463562195",
      "https://openalex.org/W2474824677",
      "https://openalex.org/W2525450212",
      "https://openalex.org/W2557436004",
      "https://openalex.org/W2573519875",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2604444020",
      "https://openalex.org/W2734443755",
      "https://openalex.org/W2784400615",
      "https://openalex.org/W2787711783",
      "https://openalex.org/W2798888952",
      "https://openalex.org/W2805005636",
      "https://openalex.org/W2806120502",
      "https://openalex.org/W2807791032",
      "https://openalex.org/W2890274659",
      "https://openalex.org/W2890276793",
      "https://openalex.org/W2962883166",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963161084",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963283805",
      "https://openalex.org/W2963353834",
      "https://openalex.org/W2963371447",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963918774",
      "https://openalex.org/W2964042872",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964134121",
      "https://openalex.org/W2964137876",
      "https://openalex.org/W2964178377",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2972052008"
    ],
    "abstract": "Wei-Jen Ko, Greg Durrett, Junyi Jessy Li. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019.",
    "match_score": 1.0
  },
  "Real-Time Speech Emotion and Sentiment Recognition for Interactive Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2565875961",
    "publication_year": 2016,
    "cited_by_count": 126,
    "referenced_works": [
      "https://openalex.org/W44815768",
      "https://openalex.org/W147964346",
      "https://openalex.org/W1492025072",
      "https://openalex.org/W1501669607",
      "https://openalex.org/W1524333225",
      "https://openalex.org/W1832693441",
      "https://openalex.org/W1932847118",
      "https://openalex.org/W2085662862",
      "https://openalex.org/W2120615054",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2153635508",
      "https://openalex.org/W2158899491",
      "https://openalex.org/W2251321385",
      "https://openalex.org/W2402040266",
      "https://openalex.org/W2423024114",
      "https://openalex.org/W2489406233",
      "https://openalex.org/W2607154244",
      "https://openalex.org/W2611669587",
      "https://openalex.org/W2951714314",
      "https://openalex.org/W2952230511",
      "https://openalex.org/W2963921497",
      "https://openalex.org/W3120421331",
      "https://openalex.org/W4294170691",
      "https://openalex.org/W4301100068"
    ],
    "abstract": "In this paper, we describe our approach of enabling an interactive dialogue system to recognize user emotion and sentiment in realtime. These modules allow otherwise conventional dialogue systems to have \u201cempathy\u201d and answer to the user while being aware of their emotion and intent. Emotion recognition from speech previously consists of feature engineering and machine learning where the first stage causes delay in decoding time. We describe a CNN model to extract emotion from raw speech input without feature engineering. This approach even achieves an impressive average of 65.7% accuracy on six emotion categories, a 4.5% improvement when compared to the conventional feature based SVM classification. A separate, CNN-based sentiment analysis module recognizes sentiments from speech recognition results, with 82.5 Fmeasure on human-machine dialogues when trained with out-of-domain data.",
    "match_score": 1.0
  },
  "MIE A Medical Information Extractor towards Medical Dialogues": {
    "openalex_id": "https://openalex.org/W3034408002",
    "publication_year": 2020,
    "cited_by_count": 48,
    "referenced_works": [
      "https://openalex.org/W1940872118",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2133012565",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2158899491",
      "https://openalex.org/W2168041406",
      "https://openalex.org/W2515682654",
      "https://openalex.org/W2538374209",
      "https://openalex.org/W2551396370",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2798858969",
      "https://openalex.org/W2806237610",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2962902328",
      "https://openalex.org/W2963108794",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2971066408"
    ],
    "abstract": "Electronic Medical Records (EMRs) have become key components of modern medical care systems. Despite the merits of EMRs, many doctors suffer from writing them, which is time-consuming and tedious. We believe that automatically converting medical dialogues to EMRs can greatly reduce the burdens of doctors, and extracting information from medical dialogues is an essential step. To this end, we annotate online medical consultation dialogues in a window-sliding style, which is much easier than the sequential labeling annotation. We then propose a Medical Information Extractor (MIE) towards medical dialogues. MIE is able to extract mentioned symptoms, surgeries, tests, other information and their corresponding status. To tackle the particular challenges of the task, MIE uses a deep matching architecture, taking dialogue turn-interaction into account. The experimental results demonstrate MIE is a promising solution to extract medical information from doctor-patient dialogues.",
    "match_score": 0.991869918699187
  },
  "Learning to Adapt to Unknown Users Referring Expression Generation in Spoken Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2157134106",
    "publication_year": 2010,
    "cited_by_count": 43,
    "referenced_works": [
      "https://openalex.org/W160067033",
      "https://openalex.org/W163988823",
      "https://openalex.org/W192597414",
      "https://openalex.org/W605575788",
      "https://openalex.org/W1494346129",
      "https://openalex.org/W1515851193",
      "https://openalex.org/W1536009700",
      "https://openalex.org/W1584761227",
      "https://openalex.org/W1601121220",
      "https://openalex.org/W1695997110",
      "https://openalex.org/W1974821254",
      "https://openalex.org/W1980340273",
      "https://openalex.org/W1986957457",
      "https://openalex.org/W1997319212",
      "https://openalex.org/W2000189111",
      "https://openalex.org/W2025989261",
      "https://openalex.org/W2030721126",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2107726111",
      "https://openalex.org/W2108654132",
      "https://openalex.org/W2117989772",
      "https://openalex.org/W2124003719",
      "https://openalex.org/W2149029524",
      "https://openalex.org/W2154124305",
      "https://openalex.org/W2166490941",
      "https://openalex.org/W2168490009",
      "https://openalex.org/W2911283634",
      "https://openalex.org/W2914656440"
    ],
    "abstract": "We present a data-driven approach to learn user-adaptive referring expression generation (REG) policies for spoken dialogue systems. Referring expressions can be difficult to understand in technical domains where users may not know the technical \u2018jargon \u2019 names of the domain entities. In such cases, dialogue systems must be able to model the user\u2019s (lexical) domain knowledge and use appropriate referring expressions. We present a reinforcement learning (RL) framework in which the system learns REG policies which can adapt to unknown users online. Furthermore, unlike supervised learning methods which require a large corpus of expert adaptive behaviour to train on, we show that effective adaptive policies can be learned from a small dialogue corpus of non-adaptive human-machine interaction, by using a RL framework and a statistical user simulation. We show that in comparison to adaptive hand-coded baseline policies, the learned policy performs significantly better, with an 18.6 % average increase in adaptation accuracy. The best learned policy also takes less dialogue time (average 1.07 min less) than the best hand-coded policy. This is because the learned policies can adapt online to changing evidence about the user\u2019s domain expertise. 1",
    "match_score": 0.9946524064171123
  },
  "Fusing Eye Gaze with Speech Recognition Hypotheses to Resolve Exophoric References in Situated Dialogue": {
    "openalex_id": "https://openalex.org/W1796449931",
    "publication_year": 2010,
    "cited_by_count": 28,
    "referenced_works": [
      "https://openalex.org/W1502293651",
      "https://openalex.org/W1529752812",
      "https://openalex.org/W1631260214",
      "https://openalex.org/W1970961429",
      "https://openalex.org/W1985270055",
      "https://openalex.org/W2007261869",
      "https://openalex.org/W2020755048",
      "https://openalex.org/W2031871242",
      "https://openalex.org/W2037442428",
      "https://openalex.org/W2042585112",
      "https://openalex.org/W2044268022",
      "https://openalex.org/W2056513832",
      "https://openalex.org/W2086458350",
      "https://openalex.org/W2105024318",
      "https://openalex.org/W2113123608",
      "https://openalex.org/W2113272343",
      "https://openalex.org/W2119609990",
      "https://openalex.org/W2126956557",
      "https://openalex.org/W2137066512",
      "https://openalex.org/W2138476326",
      "https://openalex.org/W2152907450",
      "https://openalex.org/W2168041474",
      "https://openalex.org/W2594610113"
    ],
    "abstract": "In situated dialogue humans often utter linguistic expressions that refer to extralinguistic entities in the environment. Correctly resolving these references is critical yet challenging for artificial agents partly due to their limited speech recognition and language understanding capabilities. Motivated by psycholinguistic studies demonstrating a tight link between language production and human eye gaze, we have developed approaches that integrate naturally occurring human eye gaze with speech recognition hypotheses to resolve exophoric references in situated dialogue in a virtual world. In addition to incorporating eye gaze with the best recognized spoken hypothesis, we developed an algorithm to also handle multiple hypotheses modeled as word confusion networks. Our empirical results demonstrate that incorporating eye gaze with recognition hypotheses consistently outperforms the results obtained from processing recognition hypotheses alone. Incorporating eye gaze with word confusion networks further improves performance. 1",
    "match_score": 1.0
  },
  "Discovering Latent Structure in Task-Oriented Dialogues": {
    "openalex_id": "https://openalex.org/W2251949648",
    "publication_year": 2014,
    "cited_by_count": 56,
    "referenced_works": [
      "https://openalex.org/W190230800",
      "https://openalex.org/W194972339",
      "https://openalex.org/W962073815",
      "https://openalex.org/W1483307070",
      "https://openalex.org/W1568327918",
      "https://openalex.org/W1654173042",
      "https://openalex.org/W1681299129",
      "https://openalex.org/W1831406492",
      "https://openalex.org/W1880262756",
      "https://openalex.org/W1974654183",
      "https://openalex.org/W1980340273",
      "https://openalex.org/W1985125789",
      "https://openalex.org/W1985514943",
      "https://openalex.org/W2001082470",
      "https://openalex.org/W2033593667",
      "https://openalex.org/W2042096436",
      "https://openalex.org/W2048064382",
      "https://openalex.org/W2080972498",
      "https://openalex.org/W2085623775",
      "https://openalex.org/W2099873701",
      "https://openalex.org/W2101308260",
      "https://openalex.org/W2103339462",
      "https://openalex.org/W2106918957",
      "https://openalex.org/W2115979064",
      "https://openalex.org/W2118370253",
      "https://openalex.org/W2124585778",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2132997613",
      "https://openalex.org/W2137636595",
      "https://openalex.org/W2137877387",
      "https://openalex.org/W2138742901",
      "https://openalex.org/W2144100511",
      "https://openalex.org/W2165599843",
      "https://openalex.org/W2169218343",
      "https://openalex.org/W2170323078",
      "https://openalex.org/W2171802301",
      "https://openalex.org/W2172125983",
      "https://openalex.org/W2172135926",
      "https://openalex.org/W2340541798",
      "https://openalex.org/W3037265734"
    ],
    "abstract": "A key challenge for computational conversation models is to discover latent structure in task-oriented dialogue, since it provides a basis for analysing, evaluating, and building conversational systems. We propose three new unsupervised models to discover latent structures in task-oriented dialogues. Our methods synthesize hidden Markov models (for underlying state) and topic models (to connect words to states). We apply them to two real, non-trivial datasets: human-computer spoken dialogues in bus query service, and humanhuman text-based chats from a live technical support service. We show that our models extract meaningful state representations and dialogue structures consistent with human annotations. Quantitatively, we show our models achieve superior performance on held-out log likelihood evaluation and an ordering task.",
    "match_score": 1.0
  },
  "An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue": {
    "openalex_id": "https://openalex.org/W2110450943",
    "publication_year": 2011,
    "cited_by_count": 53,
    "referenced_works": [
      "https://openalex.org/W24147957",
      "https://openalex.org/W131993176",
      "https://openalex.org/W138117123",
      "https://openalex.org/W169684159",
      "https://openalex.org/W180179361",
      "https://openalex.org/W180870983",
      "https://openalex.org/W1524941034",
      "https://openalex.org/W1530785623",
      "https://openalex.org/W1544484417",
      "https://openalex.org/W1568422853",
      "https://openalex.org/W1588539311",
      "https://openalex.org/W1595126664",
      "https://openalex.org/W1736979814",
      "https://openalex.org/W1966621938",
      "https://openalex.org/W1983906381",
      "https://openalex.org/W2009936685",
      "https://openalex.org/W2090920598",
      "https://openalex.org/W2097480711",
      "https://openalex.org/W2098326211",
      "https://openalex.org/W2102518401",
      "https://openalex.org/W2102953093",
      "https://openalex.org/W2106180965",
      "https://openalex.org/W2117645142",
      "https://openalex.org/W2118163921",
      "https://openalex.org/W2122147877",
      "https://openalex.org/W2127462305",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2133990480",
      "https://openalex.org/W2134031328",
      "https://openalex.org/W2135995390",
      "https://openalex.org/W2144910574",
      "https://openalex.org/W2145511413",
      "https://openalex.org/W2146111747",
      "https://openalex.org/W2152627593",
      "https://openalex.org/W2155120841",
      "https://openalex.org/W2156503193",
      "https://openalex.org/W2161926933",
      "https://openalex.org/W2164385461",
      "https://openalex.org/W2166835339",
      "https://openalex.org/W2168816626",
      "https://openalex.org/W2187872264",
      "https://openalex.org/W2743036880",
      "https://openalex.org/W2955331414"
    ],
    "abstract": "Dialogue act classification is a central challenge for dialogue systems. Although the importance of emotion in human dialogue is widely recognized, most dialogue act classification models make limited or no use of affective channels in dialogue act classification. This paper presents a novel affect-enriched dialogue act classifier for task-oriented dialogue that models facial expressions of users, in particular, facial expressions related to confusion. The findings indicate that the affect-enriched classifiers perform significantly better for distinguishing user requests for feedback and grounding dialogue acts within textual dialogue. The results point to ways in which dialogue systems can effectively leverage affective channels to improve dialogue act classification.",
    "match_score": 1.0
  },
  "Rethinking Supervised Learning and Reinforcement Learning in Task-Oriented Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3105781833",
    "publication_year": 2020,
    "cited_by_count": 18,
    "referenced_works": [
      "https://openalex.org/W10548402",
      "https://openalex.org/W1525961042",
      "https://openalex.org/W1598178035",
      "https://openalex.org/W2047335008",
      "https://openalex.org/W2151814822",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2161466446",
      "https://openalex.org/W2288878529",
      "https://openalex.org/W2396229782",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2547875792",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2736601468",
      "https://openalex.org/W2765111838",
      "https://openalex.org/W2798494119",
      "https://openalex.org/W2806936550",
      "https://openalex.org/W2889186204",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2950483141",
      "https://openalex.org/W2962996309",
      "https://openalex.org/W2963064439",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963095800",
      "https://openalex.org/W2963277051",
      "https://openalex.org/W2963692154",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964044380",
      "https://openalex.org/W2970828515",
      "https://openalex.org/W3015731157",
      "https://openalex.org/W3104546989",
      "https://openalex.org/W3121541553",
      "https://openalex.org/W4236521339",
      "https://openalex.org/W4312609624",
      "https://openalex.org/W4394670483"
    ],
    "abstract": "Dialogue policy learning for task-oriented dialogue systems has enjoyed great progress recently mostly through employing reinforcement learning methods. However, these approaches have become very sophisticated. It is time to re-evaluate it. Are we really making progress developing dialogue agents only based on reinforcement learning? We demonstrate how (1) traditional supervised learning together with (2) a simulator-free adversarial learning method can be used to achieve performance comparable to state-of-the-art reinforcement learning-based methods. First, we introduce a simple dialogue action decoder to predict the appropriate actions. Then, the traditional multi-label classification solution for dialogue policy learning is extended by adding dense layers to improve the dialogue agent performance. Finally, we employ the Gumbel-Softmax estimator to alternatively train the dialogue agent and the dialogue reward model without using reinforcement learning. Based on our extensive experimentation, we can conclude the proposed methods can achieve more stable and higher performance with fewer efforts, such as the domain knowledge required to design a user simulator and the intractable parameter tuning in reinforcement learning. Our main goal is not to beat RL with supervised learning, but to demonstrate the value of rethinking the role of reinforcement learning and supervised learning in optimizing task-oriented dialogue systems.",
    "match_score": 1.0
  },
  "Adversarial Learning for Neural Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2581637843",
    "publication_year": 2017,
    "cited_by_count": 765,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1604792744",
      "https://openalex.org/W1847211030",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1958706068",
      "https://openalex.org/W2046765929",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2099471712",
      "https://openalex.org/W2115613106",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2145482038",
      "https://openalex.org/W2173520492",
      "https://openalex.org/W2176263492",
      "https://openalex.org/W2210838531",
      "https://openalex.org/W2257979135",
      "https://openalex.org/W2335122196",
      "https://openalex.org/W2395531022",
      "https://openalex.org/W2413332972",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2418993857",
      "https://openalex.org/W2542835211",
      "https://openalex.org/W2550893117",
      "https://openalex.org/W2557436004",
      "https://openalex.org/W2562579542",
      "https://openalex.org/W2565274151",
      "https://openalex.org/W2570431255",
      "https://openalex.org/W2583679610",
      "https://openalex.org/W2583741591",
      "https://openalex.org/W2951523806",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963226019",
      "https://openalex.org/W2963248296",
      "https://openalex.org/W2963373786",
      "https://openalex.org/W2963463964",
      "https://openalex.org/W2963527228",
      "https://openalex.org/W2963620441",
      "https://openalex.org/W2963684088",
      "https://openalex.org/W2963729324",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964039645",
      "https://openalex.org/W2964268978",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2964352247",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4234099752",
      "https://openalex.org/W4294149591",
      "https://openalex.org/W4297809080",
      "https://openalex.org/W4302353911",
      "https://openalex.org/W4307979480",
      "https://openalex.org/W4320013936"
    ],
    "abstract": "We apply adversarial training to open-domain dialogue generation, training a system to produce sequences that are indistinguishable from human-generated dialogue utterances. We cast the task as a reinforcement learning problem where we jointly train two systems: a generative model to produce response sequences, and a discriminator\u2014analagous to the human evaluator in the Turing test\u2014 to distinguish between the human-generated dialogues and the machine-generated ones. In this generative adversarial network approach, the outputs from the discriminator are used to encourage the system towards more human-like dialogue. Further, we investigate models for adversarial evaluation that uses success in fooling an adversary as a dialogue evaluation metric, while avoiding a number of potential pitfalls. Experimental results on several metrics, including adversarial evaluation, demonstrate that the adversarially-trained system generates higher-quality responses than previous baselines",
    "match_score": 1.0
  },
  "Dialogue State Tracking with Explicit Slot Connection Modeling": {
    "openalex_id": "https://openalex.org/W3035594326",
    "publication_year": 2020,
    "cited_by_count": 45,
    "referenced_works": [
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2556468274",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964199361",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2979400990"
    ],
    "abstract": "Recent proposed approaches have made promising progress in dialogue state tracking (DST). However, in multi-domain scenarios, ellipsis and reference are frequently adopted by users to express values that have been mentioned by slots from other domains. To handle these phenomena, we propose a Dialogue State Tracking with Slot Connections (DST-SC) model to explicitly consider slot correlations across different domains. Given a target slot, the slot connecting mechanism in DST-SC can infer its source slot and copy the source slot value directly, thus significantly reducing the difficulty of learning and reasoning. Experimental results verify the benefits of explicit slot connection modeling, and our model achieves state-of-the-art performance on MultiWOZ 2.0 and MultiWOZ 2.1 datasets.",
    "match_score": 1.0
  },
  "Conversational Memory Network for Emotion Recognition in Dyadic Dialogue Videos": {
    "openalex_id": "https://openalex.org/W2805662932",
    "publication_year": 2018,
    "cited_by_count": 441,
    "referenced_works": [
      "https://openalex.org/W2402700",
      "https://openalex.org/W67701990",
      "https://openalex.org/W1504610641",
      "https://openalex.org/W1522734439",
      "https://openalex.org/W1555767263",
      "https://openalex.org/W1601218598",
      "https://openalex.org/W1793121960",
      "https://openalex.org/W1832693441",
      "https://openalex.org/W1923034539",
      "https://openalex.org/W1973453096",
      "https://openalex.org/W1985867508",
      "https://openalex.org/W1994518960",
      "https://openalex.org/W2012372415",
      "https://openalex.org/W2033702744",
      "https://openalex.org/W2047024757",
      "https://openalex.org/W2053101950",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2085662862",
      "https://openalex.org/W2097998348",
      "https://openalex.org/W2114399139",
      "https://openalex.org/W2120615054",
      "https://openalex.org/W2131494463",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2140211181",
      "https://openalex.org/W2143350951",
      "https://openalex.org/W2146334809",
      "https://openalex.org/W2149465541",
      "https://openalex.org/W2149940198",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2158335606",
      "https://openalex.org/W2163685610",
      "https://openalex.org/W2376179408",
      "https://openalex.org/W2405274704",
      "https://openalex.org/W2406223855",
      "https://openalex.org/W2518826259",
      "https://openalex.org/W2533262878",
      "https://openalex.org/W2544767710",
      "https://openalex.org/W2565875961",
      "https://openalex.org/W2578994755",
      "https://openalex.org/W2584561145",
      "https://openalex.org/W2610961739",
      "https://openalex.org/W2740550900",
      "https://openalex.org/W2742947407",
      "https://openalex.org/W2754573465",
      "https://openalex.org/W2766718178",
      "https://openalex.org/W2767461737",
      "https://openalex.org/W2772633765",
      "https://openalex.org/W2786411768",
      "https://openalex.org/W2788967885",
      "https://openalex.org/W2950527759",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2962709202",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2963520511",
      "https://openalex.org/W2964010806",
      "https://openalex.org/W2964091467",
      "https://openalex.org/W2964260444",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W3144863038",
      "https://openalex.org/W4300985914",
      "https://openalex.org/W4303633609"
    ],
    "abstract": "Emotion recognition in conversations is crucial for the development of empathetic machines. Present methods mostly ignore the role of inter-speaker dependency relations while classifying emotions in conversations. In this paper, we address recognizing utterance-level emotions in dyadic conversational videos. We propose a deep neural framework, termed conversational memory network, which leverages contextual information from the conversation history. The framework takes a multimodal approach comprising audio, visual and textual features with gated recurrent units to model past utterances of each speaker into memories. Such memories are then merged using attention-based hops to capture inter-speaker dependencies. Experiments show an accuracy improvement of 3-4% over the state of the art.",
    "match_score": 1.0
  },
  "Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2169349402",
    "publication_year": 2013,
    "cited_by_count": 2,
    "referenced_works": [
      "https://openalex.org/W1545498002",
      "https://openalex.org/W1552062513",
      "https://openalex.org/W1596967103",
      "https://openalex.org/W1704101508",
      "https://openalex.org/W1858542621",
      "https://openalex.org/W2146393546",
      "https://openalex.org/W2153190884",
      "https://openalex.org/W2167277498",
      "https://openalex.org/W2187436616",
      "https://openalex.org/W2251052362",
      "https://openalex.org/W2963375312"
    ],
    "abstract": "This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode.",
    "match_score": 1.0
  },
  "DialSQL Dialogue Based Structured Query Generation": {
    "openalex_id": "https://openalex.org/W2798753108",
    "publication_year": 2018,
    "cited_by_count": 76,
    "referenced_works": [
      "https://openalex.org/W1496189301",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1993378086",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2107618763",
      "https://openalex.org/W2111742432",
      "https://openalex.org/W2123442489",
      "https://openalex.org/W2145618437",
      "https://openalex.org/W2154268919",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2163274265",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251079237",
      "https://openalex.org/W2252136820",
      "https://openalex.org/W2269738476",
      "https://openalex.org/W2296712013",
      "https://openalex.org/W2342096063",
      "https://openalex.org/W2402144811",
      "https://openalex.org/W2559038528",
      "https://openalex.org/W2561148973",
      "https://openalex.org/W2566402689",
      "https://openalex.org/W2751448157",
      "https://openalex.org/W2759477115",
      "https://openalex.org/W2762513422",
      "https://openalex.org/W2768409085",
      "https://openalex.org/W2782031709",
      "https://openalex.org/W2786472750",
      "https://openalex.org/W2950314731",
      "https://openalex.org/W2953384591",
      "https://openalex.org/W2962682659",
      "https://openalex.org/W2962885446",
      "https://openalex.org/W2963794306",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964271186",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3159064672",
      "https://openalex.org/W4246375690"
    ],
    "abstract": "The recent advance in deep learning and semantic parsing has significantly improved the translation accuracy of natural language questions to structured queries. However, further improvement of the existing approaches turns out to be quite challenging. Rather than solely relying on algorithmic innovations, in this work, we introduce DialSQL, a dialogue-based structured query generation framework that leverages human intelligence to boost the performance of existing algorithms via user interaction. DialSQL is capable of identifying potential errors in a generated SQL query and asking users for validation via simple multi-choice questions. User feedback is then leveraged to revise the query. We design a generic simulator to bootstrap synthetic training dialogues and evaluate the performance of DialSQL on the WikiSQL dataset. Using SQLNet as a black box query generation tool, DialSQL improves its performance from 61.3% to 69.0% using only 2.4 validation questions per dialogue.",
    "match_score": 0.9900990099009901
  },
  "Zero-shot Cross-lingual Dialogue Systems with Transferable Latent Variables": {
    "openalex_id": "https://openalex.org/W2971160427",
    "publication_year": 2019,
    "cited_by_count": 76,
    "referenced_works": [
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2342045095",
      "https://openalex.org/W2493916176",
      "https://openalex.org/W2561995736",
      "https://openalex.org/W2741602058",
      "https://openalex.org/W2791169651",
      "https://openalex.org/W2885323099",
      "https://openalex.org/W2891424355",
      "https://openalex.org/W2891896107",
      "https://openalex.org/W2898856000",
      "https://openalex.org/W2954447110",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962738716",
      "https://openalex.org/W2962934384",
      "https://openalex.org/W2963118869",
      "https://openalex.org/W2963134326",
      "https://openalex.org/W2963411289",
      "https://openalex.org/W2963756346",
      "https://openalex.org/W2963993537",
      "https://openalex.org/W2970126578",
      "https://openalex.org/W2970876710",
      "https://openalex.org/W3106003309",
      "https://openalex.org/W4289744173",
      "https://openalex.org/W4299579390",
      "https://openalex.org/W4302343710"
    ],
    "abstract": "Despite the surging demands for multilingual task-oriented dialog systems (e.g., Alexa, Google Home), there has been less research done in multilingual or cross-lingual scenarios. Hence, we propose a zero-shot adaptation of task-oriented dialogue system to low-resource languages. To tackle this challenge, we first use a set of very few parallel word pairs to refine the aligned cross-lingual word-level representations. We then employ a latent variable model to cope with the variance of similar sentences across different languages, which is induced by imperfect cross-lingual alignments and inherent differences in languages. Finally, the experimental results show that even though we utilize much less external resources, our model achieves better adaptation performance for natural language understanding task (i.e., the intent detection and slot filling) compared to the current state-of-the-art model in the zero-shot scenario.",
    "match_score": 1.0
  },
  "Generate, Delete and Rewrite A Three-Stage Framework for Improving Persona Consistency of Dialogue Generation": {
    "openalex_id": "https://openalex.org/W3034720580",
    "publication_year": 2020,
    "cited_by_count": 85,
    "referenced_works": [
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1840435438",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W2025768430",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2220374841",
      "https://openalex.org/W2415204069",
      "https://openalex.org/W2578354947",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2608787653",
      "https://openalex.org/W2625977873",
      "https://openalex.org/W2756386045",
      "https://openalex.org/W2885421725",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2911994530",
      "https://openalex.org/W2947375732",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2952855649",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962863107",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962989446",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963212250",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963371754",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963521540",
      "https://openalex.org/W2963544700",
      "https://openalex.org/W2963640662",
      "https://openalex.org/W2963719234",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2965718149",
      "https://openalex.org/W2970579055",
      "https://openalex.org/W2979478117",
      "https://openalex.org/W2983160116",
      "https://openalex.org/W2997662139",
      "https://openalex.org/W2997892440",
      "https://openalex.org/W3035044096",
      "https://openalex.org/W3099023595",
      "https://openalex.org/W3168988646",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Maintaining a consistent personality in conversations is quite natural for human beings, but is still a non-trivial task for machines. The persona-based dialogue generation task is thus introduced to tackle the personality-inconsistent problem by incorporating explicit persona text into dialogue generation models. Despite the success of existing persona-based models on generating human-like responses, their one-stage decoding framework can hardly avoid the generation of inconsistent persona words. In this work, we introduce a three-stage framework that employs a generate-delete-rewrite mechanism to delete inconsistent words from a generated response prototype and further rewrite it to a personality-consistent one. We carry out evaluations by both human and automatic metrics. Experiments on the Persona-Chat dataset show that our approach achieves good performance.",
    "match_score": 0.9954337899543378
  },
  "GECOR An End-to-End Generative Ellipsis and Co-reference Resolution Model for Task-Oriented Dialogue": {
    "openalex_id": "https://openalex.org/W2970110247",
    "publication_year": 2019,
    "cited_by_count": 49,
    "referenced_works": [
      "https://openalex.org/W140747314",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1672330139",
      "https://openalex.org/W1988912276",
      "https://openalex.org/W2051948206",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2117448986",
      "https://openalex.org/W2130607791",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2250738489",
      "https://openalex.org/W2250947630",
      "https://openalex.org/W2512180100",
      "https://openalex.org/W2579689822",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2889448364",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2963087868",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963167649",
      "https://openalex.org/W2963412005",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964222246",
      "https://openalex.org/W2964308564"
    ],
    "abstract": "Jun Quan, Deyi Xiong, Bonnie Webber, Changjian Hu. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 0.9950248756218906
  },
  "Robust Coreference Resolution and Entity Linking on Dialogues Character Identification on TV Show Transcripts": {
    "openalex_id": "https://openalex.org/W2739484150",
    "publication_year": 2017,
    "cited_by_count": 29,
    "referenced_works": [
      "https://openalex.org/W1965693266",
      "https://openalex.org/W2064770078",
      "https://openalex.org/W2098345921",
      "https://openalex.org/W2099115159",
      "https://openalex.org/W2108806737",
      "https://openalex.org/W2111032703",
      "https://openalex.org/W2131357087",
      "https://openalex.org/W2139694477",
      "https://openalex.org/W2151048449",
      "https://openalex.org/W2155069789",
      "https://openalex.org/W2250738489",
      "https://openalex.org/W2251035762",
      "https://openalex.org/W2251064706",
      "https://openalex.org/W2251591847",
      "https://openalex.org/W2336260055",
      "https://openalex.org/W2464790259",
      "https://openalex.org/W2493916176",
      "https://openalex.org/W2566645459",
      "https://openalex.org/W2602447579",
      "https://openalex.org/W2759621817",
      "https://openalex.org/W2963167649",
      "https://openalex.org/W2963184844",
      "https://openalex.org/W2963695529"
    ],
    "abstract": "This paper presents a novel approach to character identification, that is an entity linking task that maps mentions to characters in dialogues from TV show transcripts. We first augment and correct several cases of annotation errors in an existing corpus so the corpus is clearer and cleaner for statistical learning. We also introduce the agglomerative convolutional neural network that takes groups of features and learns mention and mention-pair embeddings for coreference resolution. We then propose another neural model that employs the embeddings learned and creates cluster embeddings for entity linking. Our coreference resolution model shows comparable results to other state-of-the-art systems. Our entity linking model significantly outperforms the previous work, showing the F1 score of 86.76% and the accuracy of 95.30% for character identification.",
    "match_score": 0.9954337899543378
  },
  "Learning Knowledge Bases with Parameters for Task-Oriented Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3089529423",
    "publication_year": 2020,
    "cited_by_count": 7,
    "referenced_works": [
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1979299372",
      "https://openalex.org/W2012056301",
      "https://openalex.org/W2052569240",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2104544334",
      "https://openalex.org/W2132339004",
      "https://openalex.org/W2132997613",
      "https://openalex.org/W2340944142",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2550893117",
      "https://openalex.org/W2604763608",
      "https://openalex.org/W2620558438",
      "https://openalex.org/W2772001136",
      "https://openalex.org/W2798494119",
      "https://openalex.org/W2798779216",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2804047045",
      "https://openalex.org/W2806600904",
      "https://openalex.org/W2808093377",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2898856000",
      "https://openalex.org/W2910795780",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2940744433",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2946411231",
      "https://openalex.org/W2947480709",
      "https://openalex.org/W2948110372",
      "https://openalex.org/W2950457956",
      "https://openalex.org/W2951088751",
      "https://openalex.org/W2951091467",
      "https://openalex.org/W2952562169",
      "https://openalex.org/W2962682659",
      "https://openalex.org/W2962738716",
      "https://openalex.org/W2962881743",
      "https://openalex.org/W2963043030",
      "https://openalex.org/W2963248455",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963433587",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963578915",
      "https://openalex.org/W2963887424",
      "https://openalex.org/W2963984224",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2970401203",
      "https://openalex.org/W2970476646",
      "https://openalex.org/W2971160427",
      "https://openalex.org/W2972352645",
      "https://openalex.org/W2979308242",
      "https://openalex.org/W2981852735",
      "https://openalex.org/W2982482202",
      "https://openalex.org/W2985008383",
      "https://openalex.org/W2989692108",
      "https://openalex.org/W2994811754",
      "https://openalex.org/W2998385486",
      "https://openalex.org/W2999134550",
      "https://openalex.org/W2999524812",
      "https://openalex.org/W3000514857",
      "https://openalex.org/W3005441132",
      "https://openalex.org/W3007894275",
      "https://openalex.org/W3008917945",
      "https://openalex.org/W3013192639",
      "https://openalex.org/W3014521650",
      "https://openalex.org/W3015731157",
      "https://openalex.org/W3016625483",
      "https://openalex.org/W3017796738",
      "https://openalex.org/W3020629500",
      "https://openalex.org/W3021016503",
      "https://openalex.org/W3021533447",
      "https://openalex.org/W3021813138",
      "https://openalex.org/W3034533785",
      "https://openalex.org/W3035301094",
      "https://openalex.org/W3037026762",
      "https://openalex.org/W3049346316",
      "https://openalex.org/W3088453957",
      "https://openalex.org/W3092049183",
      "https://openalex.org/W3099231098",
      "https://openalex.org/W3101469874",
      "https://openalex.org/W3102659883",
      "https://openalex.org/W3106274079",
      "https://openalex.org/W3151929433",
      "https://openalex.org/W3189817881"
    ],
    "abstract": "Task-oriented dialogue systems are either modularized with separate dialogue state tracking (DST) and management steps or end-to-end trainable. In either case, the knowledge base (KB) plays an essential role in fulfilling user requests. Modularized systems rely on DST to interact with the KB, which is expensive in terms of annotation and inference time. End-to-end systems use the KB directly as input, but they cannot scale when the KB is larger than a few hundred entries. In this paper, we propose a method to embed the KB, of any size, directly into the model parameters. The resulting model does not require any DST or template responses, nor the KB as input, and it can dynamically update its KB via fine-tuning. We evaluate our solution in five task-oriented dialogue datasets with small, medium, and large KB size. Our experiments show that end-to-end models can effectively embed knowledge bases in their parameters and achieve competitive performance in all evaluated datasets.",
    "match_score": 1.0
  },
  "IRIS a Chat-oriented Dialogue System based on the Vector Space Model": {
    "openalex_id": "https://openalex.org/W2160458012",
    "publication_year": 2012,
    "cited_by_count": 175,
    "referenced_works": [
      "https://openalex.org/W966700856",
      "https://openalex.org/W1572676935",
      "https://openalex.org/W1604513301",
      "https://openalex.org/W1956559956",
      "https://openalex.org/W1978394996",
      "https://openalex.org/W2025265669",
      "https://openalex.org/W2094383466",
      "https://openalex.org/W2144211451",
      "https://openalex.org/W2147308966",
      "https://openalex.org/W2156517809",
      "https://openalex.org/W2161466446",
      "https://openalex.org/W2163723844",
      "https://openalex.org/W2165612380",
      "https://openalex.org/W2250895046",
      "https://openalex.org/W2574874554",
      "https://openalex.org/W2579447366"
    ],
    "abstract": "This system demonstration paper presents IRIS (Informal Response Interactive System), a chat-oriented dialogue system based on the vector space model framework. The system belongs to the class of examplebased dialogue systems and builds its chat capabilities on a dual search strategy over a large collection of dialogue samples. Additional strategies allowing for system adaptation and learning implemented over the same vector model space framework are also described and discussed. 1",
    "match_score": 0.9927007299270073
  },
  "Improving Knowledge-Aware Dialogue Response Generation by Using Human-Written Prototype Dialogues": {
    "openalex_id": "https://openalex.org/W3100523370",
    "publication_year": 2020,
    "cited_by_count": 17,
    "referenced_works": [
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W2127795553",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2561529111",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2754194354",
      "https://openalex.org/W2757121784",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2885421725",
      "https://openalex.org/W2887253986",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2952420867",
      "https://openalex.org/W2952723239",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963212250",
      "https://openalex.org/W2963371754",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963411289",
      "https://openalex.org/W2963521540",
      "https://openalex.org/W2963548348",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963986868",
      "https://openalex.org/W2964207259",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2970260827",
      "https://openalex.org/W2971199636",
      "https://openalex.org/W2997094605",
      "https://openalex.org/W2998083599",
      "https://openalex.org/W3034696087",
      "https://openalex.org/W3035356453",
      "https://openalex.org/W3121541553",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Incorporating commonsense knowledge can alleviate the issue of generating generic responses in open-domain generative dialogue systems. However, selecting knowledge facts for the dialogue context is still a challenge. The widely used approach Entity Name Matching always retrieves irrelevant facts from the view of local entity words. This paper proposes a novel knowledge selection approach, Prototype-KR, and a knowledge-aware generative model, Prototype-KRG. Given a query, our approach first retrieves a set of prototype dialogues that are relevant to the query. We find knowledge facts used in prototype dialogues usually are highly relevant to the current query; thus, Prototype-KR ranks such knowledge facts based on the semantic similarity and then selects the most appropriate facts. Subsequently, Prototype-KRG can generate an informative response using the selected knowledge facts. Experiments demonstrate that our approach has achieved notable improvements on the most metrics, compared to generative baselines. Meanwhile, compared to IR(Retrieval)-based baselines, responses generated by our approach are more relevant to the context and have comparable informativeness.",
    "match_score": 1.0
  },
  "Data-oriented Monologue-to-Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2131354864",
    "publication_year": 2011,
    "cited_by_count": 8,
    "referenced_works": [
      "https://openalex.org/W10376690",
      "https://openalex.org/W174903682",
      "https://openalex.org/W1527005685",
      "https://openalex.org/W1531374185",
      "https://openalex.org/W1586162438",
      "https://openalex.org/W1594389717",
      "https://openalex.org/W2045738181",
      "https://openalex.org/W2101426635",
      "https://openalex.org/W2109730238",
      "https://openalex.org/W2109888564",
      "https://openalex.org/W2120764338",
      "https://openalex.org/W2122130215",
      "https://openalex.org/W2122151248",
      "https://openalex.org/W2130523331",
      "https://openalex.org/W2136228803",
      "https://openalex.org/W2152921782",
      "https://openalex.org/W2158570207",
      "https://openalex.org/W2160736451",
      "https://openalex.org/W2165804688",
      "https://openalex.org/W2186590411"
    ],
    "abstract": "This short paper introduces an implemented and evaluated monolingual Text-to-Text generation system. The system takes monologue and transforms it to two-participant dialogue. After briefly motivating the task of monologue-to-dialogue generation, we describe the system and present an evaluation in terms of fluency and accuracy.",
    "match_score": 1.0
  },
  "Budgeted Policy Learning for Task-Oriented Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2949476504",
    "publication_year": 2019,
    "cited_by_count": 29,
    "referenced_works": [
      "https://openalex.org/W1533861849",
      "https://openalex.org/W1687382548",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2108738385",
      "https://openalex.org/W2117989772",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2408200822",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2473329891",
      "https://openalex.org/W2507592741",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2592808142",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2705882626",
      "https://openalex.org/W2759567155",
      "https://openalex.org/W2783543950",
      "https://openalex.org/W2808007596",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2884814595",
      "https://openalex.org/W2889186204",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2962776342",
      "https://openalex.org/W2963007936",
      "https://openalex.org/W2963043030",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963433587",
      "https://openalex.org/W2963567240",
      "https://openalex.org/W2963993502",
      "https://openalex.org/W2964080167",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W4289760729",
      "https://openalex.org/W4294446480",
      "https://openalex.org/W4306716473"
    ],
    "abstract": "This paper presents a new approach that extends Deep Dyna-Q (DDQ) by incorporating a Budget-Conscious Scheduling (BCS) to best utilize a fixed, small amount of user interactions (budget) for learning task-oriented dialogue agents. BCS consists of (1) a Poisson-based global scheduler to allocate budget over different stages of training; (2) a controller to decide at each training step whether the agent is trained using real or simulated experiences; (3) a user goal sampling module to generate the experiences that are most effective for policy learning. Experiments on a movie-ticket booking task with simulated and real users show that our approach leads to significant improvements in success rate over the state-of-the-art baselines given the fixed budget.",
    "match_score": 1.0
  },
  "A Generative Attentional Neural Network Model for Dialogue Act Classification": {
    "openalex_id": "https://openalex.org/W2741802726",
    "publication_year": 2017,
    "cited_by_count": 25,
    "referenced_works": [
      "https://openalex.org/W77001256",
      "https://openalex.org/W1482132414",
      "https://openalex.org/W1526096287",
      "https://openalex.org/W1810943226",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2106226466",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2146502635",
      "https://openalex.org/W2312383716",
      "https://openalex.org/W2401527985",
      "https://openalex.org/W2511929605",
      "https://openalex.org/W2964036636",
      "https://openalex.org/W2964139507",
      "https://openalex.org/W2964199361",
      "https://openalex.org/W2964308564"
    ],
    "abstract": "We propose a novel generative neural network architecture for Dialogue Act classification. Building upon the Recurrent Neural Network framework, our model incorporates a novel attentional technique and a label to label connection for sequence learning, akin to Hidden Markov Models. The experiments show that both of these innovations lead our model to outperform strong baselines for dialogue act classification on MapTask and Switchboard corpora. We further empirically analyse the effectiveness of each of the new innovations.",
    "match_score": 1.0
  },
  "Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2990563493",
    "publication_year": 2020,
    "cited_by_count": 69,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1539562568",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W2003458432",
      "https://openalex.org/W2038721957",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2123301721",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2140679639",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2584220694",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2787711783",
      "https://openalex.org/W2807278718",
      "https://openalex.org/W2900260828",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2962786758",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962989446",
      "https://openalex.org/W2963212250",
      "https://openalex.org/W2963283805",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963466651",
      "https://openalex.org/W2963527228",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963846996",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2963986868",
      "https://openalex.org/W2964178377",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2996068536",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4285719527",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Open-domain dialogue generation has gained increasing attention in Natural Language Processing. Its evaluation requires a holistic means. Human ratings are deemed as the gold standard. As human evaluation is inefficient and costly, an automated substitute is highly desirable. In this paper, we propose holistic evaluation metrics that capture different aspects of open-domain dialogues. Our metrics consist of (1) GPT-2 based context coherence between sentences in a dialogue, (2) GPT-2 based fluency in phrasing, (3) n-gram based diversity in responses to augmented queries, and (4) textual-entailment-inference based logical self-consistency. The empirical validity of our metrics is demonstrated by strong correlations with human judgments. We open source the code and relevant materials.",
    "match_score": 1.0
  },
  "Generating Dialogue Responses from a Semantic Latent Space": {
    "openalex_id": "https://openalex.org/W2997416967",
    "publication_year": 2020,
    "cited_by_count": 4,
    "referenced_works": [
      "https://openalex.org/W771469340",
      "https://openalex.org/W1523385540",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1883346539",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1949478088",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W2025341678",
      "https://openalex.org/W2089150068",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2116516955",
      "https://openalex.org/W2560512785",
      "https://openalex.org/W2593768305",
      "https://openalex.org/W2604444020",
      "https://openalex.org/W2733128608",
      "https://openalex.org/W2734443755",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2783130359",
      "https://openalex.org/W2784400615",
      "https://openalex.org/W2798888952",
      "https://openalex.org/W2799016112",
      "https://openalex.org/W2888093771",
      "https://openalex.org/W2890274659",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2904683980",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2916898195",
      "https://openalex.org/W2938704169",
      "https://openalex.org/W2945554776",
      "https://openalex.org/W2949782788",
      "https://openalex.org/W2953046278",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963096510",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963330684",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2964134121",
      "https://openalex.org/W2996287690",
      "https://openalex.org/W4237723258",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4294408270"
    ],
    "abstract": "Existing open-domain dialogue generation models are usually trained to mimic the gold response in the training set using cross-entropy loss on the vocabulary. However, a good response does not need to resemble the gold response, since there are multiple possible responses to a given prompt. In this work, we hypothesize that the current models are unable to integrate information from multiple semantically similar valid responses of a prompt, resulting in the generation of generic and uninformative responses. To address this issue, we propose an alternative to the end-to-end classification on vocabulary. We learn the pair relationship between the prompts and responses as a regression task on a latent space instead. In our novel dialog generation model, the representations of semantically related sentences are close to each other on the latent space. Human evaluation showed that learning the task on a continuous space can generate responses that are both relevant and informative.",
    "match_score": 1.0
  },
  "Automatic Dialogue Generation with Expressed Emotions": {
    "openalex_id": "https://openalex.org/W2805005636",
    "publication_year": 2018,
    "cited_by_count": 143,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1566256432",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1966797434",
      "https://openalex.org/W1975827232",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2419539795",
      "https://openalex.org/W2550821151",
      "https://openalex.org/W2563351168",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2590513900",
      "https://openalex.org/W2618843390",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4249243325",
      "https://openalex.org/W4294170691"
    ],
    "abstract": "Chenyang Huang, Osmar Za\u00efane, Amine Trabelsi, Nouha Dziri. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers). 2018.",
    "match_score": 1.0
  },
  "NEXUS Network Connecting the Preceding and the Following in Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2891744372",
    "publication_year": 2018,
    "cited_by_count": 31,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W222053410",
      "https://openalex.org/W1516111018",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1603615955",
      "https://openalex.org/W1614298861",
      "https://openalex.org/W1779483307",
      "https://openalex.org/W1828163288",
      "https://openalex.org/W1958706068",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W2077846610",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2122262818",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2136144249",
      "https://openalex.org/W2142112143",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2171421863",
      "https://openalex.org/W2188365844",
      "https://openalex.org/W2210838531",
      "https://openalex.org/W2250645967",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2419501139",
      "https://openalex.org/W2546938941",
      "https://openalex.org/W2547875792",
      "https://openalex.org/W2548228487",
      "https://openalex.org/W2557436004",
      "https://openalex.org/W2560512785",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2587284713",
      "https://openalex.org/W2598482664",
      "https://openalex.org/W2602076750",
      "https://openalex.org/W2604178507",
      "https://openalex.org/W2612675303",
      "https://openalex.org/W2661761953",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2788277448",
      "https://openalex.org/W2789543585",
      "https://openalex.org/W2803832867",
      "https://openalex.org/W2899771611",
      "https://openalex.org/W2950306824",
      "https://openalex.org/W2952264928",
      "https://openalex.org/W2953046278",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962738009",
      "https://openalex.org/W2962871754",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963226019",
      "https://openalex.org/W2963275229",
      "https://openalex.org/W2963332597",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963768805",
      "https://openalex.org/W2963799213",
      "https://openalex.org/W2963800509",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963958388",
      "https://openalex.org/W2964026424",
      "https://openalex.org/W2964042872",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3136591341",
      "https://openalex.org/W4237840503"
    ],
    "abstract": "Sequence-to-Sequence (seq2seq) models have become overwhelmingly popular in building end-to-end trainable dialogue systems. Though highly efficient in learning the backbone of human-computer communications, they suffer from the problem of strongly favoring short generic responses. In this paper, we argue that a good response should smoothly connect both the preceding dialogue history and the following conversations. We strengthen this connection by mutual information maximization. To sidestep the non-differentiability of discrete natural language tokens, we introduce an auxiliary continuous code space and map such code space to a learnable prior distribution for generation purpose. Experiments on two dialogue datasets validate the effectiveness of our model, where the generated responses are closely related to the dialogue context and lead to more interactive conversations.",
    "match_score": 0.9937106918238994
  },
  "Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W3020990315",
    "publication_year": 2020,
    "cited_by_count": 5,
    "referenced_works": [
      "https://openalex.org/W1525961042",
      "https://openalex.org/W1598178035",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W1969152782",
      "https://openalex.org/W2055537935",
      "https://openalex.org/W2077302143",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2251957808",
      "https://openalex.org/W2468710617",
      "https://openalex.org/W2561715562",
      "https://openalex.org/W2745934983",
      "https://openalex.org/W2751448157",
      "https://openalex.org/W2759998906",
      "https://openalex.org/W2784070054",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2892248135",
      "https://openalex.org/W2906637185",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2963267799",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963518342",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2971034786",
      "https://openalex.org/W2972571786",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W2999837696",
      "https://openalex.org/W3102961474",
      "https://openalex.org/W3188964051"
    ],
    "abstract": "Zero-shot transfer learning for multi-domain dialogue state tracking can allow us to handle new domains without incurring the high cost of data acquisition. This paper proposes new zero-short transfer learning technique for dialogue state tracking where the in-domain training data are all synthesized from an abstract dialogue model and the ontology of the domain. We show that data augmentation through synthesized data can improve the accuracy of zero-shot learning for both the TRADE model and the BERT-based SUMBT model on the MultiWOZ 2.1 dataset. We show training with only synthesized in-domain data on the SUMBT model can reach about 2/3 of the accuracy obtained with the full training dataset. We improve the zero-shot learning state of the art on average across domains by 21%.",
    "match_score": 1.0
  },
  "OpenDial A Toolkit for Developing Spoken Dialogue Systems with Probabilistic Rules": {
    "openalex_id": "https://openalex.org/W2508347479",
    "publication_year": 2016,
    "cited_by_count": 73,
    "referenced_works": [
      "https://openalex.org/W1569268747",
      "https://openalex.org/W1941338968",
      "https://openalex.org/W1963612627",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1979982232",
      "https://openalex.org/W2043496750",
      "https://openalex.org/W2084950741",
      "https://openalex.org/W2101308260",
      "https://openalex.org/W2112924667",
      "https://openalex.org/W2127838323"
    ],
    "abstract": "We present a new release of OpenDial, an open-source toolkit for building and evaluating spoken dialogue systems.The toolkit relies on an information-state architecture where the dialogue state is represented as a Bayesian network and acts as a shared memory for all system modules.The domain models are specified via probabilistic rules encoded in XML.Open-Dial has been deployed in several application domains such as human-robot interaction, intelligent tutoring systems and multi-modal in-car driver assistants.",
    "match_score": 0.9939393939393939
  },
  "What You See is What You Get Visual Pronoun Coreference Resolution in Dialogues": {
    "openalex_id": "https://openalex.org/W4288162065",
    "publication_year": 2019,
    "cited_by_count": 6,
    "referenced_works": [],
    "abstract": "Grounding a pronoun to a visual object it refers to requires complex\\nreasoning from various information sources, especially in conversational\\nscenarios. For example, when people in a conversation talk about something all\\nspeakers can see, they often directly use pronouns (e.g., it) to refer to it\\nwithout previous introduction. This fact brings a huge challenge for modern\\nnatural language understanding systems, particularly conventional context-based\\npronoun coreference models. To tackle this challenge, in this paper, we\\nformally define the task of visual-aware pronoun coreference resolution (PCR)\\nand introduce VisPro, a large-scale dialogue PCR dataset, to investigate\\nwhether and how the visual information can help resolve pronouns in dialogues.\\nWe then propose a novel visual-aware PCR model, VisCoref, for this task and\\nconduct comprehensive experiments and case studies on our dataset. Results\\ndemonstrate the importance of the visual information in this PCR case and show\\nthe effectiveness of the proposed model.\\n",
    "match_score": 0.9813664596273292
  },
  "Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for Span-based Question Answering": {
    "openalex_id": "https://openalex.org/W3034520363",
    "publication_year": 2020,
    "cited_by_count": 24,
    "referenced_works": [
      "https://openalex.org/W2557764419",
      "https://openalex.org/W2558203065",
      "https://openalex.org/W2612228435",
      "https://openalex.org/W2805206884",
      "https://openalex.org/W2888302696",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2912904516",
      "https://openalex.org/W2914120296",
      "https://openalex.org/W2951534261",
      "https://openalex.org/W2963323070",
      "https://openalex.org/W2963339397",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963748441",
      "https://openalex.org/W2963963993",
      "https://openalex.org/W2964120615",
      "https://openalex.org/W2964223283",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2970049541",
      "https://openalex.org/W2970597249",
      "https://openalex.org/W2975059944",
      "https://openalex.org/W2979928633",
      "https://openalex.org/W2990138404",
      "https://openalex.org/W2996428491",
      "https://openalex.org/W4288614645",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "We introduce a novel approach to transformers that learns hierarchical representations in multiparty dialogue. First, three language modeling tasks are used to pre-train the transformers, token- and utterance-level language modeling and utterance order prediction, that learn both token and utterance embeddings for better understanding in dialogue contexts. Then, multi-task learning between the utterance prediction and the token span prediction is applied to fine-tune for span-based question answering (QA). Our approach is evaluated on the FriendsQA dataset and shows improvements of 3.8% and 1.4% over the two state-of-the-art transformer models, BERT and RoBERTa, respectively.",
    "match_score": 1.0
  },
  "Neural Belief Tracker Data-Driven Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W2432549722",
    "publication_year": 2017,
    "cited_by_count": 73,
    "referenced_works": [
      "https://openalex.org/W1441091828",
      "https://openalex.org/W1524766440",
      "https://openalex.org/W1587506928",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W1814992895",
      "https://openalex.org/W1989996186",
      "https://openalex.org/W1993567041",
      "https://openalex.org/W2024632416",
      "https://openalex.org/W2055537935",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2101138947",
      "https://openalex.org/W2115101920",
      "https://openalex.org/W2118463056",
      "https://openalex.org/W2166293310",
      "https://openalex.org/W2187089797",
      "https://openalex.org/W2189256702",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250456405",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251044566",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251355666",
      "https://openalex.org/W2282031862",
      "https://openalex.org/W2372621665",
      "https://openalex.org/W2397579082",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2442323289",
      "https://openalex.org/W2468710617",
      "https://openalex.org/W2471178169",
      "https://openalex.org/W2534274346",
      "https://openalex.org/W2561293850",
      "https://openalex.org/W2575101493",
      "https://openalex.org/W2586719289",
      "https://openalex.org/W2949300694",
      "https://openalex.org/W2949697461",
      "https://openalex.org/W2951642317",
      "https://openalex.org/W2952230511",
      "https://openalex.org/W2962847367",
      "https://openalex.org/W2963050422",
      "https://openalex.org/W2963775726",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2963974889",
      "https://openalex.org/W2964121744"
    ],
    "abstract": "One of the core components of modern spoken dialogue systems is the belief tracker, which estimates the user's goal at every step of the dialogue. However, most current approaches have difficulty scaling to larger, more complex dialogue domains. This is due to their dependency on either: a) Spoken Language Understanding models that require large amounts of annotated training data; or b) hand-crafted lexicons for capturing some of the linguistic variation in users' language. We propose a novel Neural Belief Tracking (NBT) framework which overcomes these problems by building on recent advances in representation learning. NBT models reason over pre-trained word vectors, learning to compose them into distributed representations of user utterances and dialogue context. Our evaluation on two datasets shows that this approach surpasses past limitations, matching the performance of state-of-the-art models which rely on hand-crafted semantic lexicons and outperforming them when such lexicons are not provided.",
    "match_score": 0.991304347826087
  },
  "Multimodal Menu-based Dialogue with Speech Cursor in DICO II+": {
    "openalex_id": "https://openalex.org/W2158162461",
    "publication_year": 2011,
    "cited_by_count": 1,
    "referenced_works": [
      "https://openalex.org/W194972339",
      "https://openalex.org/W1495817119"
    ],
    "abstract": "This paper describes Dico II+, an in-vehicle dialogue system demonstrating a novel combination of flexible multimodal menu-based dialogueand a speech cursor which enables menu navigation as well as browsing long list using haptic input and spoken output.",
    "match_score": 1.0
  },
  "Profile Consistency Identification for Open-domain Dialogue Agents": {
    "openalex_id": "https://openalex.org/W3087232873",
    "publication_year": 2020,
    "cited_by_count": 19,
    "referenced_works": [
      "https://openalex.org/W1840435438",
      "https://openalex.org/W1879966306",
      "https://openalex.org/W2053154970",
      "https://openalex.org/W2164777277",
      "https://openalex.org/W2608787653",
      "https://openalex.org/W2741631785",
      "https://openalex.org/W2754831410",
      "https://openalex.org/W2788496822",
      "https://openalex.org/W2797206276",
      "https://openalex.org/W2911994530",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2962989446",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963530300",
      "https://openalex.org/W2963544700",
      "https://openalex.org/W2963640662",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963846996",
      "https://openalex.org/W2964309167",
      "https://openalex.org/W2965718149",
      "https://openalex.org/W2971822538",
      "https://openalex.org/W2972324944",
      "https://openalex.org/W2983160116",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2996657743",
      "https://openalex.org/W2997306177",
      "https://openalex.org/W2997892440",
      "https://openalex.org/W3034720580",
      "https://openalex.org/W3037026762",
      "https://openalex.org/W3099023595",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4294338648"
    ],
    "abstract": "Maintaining a consistent attribute profile is crucial for dialogue agents to\\nnaturally converse with humans. Existing studies on improving attribute\\nconsistency mainly explored how to incorporate attribute information in the\\nresponses, but few efforts have been made to identify the consistency relations\\nbetween response and attribute profile. To facilitate the study of profile\\nconsistency identification, we create a large-scale human-annotated dataset\\nwith over 110K single-turn conversations and their key-value attribute\\nprofiles. Explicit relation between response and profile is manually labeled.\\nWe also propose a key-value structure information enriched BERT model to\\nidentify the profile consistency, and it gained improvements over strong\\nbaselines. Further evaluations on downstream tasks demonstrate that the profile\\nconsistency identification model is conducive for improving dialogue\\nconsistency.\\n",
    "match_score": 1.0
  },
  "Latent Variable Dialogue Models and their Diversity": {
    "openalex_id": "https://openalex.org/W2593696076",
    "publication_year": 2017,
    "cited_by_count": 50,
    "referenced_works": [
      "https://openalex.org/W6908809",
      "https://openalex.org/W36903255",
      "https://openalex.org/W630532510",
      "https://openalex.org/W889023230",
      "https://openalex.org/W1574486308",
      "https://openalex.org/W1958706068",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W2011925159",
      "https://openalex.org/W2108501770",
      "https://openalex.org/W2159640018",
      "https://openalex.org/W2172140247",
      "https://openalex.org/W2173681125",
      "https://openalex.org/W2188365844",
      "https://openalex.org/W2210838531",
      "https://openalex.org/W2311783643",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2384495648",
      "https://openalex.org/W2399880602",
      "https://openalex.org/W2552838200",
      "https://openalex.org/W2949416428",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963551569",
      "https://openalex.org/W2963773425",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964199361",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W3022187094"
    ],
    "abstract": "We present a dialogue generation model that directly captures the variability in possible responses to a given input, which reduces the \u2018boring output\u2019 issue of deterministic dialogue models. Experiments show that our model generates more diverse outputs than baseline models, and also generates more consistently acceptable output than sampling from a deterministic encoder-decoder model.",
    "match_score": 1.0
  },
  "Multi-task Learning for Natural Language Generation in Task-Oriented Dialogue": {
    "openalex_id": "https://openalex.org/W2970444947",
    "publication_year": 2019,
    "cited_by_count": 33,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1917215959",
      "https://openalex.org/W1947758080",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W2060833990",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2108239140",
      "https://openalex.org/W2124445791",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2169818249",
      "https://openalex.org/W2291723583",
      "https://openalex.org/W2891439916",
      "https://openalex.org/W2951176429",
      "https://openalex.org/W2952230511",
      "https://openalex.org/W2962965405",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W3100380967",
      "https://openalex.org/W4292763141",
      "https://openalex.org/W4299612276",
      "https://openalex.org/W4300532998"
    ],
    "abstract": "Chenguang Zhu, Michael Zeng, Xuedong Huang. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "Deep Dyna-Q Integrating Planning for Task-Completion Dialogue Policy Learning": {
    "openalex_id": "https://openalex.org/W2798494119",
    "publication_year": 2018,
    "cited_by_count": 184,
    "referenced_works": [
      "https://openalex.org/W16046748",
      "https://openalex.org/W52170320",
      "https://openalex.org/W1491843047",
      "https://openalex.org/W1515851193",
      "https://openalex.org/W1564312725",
      "https://openalex.org/W1681299129",
      "https://openalex.org/W1758031947",
      "https://openalex.org/W1778387566",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2035934535",
      "https://openalex.org/W2048226872",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2109038907",
      "https://openalex.org/W2112483970",
      "https://openalex.org/W2117989772",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2257979135",
      "https://openalex.org/W2290354866",
      "https://openalex.org/W2295072214",
      "https://openalex.org/W2396229782",
      "https://openalex.org/W2412899141",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2473329891",
      "https://openalex.org/W2507592741",
      "https://openalex.org/W2567374473",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2765111838",
      "https://openalex.org/W2766447205",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2950314731",
      "https://openalex.org/W2950471160",
      "https://openalex.org/W2950517718",
      "https://openalex.org/W2962776342",
      "https://openalex.org/W2962996309",
      "https://openalex.org/W2963043030",
      "https://openalex.org/W2963064439",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2964077562",
      "https://openalex.org/W2964080167",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W3021208093",
      "https://openalex.org/W3104546989",
      "https://openalex.org/W4229706854",
      "https://openalex.org/W4245108548",
      "https://openalex.org/W4293396018"
    ],
    "abstract": "Training a task-completion dialogue agent via reinforcement learning (RL) is costly because it requires many interactions with real users. One common alternative is to use a user simulator. However, a user simulator usually lacks the language complexity of human interlocutors and the biases in its design may tend to degrade the agent. To address these issues, we present Deep Dyna-Q, which to our knowledge is the first deep RL framework that integrates planning for task-completion dialogue policy learning. We incorporate into the dialogue agent a model of the environment, referred to as the world model, to mimic real user response and generate simulated experience. During dialogue policy learning, the world model is constantly updated with real user experience to approach real user behavior, and in turn, the dialogue agent is optimized using both real experience and simulated experience. The effectiveness of our approach is demonstrated on a movie-ticket booking task in both simulated and human-in-the-loop settings.",
    "match_score": 0.9935483870967742
  },
  "The Teams Corpus and Entrainment in Multi-Party Spoken Dialogues": {
    "openalex_id": "https://openalex.org/W2564880510",
    "publication_year": 2016,
    "cited_by_count": 24,
    "referenced_works": [
      "https://openalex.org/W1536313757",
      "https://openalex.org/W1669985085",
      "https://openalex.org/W1875231349",
      "https://openalex.org/W1970251998",
      "https://openalex.org/W1971505647",
      "https://openalex.org/W1980511580",
      "https://openalex.org/W1991820721",
      "https://openalex.org/W1992711317",
      "https://openalex.org/W2024715881",
      "https://openalex.org/W2032325851",
      "https://openalex.org/W2050125829",
      "https://openalex.org/W2082178985",
      "https://openalex.org/W2087900392",
      "https://openalex.org/W2089652186",
      "https://openalex.org/W2092196438",
      "https://openalex.org/W2093268611",
      "https://openalex.org/W2101416990",
      "https://openalex.org/W2101532847",
      "https://openalex.org/W2120314390",
      "https://openalex.org/W2123027949",
      "https://openalex.org/W2125336414",
      "https://openalex.org/W2130703925",
      "https://openalex.org/W2135243376",
      "https://openalex.org/W2143302363",
      "https://openalex.org/W2145588856",
      "https://openalex.org/W2145747781",
      "https://openalex.org/W2147154374",
      "https://openalex.org/W2148445705",
      "https://openalex.org/W2154522120",
      "https://openalex.org/W2182998842",
      "https://openalex.org/W2252271018",
      "https://openalex.org/W2404124622",
      "https://openalex.org/W2952377244",
      "https://openalex.org/W2964195122",
      "https://openalex.org/W3122271111",
      "https://openalex.org/W4243968218",
      "https://openalex.org/W4249803144",
      "https://openalex.org/W4251603968",
      "https://openalex.org/W4256327895",
      "https://openalex.org/W4317471952"
    ],
    "abstract": "When interacting individuals entrain, they begin to speak more like each other.To support research on entrainment in cooperative multi-party dialogues, we have created a corpus where teams of three or four speakers play two rounds of a cooperative board game.We describe the experimental design and technical infrastructure used to collect our corpus, which consists of audio, video, transcriptions, and questionnaire data for 63 teams (47 hours of audio).We illustrate the use of our corpus as a novel resource for studying team entrainment by 1) developing and evaluating teamlevel acoustic-prosodic entrainment measures that extend existing dyad measures, and 2) investigating relationships between team entrainment and participation dominance.",
    "match_score": 1.0
  },
  "Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2952728748",
    "publication_year": 2019,
    "cited_by_count": 53,
    "referenced_works": [],
    "abstract": "Developing Video-Grounded Dialogue Systems (VGDS), where a dialogue is\\nconducted based on visual and audio aspects of a given video, is significantly\\nmore challenging than traditional image or text-grounded dialogue systems\\nbecause (1) feature space of videos span across multiple picture frames, making\\nit difficult to obtain semantic information; and (2) a dialogue agent must\\nperceive and process information from different modalities (audio, video,\\ncaption, etc.) to obtain a comprehensive understanding. Most existing work is\\nbased on RNNs and sequence-to-sequence architectures, which are not very\\neffective for capturing complex long-term dependencies (like in videos). To\\novercome this, we propose Multimodal Transformer Networks (MTN) to encode\\nvideos and incorporate information from different modalities. We also propose\\nquery-aware attention through an auto-encoder to extract query-aware features\\nfrom non-text modalities. We develop a training procedure to simulate\\ntoken-level decoding to improve the quality of generated responses during\\ninference. We get state of the art performance on Dialogue System Technology\\nChallenge 7 (DSTC7). Our model also generalizes to another multimodal\\nvisual-grounded dialogue task, and obtains promising performance. We\\nimplemented our models using PyTorch and the code is released at\\nhttps://github.com/henryhungle/MTN.\\n",
    "match_score": 1.0
  },
  "Dialogue over Context and Structured Knowledge using a Neural Network Model with External Memories": {
    "openalex_id": "https://openalex.org/W3120948726",
    "publication_year": 2020,
    "cited_by_count": 2,
    "referenced_works": [
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2117489143",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2293453011",
      "https://openalex.org/W2296712013",
      "https://openalex.org/W2840098622",
      "https://openalex.org/W2950527759",
      "https://openalex.org/W2963210342",
      "https://openalex.org/W2964119254",
      "https://openalex.org/W2964308564"
    ],
    "abstract": "The Differentiable Neural Computer (DNC), a neural network model with an addressable external memory, can solve algorithmic and question answering tasks. There are various improved versions of DNC, such as rsDNC and DNC-DMS. However, how to integrate structured knowledge into these DNC models remains a challenging research question. We incorporate an architecture for knowledge into such DNC models, i.e. DNC, rsDNC and DNC-DMS, to improve the ability to generate correct responses using both contextual information and structured knowledge. Our improved rsDNC model improves the mean accuracy by approximately 20% to the original rsDNC on tasks requiring knowledge in the dialog bAbI tasks. In addition, our improved rsDNC and DNC-DMS models also yield better performance than their original models in the Movie Dialog dataset.",
    "match_score": 1.0
  },
  "Dialogue Response Ranking Training with Large-Scale Human Feedback Data": {
    "openalex_id": "https://openalex.org/W3098258760",
    "publication_year": 2020,
    "cited_by_count": 63,
    "referenced_works": [
      "https://openalex.org/W105848778",
      "https://openalex.org/W1914571458",
      "https://openalex.org/W2019502441",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2106242970",
      "https://openalex.org/W2111910266",
      "https://openalex.org/W2130041324",
      "https://openalex.org/W2138621090",
      "https://openalex.org/W2147453867",
      "https://openalex.org/W2155482025",
      "https://openalex.org/W2264742718",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2890969459",
      "https://openalex.org/W2906579211",
      "https://openalex.org/W2916898195",
      "https://openalex.org/W2936695845",
      "https://openalex.org/W2949555952",
      "https://openalex.org/W2951883832",
      "https://openalex.org/W2953206424",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963667505",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2969574947",
      "https://openalex.org/W2970785611",
      "https://openalex.org/W2972437240",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2996403597",
      "https://openalex.org/W2998563994",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3005680577",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3024436954",
      "https://openalex.org/W3035252911",
      "https://openalex.org/W3037969532",
      "https://openalex.org/W3098708719",
      "https://openalex.org/W3104078590",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W4252076394",
      "https://openalex.org/W4287900772"
    ],
    "abstract": "Existing open-domain dialog models are generally trained to minimize the perplexity of target human responses. However, some human replies are more engaging than others, spawning more followup interactions. Current conversational models are increasingly capable of producing turns that are context-relevant, but in order to produce compelling agents, these models need to be able to predict and optimize for turns that are genuinely engaging. We leverage social media feedback data (number of replies and upvotes) to build a large-scale training dataset for feedback prediction. To alleviate possible distortion between the feedback and engagingness, we convert the ranking problem to a comparison of response pairs which involve few confounding factors. We trained DialogRPT, a set of GPT-2 based models on 133M pairs of human feedback data and the resulting ranker outperformed several baselines. Particularly, our ranker outperforms the conventional dialog perplexity baseline with a large margin on predicting Reddit feedback. We finally combine the feedback prediction models and a human-like scoring model to rank the machine-generated dialog responses. Crowd-sourced human evaluation shows that our ranking method correlates better with real human preferences than baseline models.",
    "match_score": 1.0
  },
  "Regularizing Dialogue Generation by Imitating Implicit Scenarios": {
    "openalex_id": "https://openalex.org/W3105205406",
    "publication_year": 2020,
    "cited_by_count": 18,
    "referenced_works": [
      "https://openalex.org/W648786980",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1690739335",
      "https://openalex.org/W1821462560",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2419539795",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2584185835",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2761590056",
      "https://openalex.org/W2767206889",
      "https://openalex.org/W2784400615",
      "https://openalex.org/W2807880213",
      "https://openalex.org/W2890969459",
      "https://openalex.org/W2891744372",
      "https://openalex.org/W2892153332",
      "https://openalex.org/W2916898195",
      "https://openalex.org/W2950142196",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2951883832",
      "https://openalex.org/W2952729433",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962896208",
      "https://openalex.org/W2962915948",
      "https://openalex.org/W2962969034",
      "https://openalex.org/W2963026768",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963330684",
      "https://openalex.org/W2963360026",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963434219",
      "https://openalex.org/W2963544536",
      "https://openalex.org/W2963712524",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963959597",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964118293",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964134121",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964345285",
      "https://openalex.org/W2970454332",
      "https://openalex.org/W2976965654",
      "https://openalex.org/W2997955173",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3093329015",
      "https://openalex.org/W4288256350",
      "https://openalex.org/W4299971819",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Human dialogues are scenario-based and appropriate responses generally relate to the latent context knowledge entailed by the specific scenario. To enable responses that are more meaningful and context-specific, we propose to improve generative dialogue systems from the scenario perspective, where both dialogue history and future conversation are taken into account to implicitly reconstruct the scenario knowledge. More importantly, the conversation scenarios are further internalized using imitation learning framework, where the conventional dialogue model that has no access to future conversations is effectively regularized by transferring the scenario knowledge contained in hierarchical supervising signals from the scenario-based dialogue model, so that the future conversation is not required in actual inference. Extensive evaluations show that our approach significantly outperforms state-of-the-art baselines on diversity and relevance, and expresses scenario-specific knowledge.",
    "match_score": 1.0
  },
  "Video-Grounded Dialogues with Pretrained Generation Language Models": {
    "openalex_id": "https://openalex.org/W3035314827",
    "publication_year": 2020,
    "cited_by_count": 26,
    "referenced_works": [
      "https://openalex.org/W1933349210",
      "https://openalex.org/W2194775991",
      "https://openalex.org/W2331128040",
      "https://openalex.org/W2337252826",
      "https://openalex.org/W2549139847",
      "https://openalex.org/W2563399268",
      "https://openalex.org/W2606982687",
      "https://openalex.org/W2810643877",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2952686080",
      "https://openalex.org/W2962934715",
      "https://openalex.org/W2963174698",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963446712",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2966715458",
      "https://openalex.org/W2967674528",
      "https://openalex.org/W2969876226",
      "https://openalex.org/W2970608575",
      "https://openalex.org/W2970869018",
      "https://openalex.org/W2972777589",
      "https://openalex.org/W2975501350",
      "https://openalex.org/W2981851019",
      "https://openalex.org/W2988647680",
      "https://openalex.org/W2996428491",
      "https://openalex.org/W2998356391",
      "https://openalex.org/W3015746101",
      "https://openalex.org/W3099388488",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4297800839",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Pre-trained language models have shown remarkable success in improving various downstream NLP tasks due to their ability to capture dependencies in textual data and generate natural responses. In this paper, we leverage the power of pre-trained language models for improving video-grounded dialogue, which is very challenging and involves complex features of different dynamics: (1) Video features which can extend across both spatial and temporal dimensions; and (2) Dialogue features which involve semantic dependencies over multiple dialogue turns. We propose a framework by extending GPT-2 models to tackle these challenges by formulating video-grounded dialogue tasks as a sequence-to-sequence task, combining both visual and textual representation into a structured sequence, and fine-tuning a large pre-trained GPT-2 network. Our framework allows fine-tuning language models to capture dependencies across multiple modalities over different levels of information: spatio-temporal level in video and token-sentence level in dialogue context. We achieve promising improvement on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark from DSTC7, which supports a potential direction in this line of research.",
    "match_score": 1.0
  },
  "Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2945475330",
    "publication_year": 2019,
    "cited_by_count": 412,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W2047335008",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251355666",
      "https://openalex.org/W2407905223",
      "https://openalex.org/W2426267443",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2550821151",
      "https://openalex.org/W2554616628",
      "https://openalex.org/W2556468274",
      "https://openalex.org/W2560647685",
      "https://openalex.org/W2561696860",
      "https://openalex.org/W2583761661",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2604763608",
      "https://openalex.org/W2605043629",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2777054756",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2809324505",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2888541716",
      "https://openalex.org/W2949995560",
      "https://openalex.org/W2962724315",
      "https://openalex.org/W2962934384",
      "https://openalex.org/W2962944953",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963243930",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963578915",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963866663",
      "https://openalex.org/W2963924212",
      "https://openalex.org/W2963936679",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964316912",
      "https://openalex.org/W3103800629",
      "https://openalex.org/W4289147179",
      "https://openalex.org/W4293350112",
      "https://openalex.org/W4295200480",
      "https://openalex.org/W4295883599",
      "https://openalex.org/W4306716473",
      "https://openalex.org/W4319988532"
    ],
    "abstract": "Over-dependence on domain ontology and lack of knowledge sharing across domains are two practical and yet less studied problems of dialogue state tracking. Existing approaches generally fall short in tracking unknown slot values during inference and often have difficulties in adapting to new domains. In this paper, we propose a TRAnsferable Dialogue staff, generator (TRADE) that generates dialogue states from utterances using a copy mechanism, facilitating knowledge transfer when predicting (domain, slot, value) triplets not encountered during training. Our model is composed of an utterance encoder, a slot gate, and a state generator, which are shared across domains. Empirical results demonstrate that TRADE achieves state-of-the-art joint goal accuracy of 48.62% for the five domains of MultiWOZ, a human-human dialogue dataset. In addition, we show its transferring ability by simulating zero-shot and few-shot dialogue state tracking for unseen domains. TRADE achieves 60.58% joint goal accuracy in one of the zero-shot domains, and is able to adapt to few-shot cases without forgetting already trained domains.",
    "match_score": 1.0
  },
  "Multi-domain Neural Network Language Generation for Spoken Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2291723583",
    "publication_year": 2016,
    "cited_by_count": 172,
    "referenced_works": [
      "https://openalex.org/W119177792",
      "https://openalex.org/W179875071",
      "https://openalex.org/W1542311097",
      "https://openalex.org/W1552182777",
      "https://openalex.org/W1606347560",
      "https://openalex.org/W1627331591",
      "https://openalex.org/W1644652583",
      "https://openalex.org/W1834646128",
      "https://openalex.org/W1947758080",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1971111363",
      "https://openalex.org/W1973310094",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1989549063",
      "https://openalex.org/W1999965501",
      "https://openalex.org/W2005076803",
      "https://openalex.org/W2005874308",
      "https://openalex.org/W2008652694",
      "https://openalex.org/W2012918311",
      "https://openalex.org/W2018116724",
      "https://openalex.org/W2020073413",
      "https://openalex.org/W2050523636",
      "https://openalex.org/W2063473970",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2093973850",
      "https://openalex.org/W2096557251",
      "https://openalex.org/W2099542783",
      "https://openalex.org/W2100969003",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2108239140",
      "https://openalex.org/W2120354757",
      "https://openalex.org/W2122514299",
      "https://openalex.org/W2127838323",
      "https://openalex.org/W2137387514",
      "https://openalex.org/W2139079654",
      "https://openalex.org/W2146871184",
      "https://openalex.org/W2150355110",
      "https://openalex.org/W2157716519",
      "https://openalex.org/W2161166090",
      "https://openalex.org/W2161181481",
      "https://openalex.org/W2163302275",
      "https://openalex.org/W2165698076",
      "https://openalex.org/W2251071050",
      "https://openalex.org/W2288878529",
      "https://openalex.org/W2294684023",
      "https://openalex.org/W2399550240",
      "https://openalex.org/W2953265577",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W4285719527",
      "https://openalex.org/W4292763141"
    ],
    "abstract": "Moving from limited-domain natural language generation (NLG) to open domain is difficult because the number of semantic input combinations grows exponentially with the number of domains. Therefore, it is important to leverage existing resources and exploit similarities between domains to facilitate domain adaptation. In this paper, we propose a procedure to train multi-domain, Recurrent Neural Network-based (RNN) language generators via multiple adaptation steps. In this procedure, a model is first trained on counterfeited data synthesised from an out-of-domain dataset, and then fine tuned on a small set of in-domain utterances with a discriminative objective function. Corpus-based evaluation results show that the proposed procedure can achieve competitive performance in terms of BLEU score and slot error rate while significantly reducing the data needed to train generators in new, unseen domains. In subjective testing, human judges confirm that the procedure greatly improves generator performance when only a small amount of data is available in the domain.",
    "match_score": 1.0
  },
  "Recommendation as a Communication Game Self-Supervised Bot-Play for Goal-oriented Dialogue": {
    "openalex_id": "https://openalex.org/W2970799419",
    "publication_year": 2019,
    "cited_by_count": 81,
    "referenced_works": [
      "https://openalex.org/W1509030783",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W2000031724",
      "https://openalex.org/W2054141820",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2127480961",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2144487656",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2250777971",
      "https://openalex.org/W2605350416",
      "https://openalex.org/W2755957574",
      "https://openalex.org/W2766447205",
      "https://openalex.org/W2780155557",
      "https://openalex.org/W2784400615",
      "https://openalex.org/W2891389695",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2952215380",
      "https://openalex.org/W2962784628",
      "https://openalex.org/W2962852262",
      "https://openalex.org/W2962879001",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2962985038",
      "https://openalex.org/W2963170138",
      "https://openalex.org/W2963217826",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963448850",
      "https://openalex.org/W2963537482",
      "https://openalex.org/W2963626623",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W4239272157",
      "https://openalex.org/W4295249402"
    ],
    "abstract": "Dongyeop Kang, Anusha Balakrishnan, Pararth Shah, Paul Crook, Y-Lan Boureau, Jason Weston. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 0.994475138121547
  },
  "Learning Goal-oriented Dialogue Policy with opposite Agent Awareness": {
    "openalex_id": "https://openalex.org/W3019549080",
    "publication_year": 2020,
    "cited_by_count": 7,
    "referenced_works": [
      "https://openalex.org/W1491843047",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2064290760",
      "https://openalex.org/W2097714468",
      "https://openalex.org/W2117989772",
      "https://openalex.org/W2141538250",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2155027007",
      "https://openalex.org/W2168490009",
      "https://openalex.org/W2177156214",
      "https://openalex.org/W2250464714",
      "https://openalex.org/W2257979135",
      "https://openalex.org/W2288878529",
      "https://openalex.org/W2410985346",
      "https://openalex.org/W2412899141",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2513380446",
      "https://openalex.org/W2558661633",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2736601468",
      "https://openalex.org/W2789327587",
      "https://openalex.org/W2797760463",
      "https://openalex.org/W2798494119",
      "https://openalex.org/W2804047045",
      "https://openalex.org/W2889186204",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2899771611",
      "https://openalex.org/W2899908862",
      "https://openalex.org/W2947212824",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2949868354",
      "https://openalex.org/W2951091467",
      "https://openalex.org/W2962682659",
      "https://openalex.org/W2962852262",
      "https://openalex.org/W2962879001",
      "https://openalex.org/W2962996309",
      "https://openalex.org/W2963043030",
      "https://openalex.org/W2963433587",
      "https://openalex.org/W2964345285",
      "https://openalex.org/W2970028737",
      "https://openalex.org/W3104546989"
    ],
    "abstract": "Most existing approaches for goal-oriented dialogue policy learning used reinforcement learning, which focuses on the target agent policy and simply treat the opposite agent policy as part of the environment. While in real-world scenarios, the behavior of an opposite agent often exhibits certain patterns or underlies hidden policies, which can be inferred and utilized by the target agent to facilitate its own decision making. This strategy is common in human mental simulation by first imaging a specific action and the probable results before really acting it. We therefore propose an opposite behavior aware framework for policy learning in goal-oriented dialogues. We estimate the opposite agent's policy from its behavior and use this estimation to improve the target agent by regarding it as part of the target policy. We evaluate our model on both cooperative and competitive dialogue tasks, showing superior performance over state-of-the-art baselines.",
    "match_score": 1.0
  },
  "Improving Dialogue State Tracking by Discerning the Relevant Context": {
    "openalex_id": "https://openalex.org/W2934890006",
    "publication_year": 2019,
    "cited_by_count": 12,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1989996186",
      "https://openalex.org/W1993567041",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2108806737",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2473965551",
      "https://openalex.org/W2556468274",
      "https://openalex.org/W2597655663",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2624448691",
      "https://openalex.org/W2749436976",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2963243930",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963844597",
      "https://openalex.org/W2963970400",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W4289147179"
    ],
    "abstract": "Sanuj Sharma, Prafulla Kumar Choubey, Ruihong Huang. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019.",
    "match_score": 1.0
  },
  "Towards Emotion-aided Multi-modal Dialogue Act Classification": {
    "openalex_id": "https://openalex.org/W3035473672",
    "publication_year": 2020,
    "cited_by_count": 62,
    "referenced_works": [
      "https://openalex.org/W155915536",
      "https://openalex.org/W1503312748",
      "https://openalex.org/W1517858959",
      "https://openalex.org/W1526096287",
      "https://openalex.org/W1913627016",
      "https://openalex.org/W2004864148",
      "https://openalex.org/W2016730668",
      "https://openalex.org/W2032254851",
      "https://openalex.org/W2038570053",
      "https://openalex.org/W2045565604",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2079725295",
      "https://openalex.org/W2085662862",
      "https://openalex.org/W2098689807",
      "https://openalex.org/W2098872617",
      "https://openalex.org/W2108598243",
      "https://openalex.org/W2109020278",
      "https://openalex.org/W2110450943",
      "https://openalex.org/W2122563357",
      "https://openalex.org/W2124141504",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2146334809",
      "https://openalex.org/W2166637769",
      "https://openalex.org/W2194775991",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2397375888",
      "https://openalex.org/W2556418146",
      "https://openalex.org/W2573626026",
      "https://openalex.org/W2703895418",
      "https://openalex.org/W2739871800",
      "https://openalex.org/W2740550900",
      "https://openalex.org/W2757599232",
      "https://openalex.org/W2772633765",
      "https://openalex.org/W2796830519",
      "https://openalex.org/W2805005636",
      "https://openalex.org/W2809286861",
      "https://openalex.org/W2883409523",
      "https://openalex.org/W2917937435",
      "https://openalex.org/W2918189006",
      "https://openalex.org/W2931751229",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2963349408",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963686995",
      "https://openalex.org/W2963765493",
      "https://openalex.org/W2964089584",
      "https://openalex.org/W2971770322",
      "https://openalex.org/W2978127603",
      "https://openalex.org/W3100146208",
      "https://openalex.org/W3163340360",
      "https://openalex.org/W4239031955",
      "https://openalex.org/W4239072543",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "The task of Dialogue Act Classification (DAC) that purports to capture communicative intent has been studied extensively. But these studies limit themselves to text. Non-verbal features (change of tone, facial expressions etc.) can provide cues to identify DAs, thus stressing the benefit of incorporating multi-modal inputs in the task. Also, the emotional state of the speaker has a substantial effect on the choice of the dialogue act, since conversations are often influenced by emotions. Hence, the effect of emotion too on automatic identification of DAs needs to be studied. In this work, we address the role of both multi-modality and emotion recognition (ER) in DAC. DAC and ER help each other by way of multi-task learning. One of the major contributions of this work is a new dataset- multimodal Emotion aware Dialogue Act dataset called EMOTyDA, collected from open-sourced dialogue datasets. To demonstrate the utility of EMOTyDA, we build an attention based (self, inter-modal, inter-task) multi-modal, multi-task Deep Neural Network (DNN) for joint learning of DAs and emotions. We show empirically that multi-modality and multi-tasking achieve better performance of DAC compared to uni-modal and single task DAC variants.",
    "match_score": 1.0
  },
  "Dialogue focus tracking for zero pronoun resolution": {
    "openalex_id": "https://openalex.org/W2296330515",
    "publication_year": 2015,
    "cited_by_count": 18,
    "referenced_works": [
      "https://openalex.org/W108437174",
      "https://openalex.org/W113130591",
      "https://openalex.org/W158043429",
      "https://openalex.org/W204341599",
      "https://openalex.org/W239563548",
      "https://openalex.org/W1581527173",
      "https://openalex.org/W1931054966",
      "https://openalex.org/W2088911157",
      "https://openalex.org/W2111889471",
      "https://openalex.org/W2124741472",
      "https://openalex.org/W2133258739",
      "https://openalex.org/W2135819134",
      "https://openalex.org/W2136925175",
      "https://openalex.org/W2158349948",
      "https://openalex.org/W2250555572",
      "https://openalex.org/W2251229550",
      "https://openalex.org/W2397240125",
      "https://openalex.org/W2962957031"
    ],
    "abstract": "We take a novel approach to zero pronoun resolution in Chinese: our model explicitly tracks the flow of focus in a discourse. Our approach, which generalizes to deictic references, is not reliant on the presence of overt noun phrase antecedents to resolve to, and allows us to address the large percentage of \u201cnon-anaphoric\u201d pronouns filtered out in other approaches. We furthermore train our model using readily available parallel Chinese/English corpora, allowing for training without hand-annotated data. Our results demonstrate improvements on two test sets, as well as the usefulness of linguistically motivated features.",
    "match_score": 1.0
  },
  "Scalable and Accurate Dialogue State Tracking via Hierarchical Sequence Generation": {
    "openalex_id": "https://openalex.org/W2970404807",
    "publication_year": 2019,
    "cited_by_count": 99,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1677182931",
      "https://openalex.org/W1793121960",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2785523195",
      "https://openalex.org/W2804010326",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2950635152",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2962739339",
      "https://openalex.org/W2962784628",
      "https://openalex.org/W2962847367",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963248507",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963907629",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2964101377",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W4289147179"
    ],
    "abstract": "Liliang Ren, Jianmo Ni, Julian McAuley. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "Sampling Matters! An Empirical Study of Negative Sampling Strategies for Learning of Matching Models in Retrieval-based Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2971190479",
    "publication_year": 2019,
    "cited_by_count": 33,
    "referenced_works": [
      "https://openalex.org/W295828404",
      "https://openalex.org/W1551842868",
      "https://openalex.org/W2086511124",
      "https://openalex.org/W2102531443",
      "https://openalex.org/W2339852062",
      "https://openalex.org/W2395531022",
      "https://openalex.org/W2539338396",
      "https://openalex.org/W2561368124",
      "https://openalex.org/W2748668722",
      "https://openalex.org/W2774267535",
      "https://openalex.org/W2782368579",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2949446780",
      "https://openalex.org/W2952813980",
      "https://openalex.org/W2962768358",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2963161823",
      "https://openalex.org/W2977304374",
      "https://openalex.org/W4300125564"
    ],
    "abstract": "Jia Li, Chongyang Tao, Wei Wu, Yansong Feng, Dongyan Zhao, Rui Yan. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.",
    "match_score": 1.0
  },
  "Adaptive Parameterization for Neural Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2977149219",
    "publication_year": 2019,
    "cited_by_count": 9,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2187089797",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2399880602",
      "https://openalex.org/W2435450765",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2593696076",
      "https://openalex.org/W2606712314",
      "https://openalex.org/W2615146352",
      "https://openalex.org/W2621133045",
      "https://openalex.org/W2626778328",
      "https://openalex.org/W2743149734",
      "https://openalex.org/W2757121784",
      "https://openalex.org/W2789033601",
      "https://openalex.org/W2798385473",
      "https://openalex.org/W2804255934",
      "https://openalex.org/W2888456631",
      "https://openalex.org/W2940154139",
      "https://openalex.org/W2949888546",
      "https://openalex.org/W2950037544",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962755817",
      "https://openalex.org/W2962810352",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963223306",
      "https://openalex.org/W2963332597",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963411289",
      "https://openalex.org/W2963469850",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963958388",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964119254",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Neural conversation systems generate responses based on the sequence-to-sequence (SEQ2SEQ) paradigm. Typically, the model is equipped with a single set of learned parameters to generate responses for given input contexts. When confronting diverse conversations, its adaptability is rather limited and the model is hence prone to generate generic responses. In this work, we propose an {\\bf Ada}ptive {\\bf N}eural {\\bf D}ialogue generation model, \\textsc{AdaND}, which manages various conversations with conversation-specific parameterization. For each conversation, the model generates parameters of the encoder-decoder by referring to the input context. In particular, we propose two adaptive parameterization mechanisms: a context-aware and a topic-aware parameterization mechanism. The context-aware parameterization directly generates the parameters by capturing local semantics of the given context. The topic-aware parameterization enables parameter sharing among conversations with similar topics by first inferring the latent topics of the given context and then generating the parameters with respect to the distributional topics. Extensive experiments conducted on a large-scale real-world conversational dataset show that our model achieves superior performance in terms of both quantitative metrics and human evaluations.",
    "match_score": 1.0
  },
  "Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue Models": {
    "openalex_id": "https://openalex.org/W2890719433",
    "publication_year": 2018,
    "cited_by_count": 62,
    "referenced_works": [
      "https://openalex.org/W1525961042",
      "https://openalex.org/W1645476387",
      "https://openalex.org/W1673923490",
      "https://openalex.org/W1945616565",
      "https://openalex.org/W1995945562",
      "https://openalex.org/W2016522586",
      "https://openalex.org/W2112507308",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2144960104",
      "https://openalex.org/W2155250282",
      "https://openalex.org/W2180612164",
      "https://openalex.org/W2251882135",
      "https://openalex.org/W2293844262",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2402144811",
      "https://openalex.org/W2418993857",
      "https://openalex.org/W2561498661",
      "https://openalex.org/W2570685808",
      "https://openalex.org/W2571175805",
      "https://openalex.org/W2594590228",
      "https://openalex.org/W2603766943",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2609368435",
      "https://openalex.org/W2612675303",
      "https://openalex.org/W2619479788",
      "https://openalex.org/W2735135478",
      "https://openalex.org/W2766108848",
      "https://openalex.org/W2767899794",
      "https://openalex.org/W2770626128",
      "https://openalex.org/W2772621923",
      "https://openalex.org/W2774961896",
      "https://openalex.org/W2796084947",
      "https://openalex.org/W2953384591",
      "https://openalex.org/W2962707484",
      "https://openalex.org/W2962713901",
      "https://openalex.org/W2962784628",
      "https://openalex.org/W2962790689",
      "https://openalex.org/W2962818281",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963109634",
      "https://openalex.org/W2963123621",
      "https://openalex.org/W2963126845",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963207607",
      "https://openalex.org/W2963217826",
      "https://openalex.org/W2963564844",
      "https://openalex.org/W2963661177",
      "https://openalex.org/W2963768805",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963919731",
      "https://openalex.org/W2963969878",
      "https://openalex.org/W2964153729",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3193304830",
      "https://openalex.org/W4294410794",
      "https://openalex.org/W4310299640"
    ],
    "abstract": "We present two categories of model-agnostic adversarial strategies that reveal the weaknesses of several generative, task-oriented dialogue models: Should-Not-Change strategies that evaluate over-sensitivity to small and semantics-preserving edits, as well as Should-Change strategies that test if a model is over-stable against subtle yet semantics-changing modifications. We next perform adversarial training with each strategy, employing a max-margin approach for negative generative examples. This not only makes the target dialogue model more robust to the adversarial inputs, but also helps it perform significantly better on the original inputs. Moreover, training on all strategies combined achieves further improvements, achieving a new state-of-the-art performance on the original task (also verified via human evaluation). In addition to adversarial training, we also address the robustness task at the model-level, by feeding it subword units as both inputs and outputs, and show that the resulting model is equally competitive, requires only 1/4 of the original vocabulary size, and is robust to one of the adversarial strategies (to which the original model is vulnerable) even without adversarial training.",
    "match_score": 1.0
  },
  "Reading Turn by Turn Hierarchical Attention Architecture for Spoken Dialogue Comprehension": {
    "openalex_id": "https://openalex.org/W2951855948",
    "publication_year": 2019,
    "cited_by_count": 23,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1533504578",
      "https://openalex.org/W1544827683",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2097127032",
      "https://openalex.org/W2131774270",
      "https://openalex.org/W2153190547",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2470673105",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2516930406",
      "https://openalex.org/W2551396370",
      "https://openalex.org/W2562607067",
      "https://openalex.org/W2740747242",
      "https://openalex.org/W2741263286",
      "https://openalex.org/W2804243436",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2912904516",
      "https://openalex.org/W2949615363",
      "https://openalex.org/W2962739339",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963080779",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963545005",
      "https://openalex.org/W2963547127",
      "https://openalex.org/W2963748441",
      "https://openalex.org/W2963795756",
      "https://openalex.org/W2963963993",
      "https://openalex.org/W2963969878",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W4248634141",
      "https://openalex.org/W4288614645",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Comprehending multi-turn spoken conversations is an emerging research area, presenting challenges different from reading comprehension of passages due to the interactive nature of information exchange from at least two speakers. Unlike passages, where sentences are often the default semantic modeling unit, in multi-turn conversations, a turn is a topically coherent unit embodied with immediately relevant context, making it a linguistically intuitive segment for computationally modeling verbal interactions. Therefore, in this work, we propose a hierarchical attention neural network architecture, combining turn-level and word-level attention mechanisms, to improve spoken dialogue comprehension performance. Experiments are conducted on a multi-turn conversation dataset, where nurses inquire and discuss symptom information with patients. We empirically show that the proposed approach outperforms standard attention baselines, achieves more efficient learning outcomes, and is more robust to lengthy and out-of-distribution test samples.",
    "match_score": 0.994475138121547
  },
  "MinTL Minimalist Transfer Learning for Task-Oriented Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3100128199",
    "publication_year": 2020,
    "cited_by_count": 136,
    "referenced_works": [
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2914120296",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2923014074",
      "https://openalex.org/W2945260553",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2953071719",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963310665",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963748441",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963925437",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2965373594",
      "https://openalex.org/W2969708789",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2970597249",
      "https://openalex.org/W2971274815",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2979520138",
      "https://openalex.org/W2980207396",
      "https://openalex.org/W2980282514",
      "https://openalex.org/W2982482202",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W2988647680",
      "https://openalex.org/W2988937804",
      "https://openalex.org/W2996317432",
      "https://openalex.org/W2997108628",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W2999134550",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3008966357",
      "https://openalex.org/W3011411500",
      "https://openalex.org/W3016625483",
      "https://openalex.org/W3021016503",
      "https://openalex.org/W3023786569",
      "https://openalex.org/W3024509506",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3082274269",
      "https://openalex.org/W3082549344",
      "https://openalex.org/W3100110884",
      "https://openalex.org/W3103616906",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W3155584966",
      "https://openalex.org/W4287795696",
      "https://openalex.org/W4287900772",
      "https://openalex.org/W4288027128",
      "https://openalex.org/W4288087450",
      "https://openalex.org/W4288089799",
      "https://openalex.org/W4288094254",
      "https://openalex.org/W4288624561",
      "https://openalex.org/W4289147179",
      "https://openalex.org/W4295249402"
    ],
    "abstract": "In this paper, we propose Minimalist Transfer Learning (MinTL) to simplify the system design process of task-oriented dialogue systems and alleviate the over-dependency on annotated data. MinTL is a simple yet effective transfer learning framework, which allows us to plug-and-play pre-trained seq2seq models, and jointly learn dialogue state tracking and dialogue response generation. Unlike previous approaches, which use a copy mechanism to \u201ccarryover\u201d the old dialogue states to the new one, we introduce Levenshtein belief spans (Lev), that allows efficient dialogue state tracking with a minimal generation length. We instantiate our learning framework with two pre-trained backbones: T5 and BART, and evaluate them on MultiWOZ. Extensive experiments demonstrate that: 1) our systems establish new state-of-the-art results on end-to-end response generation, 2) MinTL-based systems are more robust than baseline methods in the low resource setting, and they achieve competitive results with only 20% training data, and 3) Lev greatly improves the inference efficiency.",
    "match_score": 0.9928057553956835
  },
  "One Time of Interaction May Not Be Enough Go Deep with an Interaction-over-Interaction Network for Response Selection in Dialogues": {
    "openalex_id": "https://openalex.org/W2952813980",
    "publication_year": 2019,
    "cited_by_count": 146,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1924770834",
      "https://openalex.org/W2097117768",
      "https://openalex.org/W2102531443",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2163605009",
      "https://openalex.org/W2170738476",
      "https://openalex.org/W2194775991",
      "https://openalex.org/W2197546379",
      "https://openalex.org/W2338325072",
      "https://openalex.org/W2339852062",
      "https://openalex.org/W2395531022",
      "https://openalex.org/W2521114121",
      "https://openalex.org/W2561368124",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2767802162",
      "https://openalex.org/W2770970123",
      "https://openalex.org/W2786983967",
      "https://openalex.org/W2798456655",
      "https://openalex.org/W2807880213",
      "https://openalex.org/W2809210859",
      "https://openalex.org/W2889581211",
      "https://openalex.org/W2891416139",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2949446780",
      "https://openalex.org/W2951359136",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962739339",
      "https://openalex.org/W2962768358",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2962838727",
      "https://openalex.org/W2962854379",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963446712",
      "https://openalex.org/W2963522640",
      "https://openalex.org/W2963542836",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2963986868",
      "https://openalex.org/W2964046515",
      "https://openalex.org/W2964082993",
      "https://openalex.org/W2964092386",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964150246",
      "https://openalex.org/W2964309167",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W4294170691",
      "https://openalex.org/W4300687842",
      "https://openalex.org/W4394666973"
    ],
    "abstract": "Currently, researchers have paid great attention to retrieval-based dialogues in open-domain. In particular, people study the problem by investigating context-response matching for multi-turn response selection based on publicly recognized benchmark data sets. State-of-the-art methods require a response to interact with each utterance in a context from the beginning, but the interaction is performed in a shallow way. In this work, we let utterance-response interaction go deep by proposing an interaction-over-interaction network (IoI). The model performs matching by stacking multiple interaction blocks in which residual information from one time of interaction initiates the interaction process again. Thus, matching information within an utterance-response pair is extracted from the interaction of the pair in an iterative fashion, and the information flows along the chain of the blocks via representations. Evaluation results on three benchmark data sets indicate that IoI can significantly outperform state-of-the-art methods in terms of various matching metrics. Through further analysis, we also unveil how the depth of interaction affects the performance of IoI.",
    "match_score": 0.9961685823754789
  },
  "An End-to-end Approach for Handling Unknown Slot Values in Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W2963283951",
    "publication_year": 2018,
    "cited_by_count": 149,
    "referenced_works": [
      "https://openalex.org/W648947103",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1904365287",
      "https://openalex.org/W2115090890",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251163406",
      "https://openalex.org/W2251235149",
      "https://openalex.org/W2396928039",
      "https://openalex.org/W2412715517",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2516930406",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2772001136",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2962776342",
      "https://openalex.org/W2962847367",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2962944953",
      "https://openalex.org/W2963068985",
      "https://openalex.org/W2963243930",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W3037881859",
      "https://openalex.org/W4295249402"
    ],
    "abstract": "We highlight a practical yet rarely discussed problem in dialogue state tracking (DST), namely handling unknown slot values. Previous approaches generally assume predefined candidate lists and thus are not designed to output unknown values, especially when the spoken language understanding (SLU) module is absent as in many end-to-end (E2E) systems. We describe in this paper an E2E architecture based on the pointer network (PtrNet) that can effectively extract unknown slot values while still obtains state-of-the-art accuracy on the standard DSTC2 benchmark. We also provide extensive empirical evidence to show that tracking unknown values can be challenging and our approach can bring significant improvement with the help of an effective feature dropout technique.",
    "match_score": 1.0
  },
  "Learning to Plan and Realize Separately for Open-Ended Dialogue Systems": {
    "openalex_id": "https://openalex.org/W3088955686",
    "publication_year": 2020,
    "cited_by_count": 0,
    "referenced_works": [
      "https://openalex.org/W1645937837",
      "https://openalex.org/W1887590894",
      "https://openalex.org/W1956340063",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2033334263",
      "https://openalex.org/W2057452878",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2109878893",
      "https://openalex.org/W2111140836",
      "https://openalex.org/W2119930118",
      "https://openalex.org/W2123301721",
      "https://openalex.org/W2123442489",
      "https://openalex.org/W2127979034",
      "https://openalex.org/W2128076956",
      "https://openalex.org/W2128970689",
      "https://openalex.org/W2137076533",
      "https://openalex.org/W2141403362",
      "https://openalex.org/W2153190547",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2479110610",
      "https://openalex.org/W2498260772",
      "https://openalex.org/W2594125959",
      "https://openalex.org/W2617907584",
      "https://openalex.org/W2729046720",
      "https://openalex.org/W2739874095",
      "https://openalex.org/W2774104751",
      "https://openalex.org/W2785702304",
      "https://openalex.org/W2793978524",
      "https://openalex.org/W2798664956",
      "https://openalex.org/W2874826521",
      "https://openalex.org/W2890581450",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2914204778",
      "https://openalex.org/W2935206035",
      "https://openalex.org/W2949417144",
      "https://openalex.org/W2951560313",
      "https://openalex.org/W2952098430",
      "https://openalex.org/W2952607215",
      "https://openalex.org/W2953039584",
      "https://openalex.org/W2962676842",
      "https://openalex.org/W2962784628",
      "https://openalex.org/W2963170138",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963212250",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963592583",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W2967853777",
      "https://openalex.org/W2970072000",
      "https://openalex.org/W2970252402",
      "https://openalex.org/W2970597249",
      "https://openalex.org/W2973049837",
      "https://openalex.org/W2985891764",
      "https://openalex.org/W2990141119",
      "https://openalex.org/W2996287690",
      "https://openalex.org/W2996403597",
      "https://openalex.org/W2996614149",
      "https://openalex.org/W3007723711",
      "https://openalex.org/W3032777814",
      "https://openalex.org/W3102195370"
    ],
    "abstract": "Achieving true human-like ability to conduct a conversation remains an elusive goal for open-ended dialogue systems. We posit this is because extant approaches towards natural language generation (NLG) are typically construed as end-to-end architectures that do not adequately model human generation processes. To investigate, we decouple generation into two separate phases: planning and realization. In the planning phase, we train two planners to generate plans for response utterances. The realization phase uses response plans to produce an appropriate response. Through rigorous evaluations, both automated and human, we demonstrate that decoupling the process into planning and realization performs better than an end-to-end approach.",
    "match_score": 1.0
  },
  "DeepPavlov Open-Source Library for Dialogue Systems": {
    "openalex_id": "https://openalex.org/W2803728898",
    "publication_year": 2018,
    "cited_by_count": 155,
    "referenced_works": [
      "https://openalex.org/W1832693441",
      "https://openalex.org/W2024490156",
      "https://openalex.org/W2057900969",
      "https://openalex.org/W2123442489",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2293004735",
      "https://openalex.org/W2404126548",
      "https://openalex.org/W2562335618",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2812722839",
      "https://openalex.org/W2899771611",
      "https://openalex.org/W2951642864",
      "https://openalex.org/W2962886331",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2963140597",
      "https://openalex.org/W2963625095",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964263551",
      "https://openalex.org/W3121541553",
      "https://openalex.org/W4295249402"
    ],
    "abstract": "Mikhail Burtsev, Alexander Seliverstov, Rafael Airapetyan, Mikhail Arkhipov, Dilyara Baymurzina, Nickolay Bushkov, Olga Gureenkova, Taras Khakhulin, Yuri Kuratov, Denis Kuznetsov, Alexey Litinsky, Varvara Logacheva, Alexey Lymar, Valentin Malykh, Maxim Petrov, Vadim Polulyakh, Leonid Pugachev, Alexey Sorokin, Maria Vikhreva, Marat Zaynutdinov. Proceedings of ACL 2018, System Demonstrations. 2018.",
    "match_score": 0.9902912621359223
  },
  "Learning the Information Status of Noun Phrases in Spoken Dialogues": {
    "openalex_id": "https://openalex.org/W2176271827",
    "publication_year": 2011,
    "cited_by_count": 14,
    "referenced_works": [
      "https://openalex.org/W101214240",
      "https://openalex.org/W1547546052",
      "https://openalex.org/W1567277581",
      "https://openalex.org/W1570601904",
      "https://openalex.org/W1576504150",
      "https://openalex.org/W1576520375",
      "https://openalex.org/W1585753929",
      "https://openalex.org/W1965206833",
      "https://openalex.org/W1981082061",
      "https://openalex.org/W1982246600",
      "https://openalex.org/W2029639339",
      "https://openalex.org/W2042609668",
      "https://openalex.org/W2067982155",
      "https://openalex.org/W2075011505",
      "https://openalex.org/W2083905610",
      "https://openalex.org/W2089654579",
      "https://openalex.org/W2098345921",
      "https://openalex.org/W2107232048",
      "https://openalex.org/W2113310984",
      "https://openalex.org/W2116786260",
      "https://openalex.org/W2124700572",
      "https://openalex.org/W2127713198",
      "https://openalex.org/W2129665406",
      "https://openalex.org/W2130031580",
      "https://openalex.org/W2131340601",
      "https://openalex.org/W2131554698",
      "https://openalex.org/W2144087279",
      "https://openalex.org/W2145020046",
      "https://openalex.org/W2164455818",
      "https://openalex.org/W2169789327",
      "https://openalex.org/W2171828761",
      "https://openalex.org/W2222512263",
      "https://openalex.org/W2295547137",
      "https://openalex.org/W2475711339",
      "https://openalex.org/W3011367699",
      "https://openalex.org/W3023431232",
      "https://openalex.org/W3135387542"
    ],
    "abstract": "An entity in a dialogue may be old, new, or mediated/inferrable with respect to the hearer\u2019s beliefs. Knowing the information status of the entities participating in a dialogue can therefore facilitate its interpretation. We address the under-investigated problem of automatically determining the information status of discourse entities. Specifically, we extend Nissim\u2019s (2006) machine learning approach to information-status determination with lexical and structured features, and exploit learned knowledge of the information status of each discourse entity for coreference resolution. Experimental results on a set of Switchboard dialogues reveal that (1) incorporating our proposed features into Nissim\u2019s feature set enables our system to achieve stateof-the-art performance on information-status classification, and (2) the resulting information can be used to improve the performance of learning-based coreference resolvers. 1",
    "match_score": 1.0
  },
  "Dialogue Distillation Open-Domain Dialogue Augmentation Using Unpaired Data": {
    "openalex_id": "https://openalex.org/W3099890447",
    "publication_year": 2020,
    "cited_by_count": 25,
    "referenced_works": [
      "https://openalex.org/W112197792",
      "https://openalex.org/W222053410",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1821462560",
      "https://openalex.org/W2128892113",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2611029872",
      "https://openalex.org/W2804047946",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2808437126",
      "https://openalex.org/W2889681790",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2904444765",
      "https://openalex.org/W2911994530",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2953039584",
      "https://openalex.org/W2962796276",
      "https://openalex.org/W2963201498",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963216553",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963371754",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963521540",
      "https://openalex.org/W2963544700",
      "https://openalex.org/W2963564796",
      "https://openalex.org/W2963691849",
      "https://openalex.org/W2963736842",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2964309167",
      "https://openalex.org/W2971296908",
      "https://openalex.org/W2997892440",
      "https://openalex.org/W3014773921",
      "https://openalex.org/W3015322406",
      "https://openalex.org/W3035072597",
      "https://openalex.org/W3035148359",
      "https://openalex.org/W3035282664",
      "https://openalex.org/W3093956460",
      "https://openalex.org/W3097517997",
      "https://openalex.org/W3104078590",
      "https://openalex.org/W4295253143",
      "https://openalex.org/W4295727797",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Recent advances in open-domain dialogue systems rely on the success of neural models that are trained on large-scale data. However, collecting large-scale dialogue data is usually time-consuming and labor-intensive. To address this data dilemma, we propose a novel data augmentation method for training open-domain dialogue models by utilizing unpaired data. Specifically, a data-level distillation process is first proposed to construct augmented dialogues where both post and response are retrieved from the unpaired data. A ranking module is employed to filter out low-quality dialogues. Further, a model-level distillation process is employed to distill a teacher model trained on high-quality paired data to augmented dialogue pairs, thereby preventing dialogue models from being affected by the noise in the augmented data. Automatic and manual evaluation indicates that our method can produce high-quality dialogue pairs with diverse contents, and the proposed data-level and model-level dialogue distillation can improve the performance of competitive baselines.",
    "match_score": 0.9933774834437086
  },
  "FERNet Fine-grained Extraction and Reasoning Network for Emotion Recognition in Dialogues": {
    "openalex_id": "https://openalex.org/W3117170115",
    "publication_year": 2020,
    "cited_by_count": 1,
    "referenced_works": [
      "https://openalex.org/W1832693441",
      "https://openalex.org/W2051840895",
      "https://openalex.org/W2092206588",
      "https://openalex.org/W2146334809",
      "https://openalex.org/W2163605009",
      "https://openalex.org/W2194775991",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2250966211",
      "https://openalex.org/W2470673105",
      "https://openalex.org/W2563010554",
      "https://openalex.org/W2740550900",
      "https://openalex.org/W2805662932",
      "https://openalex.org/W2886757387",
      "https://openalex.org/W2887030499",
      "https://openalex.org/W2891359673",
      "https://openalex.org/W2905807898",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2953739332",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963520511",
      "https://openalex.org/W2963626623",
      "https://openalex.org/W2963920114",
      "https://openalex.org/W2964230360",
      "https://openalex.org/W2964300796",
      "https://openalex.org/W3205498744"
    ],
    "abstract": "Unlike non-conversation scenes, emotion recognition in dialogues (ERD) poses more complicated challenges due to its interactive nature and intricate contextual information. All present methods model historical utterances without considering the content of the target utterance. However, different parts of a historical utterance may contribute differently to emotion inference of different target utterances. Therefore we propose Fine-grained Extraction and Reasoning Network (FERNet) to generate target-specific historical utterance representations. The reasoning module effectively handles both local and global sequential dependencies to reason over context, and updates target utterance representations to more informed vectors. Experiments on two benchmarks show that our method achieves competitive performance compared with previous methods.",
    "match_score": 0.994413407821229
  },
  "MultiDM-GCN Aspect-guided Response Generation in Multi-domain Multi-modal Dialogue System using Graph Convolutional Network": {
    "openalex_id": "https://openalex.org/W3101319477",
    "publication_year": 2020,
    "cited_by_count": 17,
    "referenced_works": [
      "https://openalex.org/W1494910745",
      "https://openalex.org/W1533861849",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1686810756",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1975879668",
      "https://openalex.org/W1993378086",
      "https://openalex.org/W2016589492",
      "https://openalex.org/W2062989416",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2154652894",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2183341477",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2558809543",
      "https://openalex.org/W2583186419",
      "https://openalex.org/W2768661419",
      "https://openalex.org/W2785523195",
      "https://openalex.org/W2871584425",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2897182555",
      "https://openalex.org/W2944887439",
      "https://openalex.org/W2948742685",
      "https://openalex.org/W2950009015",
      "https://openalex.org/W2951450739",
      "https://openalex.org/W2951980657",
      "https://openalex.org/W2952723239",
      "https://openalex.org/W2953071719",
      "https://openalex.org/W2953251345",
      "https://openalex.org/W2956125353",
      "https://openalex.org/W2962764403",
      "https://openalex.org/W2962814079",
      "https://openalex.org/W2962835968",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963248455",
      "https://openalex.org/W2963287297",
      "https://openalex.org/W2963748384",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964011461",
      "https://openalex.org/W2964588180",
      "https://openalex.org/W2969576497",
      "https://openalex.org/W2971261034",
      "https://openalex.org/W2972603547",
      "https://openalex.org/W2985891764",
      "https://openalex.org/W2988647680",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3106274079",
      "https://openalex.org/W4286749334",
      "https://openalex.org/W4297728544"
    ],
    "abstract": "In the recent past, dialogue systems have gained immense popularity and have become ubiquitous. During conversations, humans not only rely on languages but seek contextual information through visual contents as well. In every task-oriented dialogue system, the user is guided by the different aspects of a product or service that regulates the conversation towards selecting the product or service. In this work, we present a multi-modal conversational framework for a task-oriented dialogue setup that generates the responses following the different aspects of a product or service to cater to the user\u2019s needs. We show that the responses guided by the aspect information provide more interactive and informative responses for better communication between the agent and the user. We first create a Multi-domain Multi-modal Dialogue (MDMMD) dataset having conversations involving both text and images belonging to the three different domains, such as restaurants, electronics, and furniture. We implement a Graph Convolutional Network (GCN) based framework that generates appropriate textual responses from the multi-modal inputs. The multi-modal information having both textual and image representation is fed to the decoder and the aspect information for generating aspect guided responses. Quantitative and qualitative analyses show that the proposed methodology outperforms several baselines for the proposed task of aspect-guided response generation.",
    "match_score": 0.9959514170040485
  },
  "Single-Agent vs. Multi-Agent Techniques for Concurrent Reinforcement Learning of Negotiation Dialogue Policies": {
    "openalex_id": "https://openalex.org/W2152342063",
    "publication_year": 2014,
    "cited_by_count": 32,
    "referenced_works": [
      "https://openalex.org/W62710299",
      "https://openalex.org/W311892248",
      "https://openalex.org/W1211946649",
      "https://openalex.org/W1513468570",
      "https://openalex.org/W1524881148",
      "https://openalex.org/W1542941925",
      "https://openalex.org/W1681299129",
      "https://openalex.org/W1746819321",
      "https://openalex.org/W1987326241",
      "https://openalex.org/W1999874108",
      "https://openalex.org/W2001050921",
      "https://openalex.org/W2021151961",
      "https://openalex.org/W2035934535",
      "https://openalex.org/W2037897789",
      "https://openalex.org/W2054716580",
      "https://openalex.org/W2056894129",
      "https://openalex.org/W2084799336",
      "https://openalex.org/W2099618002",
      "https://openalex.org/W2101445408",
      "https://openalex.org/W2104602264",
      "https://openalex.org/W2105715011",
      "https://openalex.org/W2109038907",
      "https://openalex.org/W2113033979",
      "https://openalex.org/W2115714256",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2120327309",
      "https://openalex.org/W2121863487",
      "https://openalex.org/W2142831953",
      "https://openalex.org/W2153672931",
      "https://openalex.org/W2156974606",
      "https://openalex.org/W2168490009",
      "https://openalex.org/W2169430966",
      "https://openalex.org/W2171079152",
      "https://openalex.org/W2231198303",
      "https://openalex.org/W2246008130",
      "https://openalex.org/W2250245054",
      "https://openalex.org/W2250681874",
      "https://openalex.org/W2312609093",
      "https://openalex.org/W2401150877",
      "https://openalex.org/W2586680856",
      "https://openalex.org/W3158638686",
      "https://openalex.org/W4211049957",
      "https://openalex.org/W4214717370",
      "https://openalex.org/W4285719527"
    ],
    "abstract": "We use single-agent and multi-agent Reinforcement Learning (RL) for learning dialogue policies in a resource allocation negotiation scenario.Two agents learn concurrently by interacting with each other without any need for simulated users (SUs) to train against or corpora to learn from.In particular, we compare the Qlearning, Policy Hill-Climbing (PHC) and Win or Learn Fast Policy Hill-Climbing (PHC-WoLF) algorithms, varying the scenario complexity (state space size), the number of training episodes, the learning rate, and the exploration rate.Our results show that generally Q-learning fails to converge whereas PHC and PHC-WoLF always converge and perform similarly.We also show that very high gradually decreasing exploration rates are required for convergence.We conclude that multiagent RL of dialogue policies is a promising alternative to using single-agent RL and SUs or learning directly from corpora.",
    "match_score": 1.0
  },
  "Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems": {
    "openalex_id": "https://openalex.org/W1948566616",
    "publication_year": 2015,
    "cited_by_count": 838,
    "referenced_works": [
      "https://openalex.org/W179875071",
      "https://openalex.org/W196214544",
      "https://openalex.org/W225503657",
      "https://openalex.org/W1492935830",
      "https://openalex.org/W1521413921",
      "https://openalex.org/W1534317862",
      "https://openalex.org/W1552182777",
      "https://openalex.org/W1591801644",
      "https://openalex.org/W1606347560",
      "https://openalex.org/W1810943226",
      "https://openalex.org/W1905882502",
      "https://openalex.org/W1917215959",
      "https://openalex.org/W1947758080",
      "https://openalex.org/W1970207841",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1980340273",
      "https://openalex.org/W1999965501",
      "https://openalex.org/W2004637830",
      "https://openalex.org/W2018116724",
      "https://openalex.org/W2024632416",
      "https://openalex.org/W2045738181",
      "https://openalex.org/W2050523636",
      "https://openalex.org/W2055537935",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2099542783",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2104368104",
      "https://openalex.org/W2107878631",
      "https://openalex.org/W2108239140",
      "https://openalex.org/W2110313598",
      "https://openalex.org/W2115221470",
      "https://openalex.org/W2117130368",
      "https://openalex.org/W2122514299",
      "https://openalex.org/W2122585011",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2131774270",
      "https://openalex.org/W2135363470",
      "https://openalex.org/W2136016850",
      "https://openalex.org/W2139079654",
      "https://openalex.org/W2143612262",
      "https://openalex.org/W2150355110",
      "https://openalex.org/W2160815625",
      "https://openalex.org/W2161181481",
      "https://openalex.org/W2171928131",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2257626115",
      "https://openalex.org/W2474824677",
      "https://openalex.org/W2949888546",
      "https://openalex.org/W2950527759",
      "https://openalex.org/W2951176429",
      "https://openalex.org/W4233573184",
      "https://openalex.org/W4292763141",
      "https://openalex.org/W4303633609"
    ],
    "abstract": "Natural language generation (NLG) is a critical component of spoken dialogue and it has a significant impact both on usability and perceived quality.Most NLG systems in common use employ rules and heuristics and tend to generate rigid and stylised responses without the natural variation of human language.They are also not easily scaled to systems covering multiple domains and languages.This paper presents a statistical language generator based on a semantically controlled Long Short-term Memory (LSTM) structure.The LSTM generator can learn from unaligned data by jointly optimising sentence planning and surface realisation using a simple cross entropy training criterion, and language variation can be easily achieved by sampling from output candidates.With fewer heuristics, an objective evaluation in two differing test domains showed the proposed method improved performance compared to previous methods.Human judges scored the LSTM system higher on informativeness and naturalness and overall preferred it to the other systems.",
    "match_score": 1.0
  },
  "Chatbot with a Discourse Structure-Driven Dialogue Management": {
    "openalex_id": "https://openalex.org/W2740595206",
    "publication_year": 2017,
    "cited_by_count": 41,
    "referenced_works": [
      "https://openalex.org/W1886507901",
      "https://openalex.org/W2045738181",
      "https://openalex.org/W2056698510",
      "https://openalex.org/W2251211118",
      "https://openalex.org/W2252105888"
    ],
    "abstract": "We build a chat bot with iterative content exploration that leads a user through a personalized knowledge acquisition session. The chat bot is designed as an automated customer support or product recommendation agent assisting a user in learning product features, product usability, suitability, troubleshooting and other related tasks. To control the user navigation through content, we extend the notion of a linguistic discourse tree (DT) towards a set of documents with multiple sections covering a topic. For a given paragraph, a DT is built by DT parsers. We then combine DTs for the paragraphs of documents to form what we call extended DT, which is a basis for interactive content exploration facilitated by the chat bot. To provide cohesive answers, we use a measure of rhetoric agreement between a question and an answer by tree kernel learning of their DTs.",
    "match_score": 1.0
  },
  "Agent-Aware Dropout DQN for Safe and Efficient On-line Dialogue Policy Learning": {
    "openalex_id": "https://openalex.org/W2759104452",
    "publication_year": 2017,
    "cited_by_count": 37,
    "referenced_works": [
      "https://openalex.org/W52170320",
      "https://openalex.org/W99537330",
      "https://openalex.org/W582134693",
      "https://openalex.org/W1595483645",
      "https://openalex.org/W1757796397",
      "https://openalex.org/W1778387566",
      "https://openalex.org/W1904365287",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2021151961",
      "https://openalex.org/W2035934535",
      "https://openalex.org/W2047335008",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2095705004",
      "https://openalex.org/W2115101920",
      "https://openalex.org/W2122250135",
      "https://openalex.org/W2126810476",
      "https://openalex.org/W2145339207",
      "https://openalex.org/W2157797701",
      "https://openalex.org/W2164411961",
      "https://openalex.org/W2166550727",
      "https://openalex.org/W2168359464",
      "https://openalex.org/W2175723363",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2257979135",
      "https://openalex.org/W2280163991",
      "https://openalex.org/W2408200822",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2507592741",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2740191615",
      "https://openalex.org/W2962776342",
      "https://openalex.org/W2962996309",
      "https://openalex.org/W2963938771",
      "https://openalex.org/W2963993502",
      "https://openalex.org/W2963993719",
      "https://openalex.org/W2964044380",
      "https://openalex.org/W2964059111",
      "https://openalex.org/W4298857966"
    ],
    "abstract": "Hand-crafted rules and reinforcement learning (RL) are two popular choices to obtain dialogue policy. The rule-based policy is often reliable within predefined scope but not self-adaptable, whereas RL is evolvable with data but often suffers from a bad initial performance. We employ a companion learning framework to integrate the two approaches for on-line dialogue policy learning, in which a pre-defined rule-based policy acts as a \u201cteacher\u201d and guides a data-driven RL system by giving example actions as well as additional rewards. A novel agent-aware dropout Deep Q-Network (AAD-DQN) is proposed to address the problem of when to consult the teacher and how to learn from the teacher\u2019s experiences. AAD-DQN, as a data-driven student policy, provides (1) two separate experience memories for student and teacher, (2) an uncertainty estimated by dropout to control the timing of consultation and learning. Simulation experiments showed that the proposed approach can significantly improve both safetyand efficiency of on-line policy optimization compared to other companion learning approaches as well as supervised pre-training using static dialogue corpus.",
    "match_score": 1.0
  },
  "Conversation Model Fine-Tuning for Classifying Client Utterances in Counseling Dialogues": {
    "openalex_id": "https://openalex.org/W2927341038",
    "publication_year": 2019,
    "cited_by_count": 0,
    "referenced_works": [
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1832693441",
      "https://openalex.org/W1992178348",
      "https://openalex.org/W2000324202",
      "https://openalex.org/W2005139433",
      "https://openalex.org/W2113669296",
      "https://openalex.org/W2169110538",
      "https://openalex.org/W2186654215",
      "https://openalex.org/W2250497056",
      "https://openalex.org/W2250553926",
      "https://openalex.org/W2250883471",
      "https://openalex.org/W2251383488",
      "https://openalex.org/W2252128283",
      "https://openalex.org/W2314271279",
      "https://openalex.org/W2470673105",
      "https://openalex.org/W2489334776",
      "https://openalex.org/W2504061866",
      "https://openalex.org/W2512302303",
      "https://openalex.org/W2555428947",
      "https://openalex.org/W2613843855",
      "https://openalex.org/W2623779865",
      "https://openalex.org/W2624259507",
      "https://openalex.org/W2739681832",
      "https://openalex.org/W2739725258",
      "https://openalex.org/W2742148605",
      "https://openalex.org/W2761423999",
      "https://openalex.org/W2766236516",
      "https://openalex.org/W2798955519",
      "https://openalex.org/W2887657574",
      "https://openalex.org/W2890940245",
      "https://openalex.org/W2962832505",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2962964385",
      "https://openalex.org/W2963026768",
      "https://openalex.org/W2963261455",
      "https://openalex.org/W2963266340",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2964262738"
    ],
    "abstract": "The recent surge of text-based online counseling applications enables us to collect and analyze interactions between counselors and clients. A dataset of those interactions can be used to learn to automatically classify the client utterances into categories that help counselors in diagnosing client status and predicting counseling outcome. With proper anonymization, we collect counselor-client dialogues, define meaningful categories of client utterances with professional counselors, and develop a novel neural network model for classifying the client utterances. The central idea of our model, ConvMFiT, is a pre-trained conversation model which consists of a general language model built from an out-of-domain corpus and two role-specific language models built from unlabeled in-domain dialogues. The classification result shows that ConvMFiT outperforms state-of-the-art comparison models. Further, the attention weights in the learned model confirm that the model finds expected linguistic patterns for each category.",
    "match_score": 1.0
  },
  "Generalizable and Explainable Dialogue Generation via Explicit Action Learning": {
    "openalex_id": "https://openalex.org/W3103942726",
    "publication_year": 2020,
    "cited_by_count": 4,
    "referenced_works": [
      "https://openalex.org/W1793121960",
      "https://openalex.org/W1959608418",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2514480375",
      "https://openalex.org/W2547875792",
      "https://openalex.org/W2746626573",
      "https://openalex.org/W2780155557",
      "https://openalex.org/W2788403449",
      "https://openalex.org/W2798914047",
      "https://openalex.org/W2810840719",
      "https://openalex.org/W2891612330",
      "https://openalex.org/W2903396356",
      "https://openalex.org/W2903538854",
      "https://openalex.org/W2914442349",
      "https://openalex.org/W2915295540",
      "https://openalex.org/W2947182319",
      "https://openalex.org/W2949413855",
      "https://openalex.org/W2950662112",
      "https://openalex.org/W2951008357",
      "https://openalex.org/W2951725892",
      "https://openalex.org/W2953071719",
      "https://openalex.org/W2953073956",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2962858109",
      "https://openalex.org/W2962879001",
      "https://openalex.org/W2962912551",
      "https://openalex.org/W2963134326",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963411289",
      "https://openalex.org/W2963602293",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964158321",
      "https://openalex.org/W2964222296",
      "https://openalex.org/W2964332824",
      "https://openalex.org/W2970469901",
      "https://openalex.org/W2970786335",
      "https://openalex.org/W2970866659",
      "https://openalex.org/W2970909667",
      "https://openalex.org/W2996507500",
      "https://openalex.org/W2998201756",
      "https://openalex.org/W3034930293",
      "https://openalex.org/W3102521862",
      "https://openalex.org/W3102564565",
      "https://openalex.org/W4288245792",
      "https://openalex.org/W4288614963",
      "https://openalex.org/W4295720520",
      "https://openalex.org/W4297786749",
      "https://openalex.org/W4298393544",
      "https://openalex.org/W4306716473",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Response generation for task-oriented dialogues implicitly optimizes two objectives at the same time: task completion and language quality. Conditioned response generation serves as an effective approach to separately and better optimize these two objectives. Such an approach relies on system action annotations which are expensive to obtain. To alleviate the need of action annotations, latent action learning is introduced to map each utterance to a latent representation. However, this approach is prone to over-dependence on the training data, and the generalization capability is thus restricted. To address this issue, we propose to learn natural language actions that represent utterances as a span of words. This explicit action representation promotes generalization via the compositional structure of language. It also enables an explainable generation process. Our proposed unsupervised approach learns a memory component to summarize system utterances into a short span of words. To further promote a compact action representation, we propose an auxiliary task that restores state annotations as the summarized dialogue context using the memory component. Our proposed approach outperforms latent action baselines on MultiWOZ, a benchmark multi-domain dataset.",
    "match_score": 1.0
  },
  "Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access": {
    "openalex_id": "https://openalex.org/W2963068985",
    "publication_year": 2017,
    "cited_by_count": 299,
    "referenced_works": [
      "https://openalex.org/W91852349",
      "https://openalex.org/W119047706",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W2007807439",
      "https://openalex.org/W2024632416",
      "https://openalex.org/W2026505290",
      "https://openalex.org/W2046765929",
      "https://openalex.org/W2059157630",
      "https://openalex.org/W2062175565",
      "https://openalex.org/W2083205357",
      "https://openalex.org/W2099118758",
      "https://openalex.org/W2108682071",
      "https://openalex.org/W2116009284",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2128965063",
      "https://openalex.org/W2151814822",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2204302769",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2295953541",
      "https://openalex.org/W2412715517",
      "https://openalex.org/W2412899141",
      "https://openalex.org/W2473329891",
      "https://openalex.org/W2473965551",
      "https://openalex.org/W2551571666",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2807142242",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2950483141",
      "https://openalex.org/W2962682659",
      "https://openalex.org/W2962776342",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963412005",
      "https://openalex.org/W2963546833",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963974889",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W4238430687",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4298134534"
    ],
    "abstract": "Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, Li Deng. Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2017.",
    "match_score": 1.0
  },
  "Towards an Automatic Turing Test Learning to Evaluate Dialogue Responses": {
    "openalex_id": "https://openalex.org/W2741333084",
    "publication_year": 2017,
    "cited_by_count": 28,
    "referenced_works": [],
    "abstract": "Automatically evaluating the quality of dialogue responses for unstructured domains is a challenging problem. Unfortunately, existing automatic evaluation metrics are biased and correlate very poorly with human judgements of response quality. Yet having an accurate automatic evaluation procedure is crucial for dialogue research, as it allows rapid prototyping and testing of new models with fewer expensive human evaluations. In response to this challenge, we formulate automatic dialogue evaluation as a learning problem. We present an evaluation model (ADEM) that learns to predict human-like scores to input responses, using a new dataset of human response scores. We show that the ADEM model's predictions correlate significantly, and at a level much higher than word-overlap metrics such as BLEU, with human judgements at both the utterance and system-level. We also show that ADEM can generalize to evaluating dialogue models unseen during training, an important step for automatic dialogue evaluation.",
    "match_score": 0.993103448275862
  },
  "Self-Supervised Dialogue Learning": {
    "openalex_id": "https://openalex.org/W2964046296",
    "publication_year": 2019,
    "cited_by_count": 57,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W182831726",
      "https://openalex.org/W219040644",
      "https://openalex.org/W343636949",
      "https://openalex.org/W635530177",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1614298861",
      "https://openalex.org/W1841959837",
      "https://openalex.org/W1902237438",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1993378086",
      "https://openalex.org/W2064675550",
      "https://openalex.org/W2099471712",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2140679639",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2168490009",
      "https://openalex.org/W2170973209",
      "https://openalex.org/W2335122196",
      "https://openalex.org/W2542835211",
      "https://openalex.org/W2571927164",
      "https://openalex.org/W2581637843",
      "https://openalex.org/W2584185835",
      "https://openalex.org/W2594726847",
      "https://openalex.org/W2756487349",
      "https://openalex.org/W2798494119",
      "https://openalex.org/W2798888952",
      "https://openalex.org/W2806936550",
      "https://openalex.org/W2889186204",
      "https://openalex.org/W2890969459",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2914120296",
      "https://openalex.org/W2950577311",
      "https://openalex.org/W2951883832",
      "https://openalex.org/W2952729433",
      "https://openalex.org/W2952938873",
      "https://openalex.org/W2962739339",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963167310",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963360026",
      "https://openalex.org/W2963420272",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963854351",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964268978",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W3022187094",
      "https://openalex.org/W3088653102",
      "https://openalex.org/W4285719527",
      "https://openalex.org/W4294149591",
      "https://openalex.org/W4294170691",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4306716473",
      "https://openalex.org/W4320013936"
    ],
    "abstract": "The sequential order of utterances is often meaningful in coherent dialogues, and the order changes of utterances could lead to low-quality and incoherent conversations. We consider the order information as a crucial supervised signal for dialogue learning, which, however, has been neglected by many previous dialogue systems. Therefore, in this paper, we introduce a self-supervised learning task, inconsistent order detection, to explicitly capture the flow of conversation in dialogues. Given a sampled utterance pair triple, the task is to predict whether it is ordered or misordered. Then we propose a sampling-based self-supervised network SSN to perform the prediction with sampled triple references from previous dialogue history. Furthermore, we design a joint learning framework where SSN can guide the dialogue systems towards more coherent and relevant dialogue learning through adversarial training. We demonstrate that the proposed methods can be applied to both open-domain and task-oriented dialogue scenarios, and achieve the new state-of-the-art performance on the OpenSubtitiles and Movie-Ticket Booking datasets.",
    "match_score": 1.0
  },
  "Don\u2019t Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood Training": {
    "openalex_id": "https://openalex.org/W3035068109",
    "publication_year": 2020,
    "cited_by_count": 120,
    "referenced_works": [
      "https://openalex.org/W1840435438",
      "https://openalex.org/W2741986794",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2913443447",
      "https://openalex.org/W2916772188",
      "https://openalex.org/W2938704169",
      "https://openalex.org/W2946609015",
      "https://openalex.org/W2950681488",
      "https://openalex.org/W2955315729",
      "https://openalex.org/W2962788902",
      "https://openalex.org/W2962805889",
      "https://openalex.org/W2962974452",
      "https://openalex.org/W2962989446",
      "https://openalex.org/W2963149412",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963531095",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963846996",
      "https://openalex.org/W2968297680",
      "https://openalex.org/W2969574947",
      "https://openalex.org/W2970453125",
      "https://openalex.org/W2970476646",
      "https://openalex.org/W2971883198",
      "https://openalex.org/W2995404354",
      "https://openalex.org/W2996287690",
      "https://openalex.org/W2997012196",
      "https://openalex.org/W3034999214",
      "https://openalex.org/W3035239386",
      "https://openalex.org/W4288113479",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Generative dialogue models currently suffer from a number of problems which standard maximum likelihood training does not address. They tend to produce generations that (i) rely too much on copying from the context, (ii) contain repetitions within utterances, (iii) overuse frequent words, and (iv) at a deeper level, contain logical flaws.In this work we show how all of these problems can be addressed by extending the recently introduced unlikelihood loss (Welleck et al., 2019) to these cases. We show that appropriate loss functions which regularize generated outputs to match human distributions are effective for the first three issues. For the last important general issue, we show applying unlikelihood to collected data of what a model should not do is effective for improving logical consistency, potentially paving the way to generative models with greater reasoning ability. We demonstrate the efficacy of our approach across several dialogue tasks.",
    "match_score": 1.0
  },
  "Deep Reinforcement Learning for Dialogue Generation": {
    "openalex_id": "https://openalex.org/W2963167310",
    "publication_year": 2016,
    "cited_by_count": 1047,
    "referenced_works": [
      "https://openalex.org/W10957333",
      "https://openalex.org/W319421170",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1519256446",
      "https://openalex.org/W1591706642",
      "https://openalex.org/W1592751638",
      "https://openalex.org/W1604513301",
      "https://openalex.org/W1681299129",
      "https://openalex.org/W1757796397",
      "https://openalex.org/W1847211030",
      "https://openalex.org/W1934909785",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1970207841",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1987326241",
      "https://openalex.org/W2004637830",
      "https://openalex.org/W2046765929",
      "https://openalex.org/W2068687198",
      "https://openalex.org/W2101105183",
      "https://openalex.org/W2111526438",
      "https://openalex.org/W2115101920",
      "https://openalex.org/W2117989772",
      "https://openalex.org/W2119717200",
      "https://openalex.org/W2125308790",
      "https://openalex.org/W2130942839",
      "https://openalex.org/W2132997613",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2140054881",
      "https://openalex.org/W2155027007",
      "https://openalex.org/W2160458012",
      "https://openalex.org/W2163068732",
      "https://openalex.org/W2164637623",
      "https://openalex.org/W2168490009",
      "https://openalex.org/W2176263492",
      "https://openalex.org/W2252011326",
      "https://openalex.org/W2257979135",
      "https://openalex.org/W2296073425",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2335122196",
      "https://openalex.org/W2340944142",
      "https://openalex.org/W2395531022",
      "https://openalex.org/W2417401578",
      "https://openalex.org/W2949801941",
      "https://openalex.org/W2951813108",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963206148",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2963903950",
      "https://openalex.org/W2963963856",
      "https://openalex.org/W2964179661",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W3099293669",
      "https://openalex.org/W3121854931",
      "https://openalex.org/W4234099752",
      "https://openalex.org/W4298857966"
    ],
    "abstract": "Recent neural models of dialogue generation offer great promise for generating responses for conversational agents, but tend to be shortsighted, predicting utterances one at a time while ignoring their influence on future outcomes.Modeling the future direction of a dialogue is crucial to generating coherent, interesting dialogues, a need which led traditional NLP models of dialogue to draw on reinforcement learning.In this paper, we show how to integrate these goals, applying deep reinforcement learning to model future reward in chatbot dialogue.The model simulates dialogues between two virtual agents, using policy gradient methods to reward sequences that display three useful conversational properties: informativity, coherence, and ease of answering (related to forward-looking function).We evaluate our model on diversity, length as well as with human judges, showing that the proposed algorithm generates more interactive responses and manages to foster a more sustained conversation in dialogue simulation.This work marks a first step towards learning a neural conversational model based on the long-term success of dialogues.",
    "match_score": 1.0
  },
  "Efficient Context and Schema Fusion Networks for Multi-Domain Dialogue State Tracking": {
    "openalex_id": "https://openalex.org/W3106495716",
    "publication_year": 2020,
    "cited_by_count": 51,
    "referenced_works": [
      "https://openalex.org/W10050918",
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1604102475",
      "https://openalex.org/W1975244201",
      "https://openalex.org/W1986362700",
      "https://openalex.org/W1993567041",
      "https://openalex.org/W2055537935",
      "https://openalex.org/W2116341502",
      "https://openalex.org/W2133564696",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250456405",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251058040",
      "https://openalex.org/W2251235149",
      "https://openalex.org/W2556468274",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2882101086",
      "https://openalex.org/W2891732163",
      "https://openalex.org/W2892375082",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2946824041",
      "https://openalex.org/W2950038834",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2962946486",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963106169",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963858333",
      "https://openalex.org/W2963964898",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964199361",
      "https://openalex.org/W2964308564",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2971124188",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2988252747",
      "https://openalex.org/W2996317432",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W3008966357",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W4288027128",
      "https://openalex.org/W4288094254",
      "https://openalex.org/W4297733535",
      "https://openalex.org/W4385245566",
      "https://openalex.org/W4394666973"
    ],
    "abstract": "Dialogue state tracking (DST) aims at estimating the current dialogue state given all the preceding conversation. For multi-domain DST, the data sparsity problem is a major obstacle due to increased numbers of state candidates and dialogue lengths. To encode the dialogue context efficiently, we utilize the previous dialogue state (predicted) and the current dialogue utterance as the input for DST. To consider relations among different domain-slots, the schema graph involving prior knowledge is exploited. In this paper, a novel context and schema fusion network is proposed to encode the dialogue context and schema graph by using internal and external attention mechanisms. Experiment results show that our approach can outperform strong baselines, and the previous state-of-the-art method (SOM-DST) can also be improved by our proposed schema graph.",
    "match_score": 1.0
  },
  "PolyResponse A Rank-based Approach to Task-Oriented Dialogue with Application in Restaurant Search and Booking": {
    "openalex_id": "https://openalex.org/W2971316210",
    "publication_year": 2019,
    "cited_by_count": 12,
    "referenced_works": [
      "https://openalex.org/W10050918",
      "https://openalex.org/W1577202350",
      "https://openalex.org/W2108598243",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2318810549",
      "https://openalex.org/W2413533759",
      "https://openalex.org/W2419539795",
      "https://openalex.org/W2593864460",
      "https://openalex.org/W2604698497",
      "https://openalex.org/W2611029872",
      "https://openalex.org/W2612445135",
      "https://openalex.org/W2806600904",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2939689074",
      "https://openalex.org/W2948110372",
      "https://openalex.org/W2949252816",
      "https://openalex.org/W2952267213",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963469388",
      "https://openalex.org/W2963491014",
      "https://openalex.org/W2963662719",
      "https://openalex.org/W2963788376",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2972437240",
      "https://openalex.org/W4239072543",
      "https://openalex.org/W4295249402",
      "https://openalex.org/W4297775537",
      "https://openalex.org/W4297785815",
      "https://openalex.org/W4299585995",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Matthew Henderson, Ivan Vuli\u0107, I\u00f1igo Casanueva, Pawe\u0142 Budzianowski, Daniela Gerz, Sam Coope, Georgios Spithourakis, Tsung-Hsien Wen, Nikola Mrk\u0161i\u0107, Pei-Hao Su. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations. 2019.",
    "match_score": 0.995475113122172
  },
  "Slot-consistent NLG for Task-oriented Dialogue Systems with Iterative Rectification Network": {
    "openalex_id": "https://openalex.org/W3034643843",
    "publication_year": 2020,
    "cited_by_count": 18,
    "referenced_works": [
      "https://openalex.org/W1947758080",
      "https://openalex.org/W1948566616",
      "https://openalex.org/W1970207841",
      "https://openalex.org/W2004637830",
      "https://openalex.org/W2050523636",
      "https://openalex.org/W2097828466",
      "https://openalex.org/W2104787899",
      "https://openalex.org/W2122514299",
      "https://openalex.org/W2139079654",
      "https://openalex.org/W2156718681",
      "https://openalex.org/W2157812664",
      "https://openalex.org/W2176263492",
      "https://openalex.org/W2291723583",
      "https://openalex.org/W2752047430",
      "https://openalex.org/W2808815309",
      "https://openalex.org/W2949413855",
      "https://openalex.org/W2951176429",
      "https://openalex.org/W2953035981",
      "https://openalex.org/W2962956378",
      "https://openalex.org/W2964077278",
      "https://openalex.org/W3100380967",
      "https://openalex.org/W4230563027"
    ],
    "abstract": "Data-driven approaches using neural networks have achieved promising performances in natural language generation (NLG). However, neural generators are prone to make mistakes, e.g., neglecting an input slot value and generating a redundant slot value. Prior works refer this to hallucination phenomenon. In this paper, we study slot consistency for building reliable NLG systems with all slot values of input dialogue act (DA) properly generated in output sentences. We propose Iterative Rectification Network (IRN) for improving general NLG systems to produce both correct and fluent responses. It applies a bootstrapping algorithm to sample training candidates and uses reinforcement learning to incorporate discrete reward related to slot inconsistency into training. Comprehensive studies have been conducted on multiple benchmark datasets, showing that the proposed methods have significantly reduced the slot error rate (ERR) for all strong baselines. Human evaluations also have confirmed its effectiveness.",
    "match_score": 1.0
  },
  "Improving Limited Labeled Dialogue State Tracking with Self-Supervision": {
    "openalex_id": "https://openalex.org/W3105480731",
    "publication_year": 2020,
    "cited_by_count": 11,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1785674045",
      "https://openalex.org/W2119015791",
      "https://openalex.org/W2154455818",
      "https://openalex.org/W2250297846",
      "https://openalex.org/W2250539671",
      "https://openalex.org/W2251355666",
      "https://openalex.org/W2293363371",
      "https://openalex.org/W2431080869",
      "https://openalex.org/W2438667436",
      "https://openalex.org/W2507756961",
      "https://openalex.org/W2556468274",
      "https://openalex.org/W2606974598",
      "https://openalex.org/W2798367796",
      "https://openalex.org/W2888882903",
      "https://openalex.org/W2889448364",
      "https://openalex.org/W2912889105",
      "https://openalex.org/W2930865789",
      "https://openalex.org/W2945475330",
      "https://openalex.org/W2952592807",
      "https://openalex.org/W2954492830",
      "https://openalex.org/W2962831269",
      "https://openalex.org/W2963009325",
      "https://openalex.org/W2963243930",
      "https://openalex.org/W2963283951",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963435192",
      "https://openalex.org/W2963641152",
      "https://openalex.org/W2963797754",
      "https://openalex.org/W2964006684",
      "https://openalex.org/W2964046296",
      "https://openalex.org/W2964057895",
      "https://openalex.org/W2964101860",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2970404807",
      "https://openalex.org/W2970529793",
      "https://openalex.org/W2972777589",
      "https://openalex.org/W2973230427",
      "https://openalex.org/W2978426779",
      "https://openalex.org/W2979400990",
      "https://openalex.org/W2997771882",
      "https://openalex.org/W2998228050",
      "https://openalex.org/W2998432370",
      "https://openalex.org/W3008186200",
      "https://openalex.org/W3016625483",
      "https://openalex.org/W3034573951",
      "https://openalex.org/W3034917899",
      "https://openalex.org/W3100110884",
      "https://openalex.org/W3119649668",
      "https://openalex.org/W3148060700",
      "https://openalex.org/W4231665360",
      "https://openalex.org/W4288094254"
    ],
    "abstract": "Existing dialogue state tracking (DST) models require plenty of labeled data. However, collecting high-quality labels is costly, especially when the number of domains increases. In this paper, we address a practical DST problem that is rarely discussed, i.e., learning efficiently with limited labeled data. We present and investigate two self-supervised objectives: preserving latent consistency and modeling conversational behavior. We encourage a DST model to have consistent latent distributions given a perturbed input, making it more robust to an unseen scenario. We also add an auxiliary utterance generation task, modeling a potential correlation between conversational behavior and dialogue states. The experimental results show that our proposed self-supervised signals can improve joint goal accuracy by 8.95% when only 1% labeled data is used on the MultiWOZ dataset. We can achieve an additional 1.76% improvement if some unlabeled data is jointly trained as semi-supervised learning. We analyze and visualize how our proposed self-supervised signals help the DST task and hope to stimulate future data-efficient DST research.",
    "match_score": 1.0
  },
  "ScoutBot A Dialogue System for Collaborative Navigation": {
    "openalex_id": "https://openalex.org/W2803503442",
    "publication_year": 2018,
    "cited_by_count": 22,
    "referenced_works": [
      "https://openalex.org/W175385064",
      "https://openalex.org/W1505802906",
      "https://openalex.org/W1944193361",
      "https://openalex.org/W2131799829",
      "https://openalex.org/W2176669720",
      "https://openalex.org/W2180571361",
      "https://openalex.org/W2525212249",
      "https://openalex.org/W2806560294",
      "https://openalex.org/W4300925350"
    ],
    "abstract": "Stephanie M. Lukin, Felix Gervits, Cory J. Hayes, Pooja Moolchandani, Anton Leuski, John G. Rogers III, Carlos Sanchez Amaro, Matthew Marge, Clare R. Voss, David Traum. Proceedings of ACL 2018, System Demonstrations. 2018.",
    "match_score": 0.990990990990991
  },
  "Bridging the Gap between Prior and Posterior Knowledge Selection for Knowledge-Grounded Dialogue Generation": {
    "openalex_id": "https://openalex.org/W3104123491",
    "publication_year": 2020,
    "cited_by_count": 78,
    "referenced_works": [
      "https://openalex.org/W1522301498",
      "https://openalex.org/W1821462560",
      "https://openalex.org/W2157331557",
      "https://openalex.org/W2176263492",
      "https://openalex.org/W2547875792",
      "https://openalex.org/W2581377246",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2752047430",
      "https://openalex.org/W2794557536",
      "https://openalex.org/W2807873315",
      "https://openalex.org/W2891103209",
      "https://openalex.org/W2891501508",
      "https://openalex.org/W2896457183",
      "https://openalex.org/W2898875342",
      "https://openalex.org/W2915295540",
      "https://openalex.org/W2950009015",
      "https://openalex.org/W2950635152",
      "https://openalex.org/W2950902819",
      "https://openalex.org/W2951508633",
      "https://openalex.org/W2951807227",
      "https://openalex.org/W2962717182",
      "https://openalex.org/W2962985038",
      "https://openalex.org/W2963159735",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963475460",
      "https://openalex.org/W2963789888",
      "https://openalex.org/W2963825865",
      "https://openalex.org/W2963945575",
      "https://openalex.org/W2964121744",
      "https://openalex.org/W2964165364",
      "https://openalex.org/W2964345285",
      "https://openalex.org/W2964458951",
      "https://openalex.org/W2966404868",
      "https://openalex.org/W2969895640",
      "https://openalex.org/W2970139579",
      "https://openalex.org/W2970287057",
      "https://openalex.org/W2970988759",
      "https://openalex.org/W2972664115",
      "https://openalex.org/W2979478117",
      "https://openalex.org/W2986867746",
      "https://openalex.org/W2995183464",
      "https://openalex.org/W2997300509",
      "https://openalex.org/W2997896082",
      "https://openalex.org/W2998083599",
      "https://openalex.org/W3000779003",
      "https://openalex.org/W3006065545",
      "https://openalex.org/W4287900772",
      "https://openalex.org/W4297798436",
      "https://openalex.org/W4385245566"
    ],
    "abstract": "Knowledge selection plays an important role in knowledge-grounded dialogue, which is a challenging task to generate more informative responses by leveraging external knowledge. Recently, latent variable models have been proposed to deal with the diversity of knowledge selection by using both prior and posterior distributions over knowledge and achieve promising performance. However, these models suffer from a huge gap between prior and posterior knowledge selection. Firstly, the prior selection module may not learn to select knowledge properly because of lacking the necessary posterior information. Secondly, latent variable models suffer from the exposure bias that dialogue generation is based on the knowledge selected from the posterior distribution at training but from the prior distribution at inference. Here, we deal with these issues on two aspects: (1) We enhance the prior selection module with the necessary posterior information obtained from the specially designed Posterior Information Prediction Module (PIPM); (2) We propose a Knowledge Distillation Based Training Strategy (KDBTS) to train the decoder with the knowledge selected from the prior distribution, removing the exposure bias of knowledge selection. Experimental results on two knowledge-grounded dialogue datasets show that both PIPM and KDBTS achieve performance improvement over the state-of-the-art latent variable model and their combination shows further improvement.",
    "match_score": 1.0
  },
  "Evaluating Coherence in Dialogue Systems using Entailment": {
    "openalex_id": "https://openalex.org/W2929767294",
    "publication_year": 2019,
    "cited_by_count": 17,
    "referenced_works": [
      "https://openalex.org/W119047706",
      "https://openalex.org/W630532510",
      "https://openalex.org/W1518951372",
      "https://openalex.org/W1840435438",
      "https://openalex.org/W1879966306",
      "https://openalex.org/W2151814822",
      "https://openalex.org/W2153579005",
      "https://openalex.org/W2328886022",
      "https://openalex.org/W2525127255",
      "https://openalex.org/W2608787653",
      "https://openalex.org/W2784400615",
      "https://openalex.org/W2787560479",
      "https://openalex.org/W2794557536",
      "https://openalex.org/W2899231639",
      "https://openalex.org/W2899503556",
      "https://openalex.org/W2907308297",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963035145",
      "https://openalex.org/W2963310665",
      "https://openalex.org/W2963341956",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963527228",
      "https://openalex.org/W2963790827",
      "https://openalex.org/W2963846996",
      "https://openalex.org/W2963918774",
      "https://openalex.org/W2964352131",
      "https://openalex.org/W3023071679"
    ],
    "abstract": "Evaluating open-domain dialogue systems is difficult due to the diversity of possible correct answers. Automatic metrics such as BLEU correlate weakly with human annotations, resulting in a significant bias across different models and datasets. Some researchers resort to human judgment experimentation for assessing response quality, which is expensive, time consuming, and not scalable. Moreover, judges tend to evaluate a small number of dialogues, meaning that minor differences in evaluation configuration may lead to dissimilar results. In this paper, we present interpretable metrics for evaluating topic coherence by making use of distributed sentence representations. Furthermore, we introduce calculable approximations of human judgment based on conversational coherence by adopting state-of-the-art entailment techniques. Results show that our metrics can be used as a surrogate for human judgment, making it easy to evaluate dialogue systems on large-scale datasets and allowing an unbiased estimate for the quality of the responses.",
    "match_score": 1.0
  },
  "Training Millions of Personalized Dialogue Agents": {
    "openalex_id": "https://openalex.org/W2890394457",
    "publication_year": 2018,
    "cited_by_count": 211,
    "referenced_works": [
      "https://openalex.org/W1793121960",
      "https://openalex.org/W2399060250",
      "https://openalex.org/W2586847566",
      "https://openalex.org/W2688962481",
      "https://openalex.org/W2962883855",
      "https://openalex.org/W2963149412",
      "https://openalex.org/W2963403868",
      "https://openalex.org/W2963520511",
      "https://openalex.org/W2964119254",
      "https://openalex.org/W2964210218",
      "https://openalex.org/W2964352131"
    ],
    "abstract": "Current dialogue systems fail at being engaging for users, especially when trained end-to-end without relying on proactive reengaging scripted strategies. Zhang et al. (2018) showed that the engagement level of end-to-end dialogue models increases when conditioning them on text personas providing some personalized back-story to the model. However, the dataset used in Zhang et al. (2018) is synthetic and only contains around 1k different personas. In this paper we introduce a new dataset providing 5 million personas and 700 million persona-based dialogues. Our experiments show that, at this scale, training using personas still improves the performance of end-to-end systems. In addition, we show that other tasks benefit from the wide coverage of our dataset by fine-tuning our model on the data from Zhang et al. (2018) and achieving state-of-the-art results.",
    "match_score": 1.0
  }
}